🔝 Retour au [Sommaire](/SOMMAIRE.md)

# 12.1 Stratégies de sauvegarde cloud-native

## Introduction

Les stratégies de sauvegarde modernes doivent répondre aux défis des infrastructures hybrides qui mélangent serveurs traditionnels, machines virtuelles, conteneurs et services cloud. Cette section vous guide à travers les concepts fondamentaux et les outils pratiques pour mettre en place une stratégie de sauvegarde robuste et adaptée aux besoins actuels.

---

## 12.1.1 Types de sauvegardes (traditionnelles et cloud)

### Sauvegardes traditionnelles

Les méthodes classiques restent pertinentes et constituent souvent la base de stratégies plus complexes :

**Sauvegarde complète (Full Backup)**
- Copie intégrale de toutes les données à un moment donné
- Avantages : Restauration simple et rapide
- Inconvénients : Consommation importante d'espace et de temps
- Cas d'usage : Sauvegarde hebdomadaire ou mensuelle

**Sauvegarde incrémentale**
- Ne sauvegarde que les données modifiées depuis la dernière sauvegarde (complète ou incrémentale)
- Avantages : Rapide à exécuter, économe en espace
- Inconvénients : Restauration complexe nécessitant toute la chaîne
- Cas d'usage : Sauvegardes quotidiennes

**Sauvegarde différentielle**
- Sauvegarde tous les changements depuis la dernière sauvegarde complète
- Avantages : Restauration nécessitant seulement la complète + la différentielle
- Inconvénients : Taille croissante jusqu'à la prochaine complète
- Cas d'usage : Compromis entre incrémentale et complète

### Sauvegardes cloud-native

Les approches modernes s'adaptent aux architectures distribuées :

**Sauvegarde par snapshot**
- Capture instantanée de l'état d'un volume ou d'une VM
- Avantages : Très rapide, cohérence garantie
- Cas d'usage : Volumes LVM, disques virtuels, stockage cloud

**Sauvegarde continue (CDP - Continuous Data Protection)**
- Réplication en temps réel des modifications
- Avantages : RPO très faible (quelques secondes)
- Cas d'usage : Bases de données critiques, applications transactionnelles

**Sauvegarde applicative**
- Export des données par l'application elle-même
- Avantages : Cohérence applicative garantie
- Exemples : `mysqldump`, `pg_dump`, export Kubernetes YAML

**Sauvegarde immutable**
- Données protégées contre la modification ou suppression
- Avantages : Protection contre ransomware
- Technologies : Object Lock S3, WORM (Write Once Read Many)

---

## 12.1.2 Outils (rsync, tar, borgbackup, Velero)

### rsync - Synchronisation robuste

`rsync` est l'outil de référence pour la synchronisation de fichiers :

```bash
# Syntaxe de base
rsync [options] source destination

# Options essentielles
-a : mode archive (préserve permissions, liens, dates)
-v : verbose (affichage détaillé)
-z : compression pendant le transfert
-h : format lisible (tailles en Ko, Mo, Go)
--delete : supprime les fichiers qui n'existent plus dans la source
--dry-run : simulation sans modification
```

**Cas d'usage typiques :**

```bash
# Sauvegarde locale
rsync -avh /home/user/ /backup/home-backup/

# Sauvegarde distante via SSH
rsync -avz /data/ user@backup-server:/backups/data/

# Synchronisation avec exclusions
rsync -avh --exclude='*.tmp' --exclude='cache/' /app/ /backup/app/

# Sauvegarde avec limitation de bande passante
rsync -avz --bwlimit=1000 /large-data/ remote:/backup/
```

### tar - Archivage traditionnel

`tar` reste incontournable pour l'archivage et la compression :

```bash
# Création d'archive compressée
tar -czf backup-$(date +%Y%m%d).tar.gz /path/to/data

# Archive avec exclusions
tar --exclude='*.log' --exclude='tmp/*' -czf backup.tar.gz /app

# Extraction
tar -xzf backup.tar.gz

# Listing du contenu
tar -tzf backup.tar.gz
```

**Bonnes pratiques avec tar :**
- Utiliser des noms d'archives avec timestamp
- Tester l'intégrité avec `tar -tzf`
- Considérer `pigz` pour la compression parallèle sur systèmes multi-cœurs

### BorgBackup - Déduplication avancée

BorgBackup offre des fonctionnalités avancées de déduplication et chiffrement :

```bash
# Installation sur Debian
sudo apt install borgbackup

# Initialisation d'un dépôt
borg init --encryption=repokey /path/to/repo

# Création d'une sauvegarde
borg create /path/to/repo::backup-{now} /home /etc --exclude '*.pyc'

# Lister les archives
borg list /path/to/repo

# Informations sur une archive
borg info /path/to/repo::backup-2024-01-15

# Montage pour exploration
borg mount /path/to/repo::backup-2024-01-15 /mnt/backup
```

**Avantages de Borg :**
- Déduplication au niveau des blocs
- Chiffrement intégré
- Compression adaptative
- Vérification d'intégrité automatique

### Velero - Sauvegarde Kubernetes

Velero est l'outil de référence pour sauvegarder les clusters Kubernetes :

```bash
# Installation via kubectl
kubectl apply -f https://github.com/vmware-tanzu/velero/releases/download/v1.12.0/00-prereqs.yaml

# Configuration avec AWS S3
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.8.0 \
    --bucket velero-backups \
    --backup-location-config region=us-west-2 \
    --snapshot-location-config region=us-west-2
```

**Fonctionnalités clés :**
- Sauvegarde des objets Kubernetes (Deployments, Services, etc.)
- Snapshots de volumes persistants
- Restoration sélective par namespace
- Planification automatique

---

## 12.1.3 Sauvegarde Kubernetes (ETCD, PV)

### Sauvegarde ETCD

ETCD stocke l'état complet du cluster Kubernetes. Sa sauvegarde est critique :

```bash
# Sauvegarde ETCD avec etcdctl
ETCDCTL_API=3 etcdctl snapshot save /backup/etcd-snapshot-$(date +%Y%m%d).db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# Vérification de l'intégrité
ETCDCTL_API=3 etcdctl snapshot status /backup/etcd-snapshot.db
```

**Automatisation avec script :**

```bash
#!/bin/bash
# Script de sauvegarde ETCD automatisé

BACKUP_DIR="/backup/etcd"
DATE=$(date +%Y%m%d-%H%M%S)
SNAPSHOT_FILE="${BACKUP_DIR}/etcd-snapshot-${DATE}.db"

# Création du répertoire
mkdir -p ${BACKUP_DIR}

# Sauvegarde
ETCDCTL_API=3 etcdctl snapshot save ${SNAPSHOT_FILE} \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# Nettoyage (garde 7 jours)
find ${BACKUP_DIR} -name "etcd-snapshot-*.db" -mtime +7 -delete

echo "Sauvegarde ETCD terminée : ${SNAPSHOT_FILE}"
```

### Sauvegarde des Volumes Persistants (PV)

Les données applicatives dans Kubernetes nécessitent des stratégies spécifiques :

**Snapshots de volumes :**

```yaml
# VolumeSnapshotClass
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: csi-snapclass
driver: csi.driver.example.com
deletionPolicy: Delete

---
# VolumeSnapshot
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: database-snapshot
spec:
  volumeSnapshotClassName: csi-snapclass
  source:
    persistentVolumeClaimName: database-pvc
```

**Sauvegarde avec Velero et annotations :**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: database
  annotations:
    backup.velero.io/backup-volumes: data-volume
spec:
  containers:
  - name: database
    image: postgres:13
    volumeMounts:
    - name: data-volume
      mountPath: /var/lib/postgresql/data
  volumes:
  - name: data-volume
    persistentVolumeClaim:
      claimName: database-pvc
```

---

## 12.1.4 Automatisation avec cron et CronJobs K8s

### Automatisation traditionnelle avec cron

Configuration de tâches de sauvegarde régulières :

```bash
# Édition du crontab
sudo crontab -e

# Exemples de planification
# Sauvegarde quotidienne à 2h du matin
0 2 * * * /usr/local/bin/backup-script.sh

# Sauvegarde hebdomadaire le dimanche à 1h
0 1 * * 0 /usr/local/bin/weekly-backup.sh

# Sauvegarde mensuelle le 1er de chaque mois
0 3 1 * * /usr/local/bin/monthly-backup.sh
```

**Script de sauvegarde complet :**

```bash
#!/bin/bash
# /usr/local/bin/backup-script.sh

set -e  # Arrêt en cas d'erreur

# Configuration
BACKUP_DIR="/backup"
DATE=$(date +%Y%m%d)
LOG_FILE="/var/log/backup-${DATE}.log"
RETENTION_DAYS=30

# Fonction de logging
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a ${LOG_FILE}
}

# Début de la sauvegarde
log "Début de la sauvegarde"

# Sauvegarde système
log "Sauvegarde système en cours..."
rsync -av /etc/ ${BACKUP_DIR}/system/etc-${DATE}/ 2>&1 | tee -a ${LOG_FILE}

# Sauvegarde base de données
log "Sauvegarde base de données..."
mysqldump --all-databases > ${BACKUP_DIR}/mysql/dump-${DATE}.sql

# Compression
log "Compression des archives..."
tar -czf ${BACKUP_DIR}/compressed/backup-${DATE}.tar.gz \
    ${BACKUP_DIR}/system/etc-${DATE} \
    ${BACKUP_DIR}/mysql/dump-${DATE}.sql

# Nettoyage
log "Nettoyage des anciennes sauvegardes..."
find ${BACKUP_DIR} -name "backup-*.tar.gz" -mtime +${RETENTION_DAYS} -delete

log "Sauvegarde terminée avec succès"
```

### CronJobs Kubernetes

Pour automatiser les sauvegardes dans Kubernetes :

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
spec:
  schedule: "0 2 * * *"  # Tous les jours à 2h
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:13
            command:
            - /bin/bash
            - -c
            - |
              pg_dump -h postgres-service -U postgres database_name > /backup/dump-$(date +%Y%m%d).sql
              # Upload vers S3 ou autre stockage
              aws s3 cp /backup/dump-$(date +%Y%m%d).sql s3://backup-bucket/
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            emptyDir: {}
          restartPolicy: OnFailure
```

**CronJob pour Velero :**

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: velero-backup
spec:
  schedule: "0 1 * * *"  # Quotidien à 1h
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: velero
          containers:
          - name: velero-backup
            image: velero/velero:v1.12.0
            command:
            - /velero
            - backup
            - create
            - daily-backup-$(date +%Y%m%d)
            - --include-namespaces=production,staging
            - --storage-location=default
          restartPolicy: OnFailure
```

---

## 12.1.5 Sauvegarde distante et cross-cloud

### Stratégies multi-sites

La répartition géographique des sauvegardes protège contre les sinistres majeurs :

**Réplication avec rsync :**

```bash
# Synchronisation vers multiple destinations
#!/bin/bash

SOURCES="/home /etc /var/www"
DESTINATIONS=(
    "backup1.example.com:/backup/site1"
    "backup2.example.com:/backup/site2"
    "user@remote-site:/backup/offsite"
)

for dest in "${DESTINATIONS[@]}"; do
    echo "Synchronisation vers ${dest}..."
    rsync -avz --delete ${SOURCES} ${dest}/
done
```

### Cross-cloud avec rclone

`rclone` permet la synchronisation entre différents providers cloud :

```bash
# Installation
sudo apt install rclone

# Configuration interactive
rclone config

# Synchronisation multi-cloud
rclone sync /local/backup aws-s3:backup-bucket
rclone sync aws-s3:backup-bucket gcp-storage:backup-bucket
rclone sync /local/backup azure-blob:backup-container
```

**Configuration automatisée :**

```bash
# Script de réplication cross-cloud
#!/bin/bash

LOCAL_BACKUP="/backup/current"
CLOUD_DESTINATIONS=(
    "aws-s3:company-backups/$(date +%Y/%m)"
    "gcp-storage:backup-bucket/$(date +%Y/%m)"
    "azure-blob:backups/$(date +%Y/%m)"
)

for dest in "${CLOUD_DESTINATIONS[@]}"; do
    echo "Upload vers ${dest}..."
    rclone copy ${LOCAL_BACKUP} ${dest} --progress
done
```

### Chiffrement en transit et au repos

**Chiffrement avec GPG :**

```bash
# Sauvegarde chiffrée
tar -czf - /data | gpg --cipher-algo AES256 --compress-algo 2 \
    --symmetric --output backup-$(date +%Y%m%d).tar.gz.gpg

# Déchiffrement
gpg --decrypt backup-20240115.tar.gz.gpg | tar -xzf -
```

**Chiffrement avec age (moderne) :**

```bash
# Installation d'age
sudo apt install age

# Génération de clé
age-keygen -o key.txt

# Chiffrement
tar -czf - /data | age -r $(cat key.txt.pub) > backup.tar.gz.age

# Déchiffrement
age -d -i key.txt backup.tar.gz.age | tar -xzf -
```

---

## 12.1.6 Tests de restauration et validation

### Validation automatique de l'intégrité

Les sauvegardes sans validation sont potentiellement inutiles :

```bash
#!/bin/bash
# Script de validation des sauvegardes

BACKUP_DIR="/backup"
TEST_DIR="/tmp/restore-test"
LOG_FILE="/var/log/backup-validation.log"

validate_backup() {
    local backup_file=$1
    local test_name=$2

    echo "Test de $test_name..." | tee -a $LOG_FILE

    # Nettoyage du répertoire de test
    rm -rf $TEST_DIR && mkdir -p $TEST_DIR

    # Test d'extraction
    if tar -tzf $backup_file > /dev/null 2>&1; then
        echo "✓ Archive valide : $backup_file" | tee -a $LOG_FILE

        # Test de restauration partielle
        tar -xzf $backup_file -C $TEST_DIR --strip-components=1 2>/dev/null

        if [ $? -eq 0 ]; then
            echo "✓ Restauration test réussie" | tee -a $LOG_FILE
        else
            echo "✗ Erreur de restauration" | tee -a $LOG_FILE
            return 1
        fi
    else
        echo "✗ Archive corrompue : $backup_file" | tee -a $LOG_FILE
        return 1
    fi
}

# Test de toutes les sauvegardes récentes
for backup in $(find $BACKUP_DIR -name "*.tar.gz" -mtime -7); do
    validate_backup $backup $(basename $backup)
done
```

### Tests de récupération applicative

**Test de base de données :**

```bash
#!/bin/bash
# Test de restauration MySQL

DB_BACKUP="/backup/mysql/dump-$(date +%Y%m%d).sql"
TEST_DB="test_restore_$(date +%s)"

# Création d'une base de test
mysql -e "CREATE DATABASE $TEST_DB;"

# Import du dump
if mysql $TEST_DB < $DB_BACKUP; then
    echo "✓ Restauration MySQL réussie"

    # Vérification de la cohérence
    TABLES_COUNT=$(mysql -sN -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='$TEST_DB';")
    echo "Tables restaurées : $TABLES_COUNT"

    # Nettoyage
    mysql -e "DROP DATABASE $TEST_DB;"
else
    echo "✗ Erreur de restauration MySQL"
    exit 1
fi
```

### Monitoring des sauvegardes

**Dashboard Prometheus/Grafana :**

```yaml
# Métriques custom pour les sauvegardes
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-metrics
data:
  backup-metrics.sh: |
    #!/bin/bash
    # Exposition de métriques pour Prometheus

    METRICS_FILE="/tmp/backup-metrics.prom"

    # Dernière sauvegarde réussie
    LAST_BACKUP=$(find /backup -name "*.tar.gz" -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f1)
    echo "backup_last_success_timestamp $LAST_BACKUP" > $METRICS_FILE

    # Taille des sauvegardes
    BACKUP_SIZE=$(du -sb /backup | cut -f1)
    echo "backup_total_size_bytes $BACKUP_SIZE" >> $METRICS_FILE

    # Nombre de sauvegardes
    BACKUP_COUNT=$(find /backup -name "*.tar.gz" | wc -l)
    echo "backup_files_total $BACKUP_COUNT" >> $METRICS_FILE
```

---

## 12.1.7 Calcul RTO/RPO et stratégies 3-2-1

### Définition des objectifs

**RTO (Recovery Time Objective) :**
- Temps maximum acceptable pour restaurer le service
- Inclut : détection, décision, restauration, validation
- Exemple : "L'application doit être restaurée en moins de 4 heures"

**RPO (Recovery Point Objective) :**
- Perte de données maximum acceptable
- Détermine la fréquence des sauvegardes
- Exemple : "Perte maximum de 1 heure de données"

### Calcul et planification

```bash
# Exemple de calcul de temps de restauration
#!/bin/bash

# Paramètres de l'infrastructure
BACKUP_SIZE_GB=500
NETWORK_SPEED_MBPS=100
RESTORE_RATE_MBPS=80

# Calculs
TRANSFER_TIME_MIN=$((BACKUP_SIZE_GB * 8 * 1024 / NETWORK_SPEED_MBPS / 60))
RESTORE_TIME_MIN=$((BACKUP_SIZE_GB * 8 * 1024 / RESTORE_RATE_MBPS / 60))
VALIDATION_TIME_MIN=30

TOTAL_RTO_MIN=$((TRANSFER_TIME_MIN + RESTORE_TIME_MIN + VALIDATION_TIME_MIN))

echo "Temps de transfert estimé : ${TRANSFER_TIME_MIN} minutes"
echo "Temps de restauration estimé : ${RESTORE_TIME_MIN} minutes"
echo "RTO total estimé : ${TOTAL_RTO_MIN} minutes (${TOTAL_RTO_MIN}/60 heures)"
```

### Stratégie 3-2-1

La règle 3-2-1 est un standard de l'industrie :

- **3 copies** des données importantes
- **2 supports différents** (disque local + cloud, par exemple)
- **1 copie hors site** (géographiquement distante)

**Implémentation pratique :**

```bash
#!/bin/bash
# Implémentation de la stratégie 3-2-1

SOURCE_DATA="/production/data"
DATE=$(date +%Y%m%d)

# Copie 1 : Backup local (disque différent)
LOCAL_BACKUP="/backup/local/backup-${DATE}"
rsync -av $SOURCE_DATA/ $LOCAL_BACKUP/

# Copie 2 : Backup sur serveur de backup (réseau local)
NETWORK_BACKUP="backup-server:/backup/network/backup-${DATE}"
rsync -av $SOURCE_DATA/ $NETWORK_BACKUP/

# Copie 3 : Backup cloud (hors site)
tar -czf backup-${DATE}.tar.gz -C $(dirname $SOURCE_DATA) $(basename $SOURCE_DATA)
rclone copy backup-${DATE}.tar.gz aws-s3:offsite-backups/$(date +%Y/%m)/

echo "Stratégie 3-2-1 implémentée :"
echo "- Local : $LOCAL_BACKUP"
echo "- Réseau : $NETWORK_BACKUP"
echo "- Cloud : aws-s3:offsite-backups/$(date +%Y/%m)/backup-${DATE}.tar.gz"

# Nettoyage du fichier temporaire
rm backup-${DATE}.tar.gz
```

### Matrice de stratégies par criticité

| Criticité | RPO | RTO | Fréquence | Type | Localisation |
|-----------|-----|-----|-----------|------|--------------|
| Critique | 15 min | 1h | Continue | Réplication | Multi-zone |
| Important | 4h | 4h | 4x/jour | Snapshot | Local + Cloud |
| Standard | 24h | 24h | Quotidien | Fichier | Local + Remote |
| Archive | 1 semaine | 72h | Hebdomadaire | Tape/Glacier | Hors site |

### Optimisation des coûts

**Lifecycle policies pour le stockage cloud :**

```yaml
# Politique de cycle de vie AWS S3
{
  "Rules": [
    {
      "ID": "backup-lifecycle",
      "Status": "Enabled",
      "Filter": {"Prefix": "backups/"},
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        },
        {
          "Days": 365,
          "StorageClass": "DEEP_ARCHIVE"
        }
      ],
      "Expiration": {
        "Days": 2555  # 7 ans de rétention
      }
    }
  ]
}
```

---

## Conclusion

Les stratégies de sauvegarde cloud-native nécessitent une approche multicouche combinant outils traditionnels et solutions modernes. La clé du succès réside dans :

1. **L'adaptation aux besoins** : Choisir la stratégie selon la criticité des données
2. **L'automatisation** : Réduire les erreurs humaines et garantir la régularité
3. **La validation continue** : Tester régulièrement les procédures de restauration
4. **L'optimisation** : Équilibrer coût, performance et niveau de protection

Cette approche hybride permet de répondre aux exigences modernes tout en conservant la robustesse des méthodes éprouvées.

⏭️
