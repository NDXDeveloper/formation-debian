üîù Retour au [Sommaire](/SOMMAIRE.md)

# 12.1 Strat√©gies de sauvegarde cloud-native

## Introduction

Les strat√©gies de sauvegarde modernes doivent r√©pondre aux d√©fis des infrastructures hybrides qui m√©langent serveurs traditionnels, machines virtuelles, conteneurs et services cloud. Cette section vous guide √† travers les concepts fondamentaux et les outils pratiques pour mettre en place une strat√©gie de sauvegarde robuste et adapt√©e aux besoins actuels.

---

## 12.1.1 Types de sauvegardes (traditionnelles et cloud)

### Sauvegardes traditionnelles

Les m√©thodes classiques restent pertinentes et constituent souvent la base de strat√©gies plus complexes :

**Sauvegarde compl√®te (Full Backup)**
- Copie int√©grale de toutes les donn√©es √† un moment donn√©
- Avantages : Restauration simple et rapide
- Inconv√©nients : Consommation importante d'espace et de temps
- Cas d'usage : Sauvegarde hebdomadaire ou mensuelle

**Sauvegarde incr√©mentale**
- Ne sauvegarde que les donn√©es modifi√©es depuis la derni√®re sauvegarde (compl√®te ou incr√©mentale)
- Avantages : Rapide √† ex√©cuter, √©conome en espace
- Inconv√©nients : Restauration complexe n√©cessitant toute la cha√Æne
- Cas d'usage : Sauvegardes quotidiennes

**Sauvegarde diff√©rentielle**
- Sauvegarde tous les changements depuis la derni√®re sauvegarde compl√®te
- Avantages : Restauration n√©cessitant seulement la compl√®te + la diff√©rentielle
- Inconv√©nients : Taille croissante jusqu'√† la prochaine compl√®te
- Cas d'usage : Compromis entre incr√©mentale et compl√®te

### Sauvegardes cloud-native

Les approches modernes s'adaptent aux architectures distribu√©es :

**Sauvegarde par snapshot**
- Capture instantan√©e de l'√©tat d'un volume ou d'une VM
- Avantages : Tr√®s rapide, coh√©rence garantie
- Cas d'usage : Volumes LVM, disques virtuels, stockage cloud

**Sauvegarde continue (CDP - Continuous Data Protection)**
- R√©plication en temps r√©el des modifications
- Avantages : RPO tr√®s faible (quelques secondes)
- Cas d'usage : Bases de donn√©es critiques, applications transactionnelles

**Sauvegarde applicative**
- Export des donn√©es par l'application elle-m√™me
- Avantages : Coh√©rence applicative garantie
- Exemples : `mysqldump`, `pg_dump`, export Kubernetes YAML

**Sauvegarde immutable**
- Donn√©es prot√©g√©es contre la modification ou suppression
- Avantages : Protection contre ransomware
- Technologies : Object Lock S3, WORM (Write Once Read Many)

---

## 12.1.2 Outils (rsync, tar, borgbackup, Velero)

### rsync - Synchronisation robuste

`rsync` est l'outil de r√©f√©rence pour la synchronisation de fichiers :

```bash
# Syntaxe de base
rsync [options] source destination

# Options essentielles
-a : mode archive (pr√©serve permissions, liens, dates)
-v : verbose (affichage d√©taill√©)
-z : compression pendant le transfert
-h : format lisible (tailles en Ko, Mo, Go)
--delete : supprime les fichiers qui n'existent plus dans la source
--dry-run : simulation sans modification
```

**Cas d'usage typiques :**

```bash
# Sauvegarde locale
rsync -avh /home/user/ /backup/home-backup/

# Sauvegarde distante via SSH
rsync -avz /data/ user@backup-server:/backups/data/

# Synchronisation avec exclusions
rsync -avh --exclude='*.tmp' --exclude='cache/' /app/ /backup/app/

# Sauvegarde avec limitation de bande passante
rsync -avz --bwlimit=1000 /large-data/ remote:/backup/
```

### tar - Archivage traditionnel

`tar` reste incontournable pour l'archivage et la compression :

```bash
# Cr√©ation d'archive compress√©e
tar -czf backup-$(date +%Y%m%d).tar.gz /path/to/data

# Archive avec exclusions
tar --exclude='*.log' --exclude='tmp/*' -czf backup.tar.gz /app

# Extraction
tar -xzf backup.tar.gz

# Listing du contenu
tar -tzf backup.tar.gz
```

**Bonnes pratiques avec tar :**
- Utiliser des noms d'archives avec timestamp
- Tester l'int√©grit√© avec `tar -tzf`
- Consid√©rer `pigz` pour la compression parall√®le sur syst√®mes multi-c≈ìurs

### BorgBackup - D√©duplication avanc√©e

BorgBackup offre des fonctionnalit√©s avanc√©es de d√©duplication et chiffrement :

```bash
# Installation sur Debian
sudo apt install borgbackup

# Initialisation d'un d√©p√¥t
borg init --encryption=repokey /path/to/repo

# Cr√©ation d'une sauvegarde
borg create /path/to/repo::backup-{now} /home /etc --exclude '*.pyc'

# Lister les archives
borg list /path/to/repo

# Informations sur une archive
borg info /path/to/repo::backup-2024-01-15

# Montage pour exploration
borg mount /path/to/repo::backup-2024-01-15 /mnt/backup
```

**Avantages de Borg :**
- D√©duplication au niveau des blocs
- Chiffrement int√©gr√©
- Compression adaptative
- V√©rification d'int√©grit√© automatique

### Velero - Sauvegarde Kubernetes

Velero est l'outil de r√©f√©rence pour sauvegarder les clusters Kubernetes :

```bash
# Installation via kubectl
kubectl apply -f https://github.com/vmware-tanzu/velero/releases/download/v1.12.0/00-prereqs.yaml

# Configuration avec AWS S3
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.8.0 \
    --bucket velero-backups \
    --backup-location-config region=us-west-2 \
    --snapshot-location-config region=us-west-2
```

**Fonctionnalit√©s cl√©s :**
- Sauvegarde des objets Kubernetes (Deployments, Services, etc.)
- Snapshots de volumes persistants
- Restoration s√©lective par namespace
- Planification automatique

---

## 12.1.3 Sauvegarde Kubernetes (ETCD, PV)

### Sauvegarde ETCD

ETCD stocke l'√©tat complet du cluster Kubernetes. Sa sauvegarde est critique :

```bash
# Sauvegarde ETCD avec etcdctl
ETCDCTL_API=3 etcdctl snapshot save /backup/etcd-snapshot-$(date +%Y%m%d).db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# V√©rification de l'int√©grit√©
ETCDCTL_API=3 etcdctl snapshot status /backup/etcd-snapshot.db
```

**Automatisation avec script :**

```bash
#!/bin/bash
# Script de sauvegarde ETCD automatis√©

BACKUP_DIR="/backup/etcd"
DATE=$(date +%Y%m%d-%H%M%S)
SNAPSHOT_FILE="${BACKUP_DIR}/etcd-snapshot-${DATE}.db"

# Cr√©ation du r√©pertoire
mkdir -p ${BACKUP_DIR}

# Sauvegarde
ETCDCTL_API=3 etcdctl snapshot save ${SNAPSHOT_FILE} \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# Nettoyage (garde 7 jours)
find ${BACKUP_DIR} -name "etcd-snapshot-*.db" -mtime +7 -delete

echo "Sauvegarde ETCD termin√©e : ${SNAPSHOT_FILE}"
```

### Sauvegarde des Volumes Persistants (PV)

Les donn√©es applicatives dans Kubernetes n√©cessitent des strat√©gies sp√©cifiques :

**Snapshots de volumes :**

```yaml
# VolumeSnapshotClass
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshotClass
metadata:
  name: csi-snapclass
driver: csi.driver.example.com
deletionPolicy: Delete

---
# VolumeSnapshot
apiVersion: snapshot.storage.k8s.io/v1
kind: VolumeSnapshot
metadata:
  name: database-snapshot
spec:
  volumeSnapshotClassName: csi-snapclass
  source:
    persistentVolumeClaimName: database-pvc
```

**Sauvegarde avec Velero et annotations :**

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: database
  annotations:
    backup.velero.io/backup-volumes: data-volume
spec:
  containers:
  - name: database
    image: postgres:13
    volumeMounts:
    - name: data-volume
      mountPath: /var/lib/postgresql/data
  volumes:
  - name: data-volume
    persistentVolumeClaim:
      claimName: database-pvc
```

---

## 12.1.4 Automatisation avec cron et CronJobs K8s

### Automatisation traditionnelle avec cron

Configuration de t√¢ches de sauvegarde r√©guli√®res :

```bash
# √âdition du crontab
sudo crontab -e

# Exemples de planification
# Sauvegarde quotidienne √† 2h du matin
0 2 * * * /usr/local/bin/backup-script.sh

# Sauvegarde hebdomadaire le dimanche √† 1h
0 1 * * 0 /usr/local/bin/weekly-backup.sh

# Sauvegarde mensuelle le 1er de chaque mois
0 3 1 * * /usr/local/bin/monthly-backup.sh
```

**Script de sauvegarde complet :**

```bash
#!/bin/bash
# /usr/local/bin/backup-script.sh

set -e  # Arr√™t en cas d'erreur

# Configuration
BACKUP_DIR="/backup"
DATE=$(date +%Y%m%d)
LOG_FILE="/var/log/backup-${DATE}.log"
RETENTION_DAYS=30

# Fonction de logging
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a ${LOG_FILE}
}

# D√©but de la sauvegarde
log "D√©but de la sauvegarde"

# Sauvegarde syst√®me
log "Sauvegarde syst√®me en cours..."
rsync -av /etc/ ${BACKUP_DIR}/system/etc-${DATE}/ 2>&1 | tee -a ${LOG_FILE}

# Sauvegarde base de donn√©es
log "Sauvegarde base de donn√©es..."
mysqldump --all-databases > ${BACKUP_DIR}/mysql/dump-${DATE}.sql

# Compression
log "Compression des archives..."
tar -czf ${BACKUP_DIR}/compressed/backup-${DATE}.tar.gz \
    ${BACKUP_DIR}/system/etc-${DATE} \
    ${BACKUP_DIR}/mysql/dump-${DATE}.sql

# Nettoyage
log "Nettoyage des anciennes sauvegardes..."
find ${BACKUP_DIR} -name "backup-*.tar.gz" -mtime +${RETENTION_DAYS} -delete

log "Sauvegarde termin√©e avec succ√®s"
```

### CronJobs Kubernetes

Pour automatiser les sauvegardes dans Kubernetes :

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: database-backup
spec:
  schedule: "0 2 * * *"  # Tous les jours √† 2h
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: postgres:13
            command:
            - /bin/bash
            - -c
            - |
              pg_dump -h postgres-service -U postgres database_name > /backup/dump-$(date +%Y%m%d).sql
              # Upload vers S3 ou autre stockage
              aws s3 cp /backup/dump-$(date +%Y%m%d).sql s3://backup-bucket/
            env:
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            emptyDir: {}
          restartPolicy: OnFailure
```

**CronJob pour Velero :**

```yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: velero-backup
spec:
  schedule: "0 1 * * *"  # Quotidien √† 1h
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: velero
          containers:
          - name: velero-backup
            image: velero/velero:v1.12.0
            command:
            - /velero
            - backup
            - create
            - daily-backup-$(date +%Y%m%d)
            - --include-namespaces=production,staging
            - --storage-location=default
          restartPolicy: OnFailure
```

---

## 12.1.5 Sauvegarde distante et cross-cloud

### Strat√©gies multi-sites

La r√©partition g√©ographique des sauvegardes prot√®ge contre les sinistres majeurs :

**R√©plication avec rsync :**

```bash
# Synchronisation vers multiple destinations
#!/bin/bash

SOURCES="/home /etc /var/www"
DESTINATIONS=(
    "backup1.example.com:/backup/site1"
    "backup2.example.com:/backup/site2"
    "user@remote-site:/backup/offsite"
)

for dest in "${DESTINATIONS[@]}"; do
    echo "Synchronisation vers ${dest}..."
    rsync -avz --delete ${SOURCES} ${dest}/
done
```

### Cross-cloud avec rclone

`rclone` permet la synchronisation entre diff√©rents providers cloud :

```bash
# Installation
sudo apt install rclone

# Configuration interactive
rclone config

# Synchronisation multi-cloud
rclone sync /local/backup aws-s3:backup-bucket
rclone sync aws-s3:backup-bucket gcp-storage:backup-bucket
rclone sync /local/backup azure-blob:backup-container
```

**Configuration automatis√©e :**

```bash
# Script de r√©plication cross-cloud
#!/bin/bash

LOCAL_BACKUP="/backup/current"
CLOUD_DESTINATIONS=(
    "aws-s3:company-backups/$(date +%Y/%m)"
    "gcp-storage:backup-bucket/$(date +%Y/%m)"
    "azure-blob:backups/$(date +%Y/%m)"
)

for dest in "${CLOUD_DESTINATIONS[@]}"; do
    echo "Upload vers ${dest}..."
    rclone copy ${LOCAL_BACKUP} ${dest} --progress
done
```

### Chiffrement en transit et au repos

**Chiffrement avec GPG :**

```bash
# Sauvegarde chiffr√©e
tar -czf - /data | gpg --cipher-algo AES256 --compress-algo 2 \
    --symmetric --output backup-$(date +%Y%m%d).tar.gz.gpg

# D√©chiffrement
gpg --decrypt backup-20240115.tar.gz.gpg | tar -xzf -
```

**Chiffrement avec age (moderne) :**

```bash
# Installation d'age
sudo apt install age

# G√©n√©ration de cl√©
age-keygen -o key.txt

# Chiffrement
tar -czf - /data | age -r $(cat key.txt.pub) > backup.tar.gz.age

# D√©chiffrement
age -d -i key.txt backup.tar.gz.age | tar -xzf -
```

---

## 12.1.6 Tests de restauration et validation

### Validation automatique de l'int√©grit√©

Les sauvegardes sans validation sont potentiellement inutiles :

```bash
#!/bin/bash
# Script de validation des sauvegardes

BACKUP_DIR="/backup"
TEST_DIR="/tmp/restore-test"
LOG_FILE="/var/log/backup-validation.log"

validate_backup() {
    local backup_file=$1
    local test_name=$2

    echo "Test de $test_name..." | tee -a $LOG_FILE

    # Nettoyage du r√©pertoire de test
    rm -rf $TEST_DIR && mkdir -p $TEST_DIR

    # Test d'extraction
    if tar -tzf $backup_file > /dev/null 2>&1; then
        echo "‚úì Archive valide : $backup_file" | tee -a $LOG_FILE

        # Test de restauration partielle
        tar -xzf $backup_file -C $TEST_DIR --strip-components=1 2>/dev/null

        if [ $? -eq 0 ]; then
            echo "‚úì Restauration test r√©ussie" | tee -a $LOG_FILE
        else
            echo "‚úó Erreur de restauration" | tee -a $LOG_FILE
            return 1
        fi
    else
        echo "‚úó Archive corrompue : $backup_file" | tee -a $LOG_FILE
        return 1
    fi
}

# Test de toutes les sauvegardes r√©centes
for backup in $(find $BACKUP_DIR -name "*.tar.gz" -mtime -7); do
    validate_backup $backup $(basename $backup)
done
```

### Tests de r√©cup√©ration applicative

**Test de base de donn√©es :**

```bash
#!/bin/bash
# Test de restauration MySQL

DB_BACKUP="/backup/mysql/dump-$(date +%Y%m%d).sql"
TEST_DB="test_restore_$(date +%s)"

# Cr√©ation d'une base de test
mysql -e "CREATE DATABASE $TEST_DB;"

# Import du dump
if mysql $TEST_DB < $DB_BACKUP; then
    echo "‚úì Restauration MySQL r√©ussie"

    # V√©rification de la coh√©rence
    TABLES_COUNT=$(mysql -sN -e "SELECT COUNT(*) FROM information_schema.tables WHERE table_schema='$TEST_DB';")
    echo "Tables restaur√©es : $TABLES_COUNT"

    # Nettoyage
    mysql -e "DROP DATABASE $TEST_DB;"
else
    echo "‚úó Erreur de restauration MySQL"
    exit 1
fi
```

### Monitoring des sauvegardes

**Dashboard Prometheus/Grafana :**

```yaml
# M√©triques custom pour les sauvegardes
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-metrics
data:
  backup-metrics.sh: |
    #!/bin/bash
    # Exposition de m√©triques pour Prometheus

    METRICS_FILE="/tmp/backup-metrics.prom"

    # Derni√®re sauvegarde r√©ussie
    LAST_BACKUP=$(find /backup -name "*.tar.gz" -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f1)
    echo "backup_last_success_timestamp $LAST_BACKUP" > $METRICS_FILE

    # Taille des sauvegardes
    BACKUP_SIZE=$(du -sb /backup | cut -f1)
    echo "backup_total_size_bytes $BACKUP_SIZE" >> $METRICS_FILE

    # Nombre de sauvegardes
    BACKUP_COUNT=$(find /backup -name "*.tar.gz" | wc -l)
    echo "backup_files_total $BACKUP_COUNT" >> $METRICS_FILE
```

---

## 12.1.7 Calcul RTO/RPO et strat√©gies 3-2-1

### D√©finition des objectifs

**RTO (Recovery Time Objective) :**
- Temps maximum acceptable pour restaurer le service
- Inclut : d√©tection, d√©cision, restauration, validation
- Exemple : "L'application doit √™tre restaur√©e en moins de 4 heures"

**RPO (Recovery Point Objective) :**
- Perte de donn√©es maximum acceptable
- D√©termine la fr√©quence des sauvegardes
- Exemple : "Perte maximum de 1 heure de donn√©es"

### Calcul et planification

```bash
# Exemple de calcul de temps de restauration
#!/bin/bash

# Param√®tres de l'infrastructure
BACKUP_SIZE_GB=500
NETWORK_SPEED_MBPS=100
RESTORE_RATE_MBPS=80

# Calculs
TRANSFER_TIME_MIN=$((BACKUP_SIZE_GB * 8 * 1024 / NETWORK_SPEED_MBPS / 60))
RESTORE_TIME_MIN=$((BACKUP_SIZE_GB * 8 * 1024 / RESTORE_RATE_MBPS / 60))
VALIDATION_TIME_MIN=30

TOTAL_RTO_MIN=$((TRANSFER_TIME_MIN + RESTORE_TIME_MIN + VALIDATION_TIME_MIN))

echo "Temps de transfert estim√© : ${TRANSFER_TIME_MIN} minutes"
echo "Temps de restauration estim√© : ${RESTORE_TIME_MIN} minutes"
echo "RTO total estim√© : ${TOTAL_RTO_MIN} minutes (${TOTAL_RTO_MIN}/60 heures)"
```

### Strat√©gie 3-2-1

La r√®gle 3-2-1 est un standard de l'industrie :

- **3 copies** des donn√©es importantes
- **2 supports diff√©rents** (disque local + cloud, par exemple)
- **1 copie hors site** (g√©ographiquement distante)

**Impl√©mentation pratique :**

```bash
#!/bin/bash
# Impl√©mentation de la strat√©gie 3-2-1

SOURCE_DATA="/production/data"
DATE=$(date +%Y%m%d)

# Copie 1 : Backup local (disque diff√©rent)
LOCAL_BACKUP="/backup/local/backup-${DATE}"
rsync -av $SOURCE_DATA/ $LOCAL_BACKUP/

# Copie 2 : Backup sur serveur de backup (r√©seau local)
NETWORK_BACKUP="backup-server:/backup/network/backup-${DATE}"
rsync -av $SOURCE_DATA/ $NETWORK_BACKUP/

# Copie 3 : Backup cloud (hors site)
tar -czf backup-${DATE}.tar.gz -C $(dirname $SOURCE_DATA) $(basename $SOURCE_DATA)
rclone copy backup-${DATE}.tar.gz aws-s3:offsite-backups/$(date +%Y/%m)/

echo "Strat√©gie 3-2-1 impl√©ment√©e :"
echo "- Local : $LOCAL_BACKUP"
echo "- R√©seau : $NETWORK_BACKUP"
echo "- Cloud : aws-s3:offsite-backups/$(date +%Y/%m)/backup-${DATE}.tar.gz"

# Nettoyage du fichier temporaire
rm backup-${DATE}.tar.gz
```

### Matrice de strat√©gies par criticit√©

| Criticit√© | RPO | RTO | Fr√©quence | Type | Localisation |
|-----------|-----|-----|-----------|------|--------------|
| Critique | 15 min | 1h | Continue | R√©plication | Multi-zone |
| Important | 4h | 4h | 4x/jour | Snapshot | Local + Cloud |
| Standard | 24h | 24h | Quotidien | Fichier | Local + Remote |
| Archive | 1 semaine | 72h | Hebdomadaire | Tape/Glacier | Hors site |

### Optimisation des co√ªts

**Lifecycle policies pour le stockage cloud :**

```yaml
# Politique de cycle de vie AWS S3
{
  "Rules": [
    {
      "ID": "backup-lifecycle",
      "Status": "Enabled",
      "Filter": {"Prefix": "backups/"},
      "Transitions": [
        {
          "Days": 30,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        },
        {
          "Days": 365,
          "StorageClass": "DEEP_ARCHIVE"
        }
      ],
      "Expiration": {
        "Days": 2555  # 7 ans de r√©tention
      }
    }
  ]
}
```

---

## Conclusion

Les strat√©gies de sauvegarde cloud-native n√©cessitent une approche multicouche combinant outils traditionnels et solutions modernes. La cl√© du succ√®s r√©side dans :

1. **L'adaptation aux besoins** : Choisir la strat√©gie selon la criticit√© des donn√©es
2. **L'automatisation** : R√©duire les erreurs humaines et garantir la r√©gularit√©
3. **La validation continue** : Tester r√©guli√®rement les proc√©dures de restauration
4. **L'optimisation** : √âquilibrer co√ªt, performance et niveau de protection

Cette approche hybride permet de r√©pondre aux exigences modernes tout en conservant la robustesse des m√©thodes √©prouv√©es.

‚è≠Ô∏è
