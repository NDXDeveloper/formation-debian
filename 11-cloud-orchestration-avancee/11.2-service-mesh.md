üîù Retour au [Sommaire](/SOMMAIRE.md)

# 11.2 Service Mesh

## Introduction au Service Mesh

### Qu'est-ce qu'un Service Mesh ?

Un **Service Mesh** (maillage de services) est une infrastructure d√©di√©e qui g√®re la communication entre les microservices dans une application distribu√©e. Imaginez-le comme un "syst√®me nerveux" pour vos applications : il connecte, s√©curise et surveille toutes les communications entre vos services.

### Pourquoi avons-nous besoin d'un Service Mesh ?

Dans une architecture traditionnelle **monolithique**, vous avez une seule grande application. Toutes les parties communiquent directement entre elles √† l'int√©rieur du m√™me processus.

Avec les **microservices**, vous avez de nombreuses petites applications qui doivent communiquer via le r√©seau. Cela cr√©e de nouveaux d√©fis :

- **S√©curit√©** : Comment s'assurer que seuls les services autoris√©s communiquent ?
- **Observabilit√©** : Comment voir ce qui se passe entre tous ces services ?
- **Fiabilit√©** : Comment g√©rer les pannes et les retry automatiques ?
- **Performance** : Comment √©quilibrer la charge et optimiser le routage ?

### Les composants d'un Service Mesh

Un Service Mesh est compos√© de deux parties principales :

1. **Data Plane** (Plan de donn√©es) :
   - Des **proxies** (souvent appel√©s "sidecars") d√©ploy√©s √† c√¥t√© de chaque service
   - Ils interceptent tout le trafic r√©seau entrant et sortant
   - Exemples : Envoy Proxy, Linkerd2-proxy

2. **Control Plane** (Plan de contr√¥le) :
   - Le "cerveau" qui configure et manage tous les proxies
   - Fournit les politiques de s√©curit√©, de routage, etc.
   - Interface utilisateur pour la configuration et le monitoring

### Avantages du Service Mesh

- **S√©curit√©** : Chiffrement automatique (mTLS) entre tous les services
- **Observabilit√©** : M√©triques, logs et traces automatiques
- **Gestion du trafic** : Load balancing, circuit breakers, retry policies
- **D√©ploiements avanc√©s** : Blue/green, canary deployments
- **Isolation** : Politiques de s√©curit√© granulaires

---

## 11.2.1 Istio installation et configuration

### Qu'est-ce qu'Istio ?

**Istio** est le service mesh le plus populaire et le plus complet. D√©velopp√© par Google, IBM et Lyft, il utilise Envoy Proxy comme data plane et fournit un control plane riche en fonctionnalit√©s.

### Architecture d'Istio

Istio se compose de plusieurs composants :

- **Envoy Proxy** : Le sidecar proxy inject√© dans chaque pod
- **Istiod** : Le control plane unifi√© qui g√®re la configuration
- **Ingress Gateway** : Point d'entr√©e pour le trafic externe
- **Egress Gateway** : Point de sortie pour le trafic vers l'ext√©rieur

### Pr√©requis

Avant d'installer Istio, vous devez avoir :
- Un cluster Kubernetes fonctionnel
- kubectl configur√© et connect√© √† votre cluster
- Au moins 4 GB de RAM disponible dans le cluster
- Permissions administrateur sur le cluster

### Installation d'Istio

#### √âtape 1 : T√©l√©charger Istio

```bash
# T√©l√©charger la derni√®re version stable d'Istio
curl -L https://istio.io/downloadIstio | sh -

# Aller dans le r√©pertoire d'Istio
cd istio-*

# Ajouter istioctl au PATH
export PATH=$PWD/bin:$PATH

# V√©rifier l'installation
istioctl version
```

#### √âtape 2 : V√©rification des pr√©requis

```bash
# V√©rifier que votre cluster est compatible
istioctl x precheck
```

#### √âtape 3 : Installation du control plane

```bash
# Installation avec le profil par d√©faut
istioctl install --set values.defaultRevision=default

# Ou installation avec un profil sp√©cifique
# istioctl install --set values.defaultRevision=default --set values.pilot.env.EXTERNAL_ISTIOD=false
```

#### √âtape 4 : Activer l'injection automatique des sidecars

```bash
# Marquer un namespace pour l'injection automatique
kubectl label namespace default istio-injection=enabled

# V√©rifier le label
kubectl get namespace -L istio-injection
```

### Configuration de base d'Istio

#### D√©ploiement d'une application de test

```bash
# D√©ployer l'application exemple Bookinfo
kubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml

# V√©rifier le d√©ploiement
kubectl get services
kubectl get pods

# V√©rifier que les sidecars Envoy sont inject√©s
kubectl get pods -o jsonpath='{.items[*].spec.containers[*].name}'
```

#### Configuration de l'Ingress Gateway

```bash
# D√©ployer la gateway
kubectl apply -f samples/bookinfo/networking/bookinfo-gateway.yaml

# Obtenir l'IP externe de la gateway
kubectl get svc istio-ingressgateway -n istio-system

# D√©finir les variables d'environnement pour acc√©der √† l'application
export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath='{.spec.ports[?(@.name=="http2")].port}')
export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT

# Tester l'acc√®s
curl -s "http://${GATEWAY_URL}/productpage" | grep -o "<title>.*</title>"
```

#### Configuration des r√®gles de routage

Exemple de configuration pour diriger le trafic :

```yaml
# destination-rule.yaml
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: productpage
spec:
  host: productpage
  subsets:
  - name: v1
    labels:
      version: v1
---
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: productpage
spec:
  http:
  - match:
    - headers:
        end-user:
          exact: jason
    route:
    - destination:
        host: productpage
        subset: v1
  - route:
    - destination:
        host: productpage
        subset: v1
```

### Fonctionnalit√©s avanc√©es d'Istio

#### S√©curit√© avec mTLS

```bash
# Activer mTLS strict pour tout le cluster
kubectl apply -f - <<EOF
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: istio-system
spec:
  mtls:
    mode: STRICT
EOF
```

#### Politiques d'autorisation

```yaml
# authorization-policy.yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: allow-nothing
  namespace: default
spec: {}
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: productpage-viewer
  namespace: default
spec:
  selector:
    matchLabels:
      app: productpage
  action: ALLOW
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/default/sa/bookinfo-productpage"]
```

---

## 11.2.2 Linkerd sur Kubernetes

### Qu'est-ce que Linkerd ?

**Linkerd** est un service mesh ultral√©ger et haute performance, con√ßu pour √™tre simple √† utiliser et √† op√©rer. Contrairement √† Istio, Linkerd se concentre sur la simplicit√© et les performances.

### Avantages de Linkerd

- **Simplicit√©** : Installation et configuration tr√®s faciles
- **Performance** : Proxy Rust ultrarapide et faible latence
- **S√©curit√©** : mTLS automatique par d√©faut
- **Observabilit√©** : M√©triques et dashboards int√©gr√©s
- **Stabilit√©** : Moins de composants = moins de points de d√©faillance

### Installation de Linkerd

#### √âtape 1 : Installation du CLI

```bash
# T√©l√©charger et installer linkerd CLI
curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh

# Ajouter au PATH
export PATH=$PATH:$HOME/.linkerd2/bin

# V√©rifier l'installation
linkerd version
```

#### √âtape 2 : Validation des pr√©requis

```bash
# V√©rifier que Kubernetes est pr√™t pour Linkerd
linkerd check --pre
```

#### √âtape 3 : Installation du control plane

```bash
# G√©n√©rer les certificats et installer Linkerd
linkerd install --crds | kubectl apply -f -
linkerd install | kubectl apply -f -

# V√©rifier l'installation
linkerd check
```

#### √âtape 4 : Installation du dashboard (optionnel)

```bash
# Installer l'extension viz pour les m√©triques et le dashboard
linkerd viz install | kubectl apply -f -

# V√©rifier l'installation de viz
linkerd check --proxy
```

### Utilisation de Linkerd

#### Injection des proxies

```bash
# M√©thode 1 : Injection manuelle pour un d√©ploiement
kubectl get deploy -o yaml | linkerd inject - | kubectl apply -f -

# M√©thode 2 : Injection automatique avec annotation
kubectl annotate namespace default linkerd.io/inject=enabled

# V√©rifier l'injection
kubectl get pods -o jsonpath='{.items[*].metadata.annotations.linkerd\.io/inject}'
```

#### Acc√®s au dashboard

```bash
# Lancer le dashboard Linkerd
linkerd viz dashboard

# Ou obtenir les m√©triques en ligne de commande
linkerd viz stat deployments
linkerd viz top deployments
linkerd viz routes deployments
```

### Configuration avanc√©e de Linkerd

#### Traffic splitting (r√©partition de trafic)

```yaml
# traffic-split.yaml
apiVersion: split.smi-spec.io/v1alpha1
kind: TrafficSplit
metadata:
  name: webapp-split
  namespace: default
spec:
  service: webapp
  backends:
  - service: webapp-v1
    weight: 80
  - service: webapp-v2
    weight: 20
```

#### Politiques de retry

```yaml
# retry-policy.yaml
apiVersion: policy.linkerd.io/v1beta1
kind: HTTPRoute
metadata:
  name: webapp-retry
  namespace: default
spec:
  parentRefs:
  - name: webapp
    kind: Service
  rules:
  - backendRefs:
    - name: webapp
      port: 80
    timeouts:
      request: 10s
    retry:
      maxRetries: 3
      backoff:
        baseInterval: 1s
        maxInterval: 10s
```

---

## 11.2.3 Consul Connect

### Qu'est-ce que Consul Connect ?

**Consul Connect** est la fonctionnalit√© service mesh de HashiCorp Consul. Consul est d'abord un outil de service discovery, mais Connect ajoute les capacit√©s de service mesh avec un focus sur la simplicit√© et l'int√©gration multi-plateformes.

### Avantages de Consul Connect

- **Multi-plateforme** : Fonctionne sur Kubernetes, VMs, et conteneurs
- **Service Discovery** : Int√©gr√© avec le service discovery de Consul
- **Simplicit√©** : Configuration d√©clarative simple
- **Flexibilit√©** : Support de diff√©rents proxies (Envoy, builtin)
- **Int√©gration** : S'int√®gre bien avec l'√©cosyst√®me HashiCorp

### Installation de Consul avec Connect

#### M√©thode 1 : Installation via Helm

```bash
# Ajouter le repo Helm HashiCorp
helm repo add hashicorp https://helm.releases.hashicorp.com
helm repo update

# Cr√©er un fichier de valeurs pour Consul
cat > consul-values.yaml <<EOF
global:
  name: consul
  datacenter: dc1

server:
  replicas: 3
  storage: 10Gi

connectInject:
  enabled: true
  default: true

controller:
  enabled: true

ui:
  enabled: true
  service:
    type: LoadBalancer
EOF

# Installer Consul
helm install consul hashicorp/consul -f consul-values.yaml
```

#### M√©thode 2 : Installation manuelle

```bash
# T√©l√©charger Consul
wget https://releases.hashicorp.com/consul/1.16.1/consul_1.16.1_linux_amd64.zip
unzip consul_1.16.1_linux_amd64.zip
sudo mv consul /usr/local/bin/

# Cr√©er un utilisateur consul
sudo useradd --system --home /etc/consul.d --shell /bin/false consul

# Cr√©er les r√©pertoires
sudo mkdir -p /opt/consul /etc/consul.d
sudo chown -R consul:consul /opt/consul /etc/consul.d
```

### Configuration de Consul Connect

#### Configuration de base du serveur

```json
// /etc/consul.d/consul.json
{
  "datacenter": "dc1",
  "data_dir": "/opt/consul",
  "log_level": "INFO",
  "server": true,
  "bootstrap_expect": 1,
  "bind_addr": "0.0.0.0",
  "client_addr": "0.0.0.0",
  "retry_join": ["consul-server"],
  "ui_config": {
    "enabled": true
  },
  "connect": {
    "enabled": true
  },
  "ports": {
    "grpc": 8502
  }
}
```

#### Enregistrement d'un service avec Connect

```json
// /etc/consul.d/web-service.json
{
  "service": {
    "name": "web",
    "port": 8080,
    "connect": {
      "sidecar_service": {
        "proxy": {
          "upstreams": [
            {
              "destination_name": "database",
              "local_bind_port": 5432
            }
          ]
        }
      }
    }
  }
}
```

### Utilisation de Consul Connect sur Kubernetes

#### D√©ploiement d'une application avec Connect

```yaml
# web-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: web
  template:
    metadata:
      labels:
        app: web
      annotations:
        'consul.hashicorp.com/connect-inject': 'true'
        'consul.hashicorp.com/connect-service-upstreams': 'database:5432'
    spec:
      containers:
      - name: web
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: web
spec:
  selector:
    app: web
  ports:
  - port: 80
    targetPort: 80
```

#### Configuration des intentions (politiques de s√©curit√©)

```yaml
# web-to-database-intention.yaml
apiVersion: consul.hashicorp.com/v1alpha1
kind: ServiceIntentions
metadata:
  name: web-to-database
spec:
  destination:
    name: database
  sources:
  - name: web
    action: allow
```

### Monitoring avec Consul Connect

#### M√©triques avec Prometheus

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
    - job_name: 'consul-connect'
      consul_sd_configs:
      - server: 'consul-server:8500'
        services: []
      relabel_configs:
      - source_labels: [__meta_consul_service]
        target_label: service
      - source_labels: [__meta_consul_service_metadata_prometheus_port]
        target_label: __address__
        regex: (.+)
        replacement: ${1}
```

---

## 11.2.4 Observabilit√© et s√©curit√©

### L'observabilit√© dans un Service Mesh

L'**observabilit√©** est la capacit√© √† comprendre l'√©tat interne d'un syst√®me en examinant ses sorties externes. Dans un service mesh, cela inclut trois piliers principaux :

1. **M√©triques** : Donn√©es num√©riques sur les performances
2. **Logs** : Enregistrements d√©taill√©s des √©v√©nements
3. **Traces** : Suivi des requ√™tes √† travers tous les services

### M√©triques dans un Service Mesh

#### Types de m√©triques importantes

- **M√©triques de trafic** :
  - Requests per second (RPS)
  - Latence (p50, p95, p99)
  - Taux d'erreur
  - Volume de donn√©es

- **M√©triques de s√©curit√©** :
  - Connexions mTLS r√©ussies/√©chou√©es
  - Violations de politiques d'autorisation
  - Tentatives d'acc√®s non autoris√©es

- **M√©triques d'infrastructure** :
  - Utilisation CPU/m√©moire des proxies
  - Nombre de connexions actives
  - Taille des files d'attente

#### Configuration des m√©triques avec Prometheus

```yaml
# prometheus-istio.yaml
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: istio-system
spec:
  selector:
    app: prometheus
  ports:
  - port: 9090
    targetPort: 9090
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: istio-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      containers:
      - name: prometheus
        image: prom/prometheus:latest
        ports:
        - containerPort: 9090
        volumeMounts:
        - name: config
          mountPath: /etc/prometheus
        args:
        - '--config.file=/etc/prometheus/prometheus.yml'
        - '--storage.tsdb.path=/prometheus'
        - '--web.console.libraries=/usr/share/prometheus/console_libraries'
        - '--web.console.templates=/usr/share/prometheus/consoles'
      volumes:
      - name: config
        configMap:
          name: prometheus-config
```

### Logging dans un Service Mesh

#### Configuration des logs Envoy

```yaml
# envoy-access-logs.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: istio
  namespace: istio-system
data:
  mesh: |
    defaultConfig:
      proxyStatsMatcher:
        inclusionRegexps:
        - ".*circuit_breakers.*"
        - ".*upstream_rq_retry.*"
        - ".*_cx_.*"
      accessLogFile: /dev/stdout
      accessLogFormat: |
        [%START_TIME%] "%REQ(:METHOD)% %REQ(X-ENVOY-ORIGINAL-PATH?:PATH)% %PROTOCOL%"
        %RESPONSE_CODE% %RESPONSE_FLAGS% "%UPSTREAM_SERVICE_TIME%"
        "%REQ(X-FORWARDED-FOR)%" "%REQ(USER-AGENT)%" "%REQ(X-REQUEST-ID)%"
        "%REQ(:AUTHORITY)%" "%UPSTREAM_HOST%"
```

#### Agr√©gation des logs avec Fluentd

```yaml
# fluentd-daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENTD_SYSTEMD_CONF
          value: disable
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```

### Tracing distribu√©

#### Configuration de Jaeger avec Istio

```bash
# Installation de Jaeger
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.19/samples/addons/jaeger.yaml

# Activation du tracing
kubectl apply -f - <<EOF
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: istio-control-plane
spec:
  values:
    meshConfig:
      defaultConfig:
        tracing:
          sampling: 100.0
      extensionProviders:
      - name: jaeger
        envoyExtAuthzHttp:
          service: jaeger-collector.istio-system.svc.cluster.local
          port: 14268
          pathPrefix: /api/traces
EOF
```

#### Configuration du sampling

```yaml
# telemetry-v2.yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: control-plane
spec:
  values:
    telemetry:
      v2:
        prometheus:
          configOverride:
            disable_host_header_fallback: true
            metric_relabeling_configs:
            - source_labels: [__name__]
              regex: istio_build
              action: drop
        stackdriver:
          configOverride:
            enable_logging: true
            logging:
              sampling_rate: 1.0
```

### S√©curit√© dans un Service Mesh

#### mTLS (Mutual TLS) automatique

Le mTLS chiffre automatiquement toutes les communications entre services et v√©rifie leur identit√©.

```yaml
# strict-mtls.yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: istio-system
spec:
  mtls:
    mode: STRICT
```

#### Politiques d'autorisation granulaires

```yaml
# authorization-policy-example.yaml
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: frontend-access
  namespace: production
spec:
  selector:
    matchLabels:
      app: frontend
  action: ALLOW
  rules:
  - from:
    - source:
        namespaces: ["production"]
  - to:
    - operation:
        methods: ["GET", "POST"]
        paths: ["/api/*"]
  - when:
    - key: request.headers[user-agent]
      values: ["Mozilla/*", "Chrome/*"]
```

#### Politiques de s√©curit√© r√©seau

```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
  namespace: production
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-frontend-to-backend
  namespace: production
spec:
  podSelector:
    matchLabels:
      app: backend
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: frontend
    ports:
    - protocol: TCP
      port: 8080
```

### Monitoring de s√©curit√©

#### D√©tection d'anomalies

```yaml
# security-monitoring.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: security-rules
  namespace: istio-system
data:
  rules.yml: |
    groups:
    - name: istio-security
      rules:
      - alert: HighErrorRate
        expr: sum(rate(istio_requests_total{response_code!~"2.."}[5m])) > 0.1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is above 10% for 5 minutes"

      - alert: UnauthorizedAccess
        expr: sum(rate(istio_requests_total{response_code="403"}[5m])) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Unauthorized access attempts"
          description: "HTTP 403 responses detected"

      - alert: MTLSFailure
        expr: sum(rate(istio_requests_total{source_app="unknown"}[5m])) > 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "mTLS authentication failure"
          description: "Requests from unknown sources detected"
```

### Dashboard et visualisation

#### Configuration de Grafana pour service mesh

```yaml
# grafana-dashboard.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: istio-dashboard
  namespace: istio-system
data:
  dashboard.json: |
    {
      "dashboard": {
        "title": "Istio Service Mesh Dashboard",
        "panels": [
          {
            "title": "Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(rate(istio_requests_total[5m])) by (destination_service_name)",
                "legendFormat": "{{destination_service_name}}"
              }
            ]
          },
          {
            "title": "Error Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(rate(istio_requests_total{response_code!~\"2..\"}[5m])) by (destination_service_name) / sum(rate(istio_requests_total[5m])) by (destination_service_name)",
                "legendFormat": "{{destination_service_name}}"
              }
            ]
          },
          {
            "title": "Response Time",
            "type": "graph",
            "targets": [
              {
                "expr": "histogram_quantile(0.99, sum(rate(istio_request_duration_milliseconds_bucket[5m])) by (destination_service_name, le))",
                "legendFormat": "{{destination_service_name}} p99"
              }
            ]
          }
        ]
      }
    }
```

### Bonnes pratiques de s√©curit√©

1. **Principe du moindre privil√®ge** :
   - Autorisez uniquement les communications n√©cessaires
   - Utilisez des politiques d'autorisation granulaires
   - S√©parez les environnements par namespace

2. **Defense in depth** :
   - Combinez service mesh avec network policies
   - Utilisez plusieurs couches de s√©curit√©
   - Impl√©mentez le scanning des images de conteneurs

3. **Monitoring continu** :
   - Surveillez les m√©triques de s√©curit√© en temps r√©el
   - Configurez des alertes pour les comportements anormaux
   - Auditez r√©guli√®rement les acc√®s et permissions

4. **Gestion des certificats** :
   - Utilisez la rotation automatique des certificats
   - Surveillez l'expiration des certificats
   - Impl√©mentez une PKI robuste

---

Cette section vous a donn√© une vue d'ensemble compl√®te des service mesh et de leur impl√©mentation. Dans la section suivante, nous explorerons le monitoring cloud-native qui s'appuie sur les capacit√©s d'observabilit√© que nous venons de voir.

‚è≠Ô∏è
