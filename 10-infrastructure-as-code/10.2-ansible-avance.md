üîù Retour au [Sommaire](/SOMMAIRE.md)

# 10.2 Ansible avanc√©

## Introduction √† Ansible avanc√©

Ansible est un outil d'automatisation puissant qui utilise une approche d√©clarative pour g√©rer la configuration des syst√®mes. Contrairement √† d'autres outils, Ansible est **agentless** (sans agent), ce qui signifie qu'il n'a besoin d'aucun logiciel sp√©cial install√© sur les machines cibles - il utilise simplement SSH pour se connecter et ex√©cuter les t√¢ches.

Dans cette section avanc√©e, nous explorons comment utiliser Ansible pour des t√¢ches complexes incluant la gestion d'infrastructures Kubernetes, l'int√©gration cloud, et l'utilisation d'outils d'entreprise comme AWX/Tower.

### Rappel des concepts de base

**Playbook :** Un fichier YAML qui d√©finit les t√¢ches √† ex√©cuter sur les h√¥tes cibles.

**Inventory :** Liste des machines sur lesquelles Ansible va op√©rer.

**Module :** Unit√© de travail dans Ansible (copie de fichier, installation de paquet, etc.).

**Role :** Organisation r√©utilisable de playbooks, variables, fichiers et templates.

**Facts :** Informations automatiquement collect√©es sur les syst√®mes cibles.

## 10.2.1 Ansible sur Debian

### Installation d'Ansible sur Debian

#### Installation via les d√©p√¥ts officiels

```bash
# Mise √† jour des paquets
sudo apt update

# Installation d'Ansible
sudo apt install ansible

# V√©rification de l'installation
ansible --version
```

#### Installation via pip (version plus r√©cente)

```bash
# Installation de pip si n√©cessaire
sudo apt install python3-pip python3-venv

# Cr√©ation d'un environnement virtuel (recommand√©)
python3 -m venv ansible-env
source ansible-env/bin/activate

# Installation d'Ansible via pip
pip install ansible

# V√©rification
ansible --version
```

#### Installation via le PPA Ansible (derni√®re version)

```bash
# Ajout du PPA Ansible
sudo apt update
sudo apt install software-properties-common
sudo add-apt-repository --yes --update ppa:ansible/ansible

# Installation
sudo apt install ansible

# V√©rification
ansible --version
```

### Configuration initiale d'Ansible

#### Fichier de configuration ansible.cfg

Ansible recherche sa configuration dans plusieurs emplacements, dans cet ordre :
1. `ANSIBLE_CONFIG` (variable d'environnement)
2. `ansible.cfg` (dans le r√©pertoire courant)
3. `~/.ansible.cfg` (dans le r√©pertoire home)
4. `/etc/ansible/ansible.cfg` (syst√®me)

```ini
# ansible.cfg

[defaults]
# Fichier d'inventaire par d√©faut
inventory = ./inventory/hosts.yml

# Utilisateur SSH par d√©faut
remote_user = debian

# Cl√© SSH priv√©e
private_key_file = ~/.ssh/id_rsa

# D√©sactiver la v√©rification des cl√©s d'h√¥te SSH (attention en production)
host_key_checking = False

# R√©pertoire des r√¥les
roles_path = ./roles:~/.ansible/roles:/etc/ansible/roles

# Fichier de log
log_path = ./ansible.log

# Parall√©lisme (nombre de t√¢ches simultan√©es)
forks = 10

# Timeout SSH
timeout = 30

# Collecte des facts
gathering = smart
fact_caching = jsonfile
fact_caching_connection = ./facts_cache
fact_caching_timeout = 86400

# Format de sortie
stdout_callback = yaml
bin_ansible_callbacks = True

[inventory]
# Activer les plugins d'inventaire
enable_plugins = yaml, ini, auto

[privilege_escalation]
# Configuration sudo
become = True
become_method = sudo
become_user = root
become_ask_pass = False

[ssh_connection]
# Configuration SSH
ssh_args = -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
control_path_dir = ~/.ansible/cp
control_path = %(directory)s/%%h-%%p-%%r
pipelining = True
```

#### Structure d'un projet Ansible

```
ansible-project/
‚îú‚îÄ‚îÄ ansible.cfg                 # Configuration Ansible
‚îú‚îÄ‚îÄ inventory/                  # Inventaires
‚îÇ   ‚îú‚îÄ‚îÄ hosts.yml              # Inventaire principal
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hosts.yml          # Inventaire d√©veloppement
‚îÇ   ‚îî‚îÄ‚îÄ prod/
‚îÇ       ‚îî‚îÄ‚îÄ hosts.yml          # Inventaire production
‚îú‚îÄ‚îÄ group_vars/                # Variables par groupe
‚îÇ   ‚îú‚îÄ‚îÄ all.yml               # Variables globales
‚îÇ   ‚îú‚îÄ‚îÄ webservers.yml        # Variables pour les serveurs web
‚îÇ   ‚îî‚îÄ‚îÄ databases.yml         # Variables pour les bases de donn√©es
‚îú‚îÄ‚îÄ host_vars/                # Variables par h√¥te
‚îÇ   ‚îú‚îÄ‚îÄ web01.yml
‚îÇ   ‚îî‚îÄ‚îÄ db01.yml
‚îú‚îÄ‚îÄ roles/                    # R√¥les personnalis√©s
‚îÇ   ‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îú‚îÄ‚îÄ webserver/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îú‚îÄ‚îÄ playbooks/               # Playbooks
‚îÇ   ‚îú‚îÄ‚îÄ site.yml            # Playbook principal
‚îÇ   ‚îú‚îÄ‚îÄ webservers.yml      # Playbook serveurs web
‚îÇ   ‚îî‚îÄ‚îÄ databases.yml       # Playbook bases de donn√©es
‚îú‚îÄ‚îÄ files/                  # Fichiers statiques
‚îú‚îÄ‚îÄ templates/              # Templates Jinja2
‚îú‚îÄ‚îÄ vars/                   # Fichiers de variables
‚îî‚îÄ‚îÄ vault/                  # Fichiers chiffr√©s avec Ansible Vault
```

### Inventaire avanc√©

#### Inventaire YAML avec groupes et variables

```yaml
# inventory/hosts.yml

all:
  vars:
    ansible_user: debian
    ansible_ssh_private_key_file: ~/.ssh/id_rsa
    domain_name: example.com

  children:
    webservers:
      vars:
        http_port: 80
        https_port: 443
        nginx_version: latest
      hosts:
        web01:
          ansible_host: 192.168.1.10
          server_id: 1
        web02:
          ansible_host: 192.168.1.11
          server_id: 2
        web03:
          ansible_host: 192.168.1.12
          server_id: 3

    databases:
      vars:
        mysql_port: 3306
        mysql_root_password: "{{ vault_mysql_root_password }}"
      hosts:
        db01:
          ansible_host: 192.168.1.20
          mysql_server_id: 1
          mysql_role: master
        db02:
          ansible_host: 192.168.1.21
          mysql_server_id: 2
          mysql_role: slave

    loadbalancers:
      hosts:
        lb01:
          ansible_host: 192.168.1.5

    monitoring:
      hosts:
        monitor01:
          ansible_host: 192.168.1.30

    # Groupes de groupes
    production:
      children:
        webservers:
        databases:
        loadbalancers:

    backend:
      children:
        databases:

    frontend:
      children:
        webservers:
        loadbalancers:
```

#### Inventaire dynamique pour le cloud

```python
#!/usr/bin/env python3
# inventory/aws_inventory.py

import json
import boto3
from botocore.exceptions import ClientError

def get_aws_inventory():
    """G√©n√®re un inventaire dynamique depuis AWS EC2"""

    inventory = {
        '_meta': {
            'hostvars': {}
        },
        'all': {
            'children': ['ungrouped']
        },
        'ungrouped': {
            'hosts': []
        }
    }

    try:
        ec2 = boto3.client('ec2', region_name='eu-west-1')

        # R√©cup√©ration des instances EC2
        response = ec2.describe_instances(
            Filters=[
                {'Name': 'instance-state-name', 'Values': ['running']}
            ]
        )

        for reservation in response['Reservations']:
            for instance in reservation['Instances']:
                instance_id = instance['InstanceId']

                # Nom de l'instance depuis les tags
                instance_name = instance_id
                for tag in instance.get('Tags', []):
                    if tag['Key'] == 'Name':
                        instance_name = tag['Value']
                        break

                # Variables d'h√¥te
                hostvars = {
                    'ansible_host': instance.get('PublicIpAddress', instance.get('PrivateIpAddress')),
                    'ansible_user': 'ubuntu',  # ou 'ec2-user' selon l'AMI
                    'instance_id': instance_id,
                    'instance_type': instance['InstanceType'],
                    'availability_zone': instance['Placement']['AvailabilityZone'],
                    'private_ip': instance.get('PrivateIpAddress'),
                    'public_ip': instance.get('PublicIpAddress')
                }

                inventory['_meta']['hostvars'][instance_name] = hostvars
                inventory['ungrouped']['hosts'].append(instance_name)

                # Groupes bas√©s sur les tags
                for tag in instance.get('Tags', []):
                    if tag['Key'] == 'Environment':
                        group_name = f"env_{tag['Value']}"
                        if group_name not in inventory:
                            inventory[group_name] = {'hosts': []}
                        inventory[group_name]['hosts'].append(instance_name)

                    elif tag['Key'] == 'Role':
                        group_name = f"role_{tag['Value']}"
                        if group_name not in inventory:
                            inventory[group_name] = {'hosts': []}
                        inventory[group_name]['hosts'].append(instance_name)

    except ClientError as e:
        print(f"Erreur AWS: {e}")

    return inventory

if __name__ == '__main__':
    print(json.dumps(get_aws_inventory(), indent=2))
```

### Ansible Vault pour la s√©curit√©

#### Cr√©ation et gestion des secrets

```bash
# Cr√©ation d'un fichier chiffr√©
ansible-vault create vault/secrets.yml

# √âdition d'un fichier chiffr√©
ansible-vault edit vault/secrets.yml

# Chiffrement d'un fichier existant
ansible-vault encrypt vars/database.yml

# D√©chiffrement d'un fichier
ansible-vault decrypt vars/database.yml

# Affichage du contenu sans d√©chiffrer
ansible-vault view vault/secrets.yml

# Changement du mot de passe
ansible-vault rekey vault/secrets.yml
```

#### Utilisation avec des fichiers de mots de passe

```bash
# Stockage du mot de passe dans un fichier
echo 'mon_mot_de_passe_vault' > .vault_password

# Configuration dans ansible.cfg
echo 'vault_password_file = ./.vault_password' >> ansible.cfg

# Ou via variable d'environnement
export ANSIBLE_VAULT_PASSWORD_FILE=./.vault_password
```

#### Exemple de fichier chiffr√©

```yaml
# vault/secrets.yml (contenu chiffr√©)

$ANSIBLE_VAULT;1.1;AES256
66663433383862623039323739353766623364383963356264393835336634326439653035623730
3539323434336662346565643038343734656536656235300a386665356564656430373665306163
...
```

```yaml
# Contenu d√©chiffr√© pour r√©f√©rence (NE PAS stocker en clair)
vault_mysql_root_password: "super_secret_password"
vault_api_key: "api_key_secret"
vault_ssl_private_key: |
  -----BEGIN PRIVATE KEY-----
  MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQC...
  -----END PRIVATE KEY-----
```

### Playbooks avanc√©s pour Debian

#### Playbook de hardening syst√®me

```yaml
# playbooks/debian-hardening.yml

---
- name: Hardening syst√®me Debian
  hosts: all
  become: yes
  vars:
    ssh_port: 2222
    allowed_users: ['debian', 'admin']

  tasks:
    - name: Mise √† jour du syst√®me
      apt:
        update_cache: yes
        upgrade: dist
        autoremove: yes
        autoclean: yes
      register: apt_result

    - name: Red√©marrage si n√©cessaire
      reboot:
        reboot_timeout: 300
      when: apt_result.changed and ansible_facts['kernel'] not in ansible_facts['kernel_modules']

    - name: Installation des paquets de s√©curit√©
      apt:
        name:
          - fail2ban
          - ufw
          - unattended-upgrades
          - aide
          - rkhunter
          - chkrootkit
        state: present

    - name: Configuration SSH s√©curis√©e
      template:
        src: sshd_config.j2
        dest: /etc/ssh/sshd_config
        backup: yes
      notify: restart ssh

    - name: Configuration du firewall UFW
      ufw:
        rule: "{{ item.rule }}"
        port: "{{ item.port }}"
        proto: "{{ item.proto | default('tcp') }}"
        src: "{{ item.src | default('any') }}"
      loop:
        - { rule: 'allow', port: '{{ ssh_port }}', src: '192.168.0.0/16' }
        - { rule: 'allow', port: '80' }
        - { rule: 'allow', port: '443' }
      notify: enable ufw

    - name: Configuration de fail2ban
      template:
        src: jail.local.j2
        dest: /etc/fail2ban/jail.local
      notify: restart fail2ban

    - name: Configuration des mises √† jour automatiques
      template:
        src: 50unattended-upgrades.j2
        dest: /etc/apt/apt.conf.d/50unattended-upgrades

    - name: Suppression des paquets inutiles
      apt:
        name:
          - telnet
          - rsh-client
          - rsh-redone-client
        state: absent

    - name: Configuration des limites syst√®me
      template:
        src: limits.conf.j2
        dest: /etc/security/limits.conf

  handlers:
    - name: restart ssh
      service:
        name: ssh
        state: restarted

    - name: enable ufw
      ufw:
        state: enabled

    - name: restart fail2ban
      service:
        name: fail2ban
        state: restarted
```

#### Template SSH s√©curis√©

```jinja2
# templates/sshd_config.j2

# Configuration SSH s√©curis√©e pour {{ inventory_hostname }}
Port {{ ssh_port }}
Protocol 2

# Authentification
PermitRootLogin no
PasswordAuthentication no
ChallengeResponseAuthentication no
UsePAM yes

# Utilisateurs autoris√©s
{% for user in allowed_users %}
AllowUsers {{ user }}
{% endfor %}

# S√©curit√©
X11Forwarding no
ClientAliveInterval 300
ClientAliveCountMax 2
MaxAuthTries 3
MaxSessions 2

# Chiffrement
Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com
MACs hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com
KexAlgorithms curve25519-sha256@libssh.org,diffie-hellman-group16-sha512

# Subsyst√®mes
Subsystem sftp /usr/lib/openssh/sftp-server

# Logging
SyslogFacility AUTH
LogLevel INFO
```

## 10.2.2 Playbooks Kubernetes et cloud

### Gestion de Kubernetes avec Ansible

#### Installation du module Kubernetes

```bash
# Installation via pip
pip install kubernetes openshift

# Ou via les collections Ansible
ansible-galaxy collection install kubernetes.core
ansible-galaxy collection install community.kubernetes
```

#### Configuration et connexion √† Kubernetes

```yaml
# playbooks/k8s-setup.yml

---
- name: Configuration Kubernetes avec Ansible
  hosts: localhost
  connection: local
  vars:
    k8s_namespace: production
    app_name: webapp
    replicas: 3

  tasks:
    - name: V√©rification de la connexion au cluster
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Node
      register: cluster_nodes

    - name: Affichage des n≈ìuds du cluster
      debug:
        msg: "Cluster avec {{ cluster_nodes.resources | length }} n≈ìuds"

    - name: Cr√©ation du namespace
      kubernetes.core.k8s:
        name: "{{ k8s_namespace }}"
        api_version: v1
        kind: Namespace
        state: present

    - name: D√©ploiement de l'application
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: "{{ app_name }}"
            namespace: "{{ k8s_namespace }}"
            labels:
              app: "{{ app_name }}"
          spec:
            replicas: "{{ replicas }}"
            selector:
              matchLabels:
                app: "{{ app_name }}"
            template:
              metadata:
                labels:
                  app: "{{ app_name }}"
              spec:
                containers:
                - name: webapp
                  image: nginx:1.21
                  ports:
                  - containerPort: 80
                  resources:
                    requests:
                      memory: "64Mi"
                      cpu: "250m"
                    limits:
                      memory: "128Mi"
                      cpu: "500m"

    - name: Cr√©ation du service
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Service
          metadata:
            name: "{{ app_name }}-service"
            namespace: "{{ k8s_namespace }}"
          spec:
            selector:
              app: "{{ app_name }}"
            ports:
            - protocol: TCP
              port: 80
              targetPort: 80
            type: ClusterIP

    - name: Cr√©ation de l'Ingress
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: "{{ app_name }}-ingress"
            namespace: "{{ k8s_namespace }}"
            annotations:
              nginx.ingress.kubernetes.io/rewrite-target: /
          spec:
            rules:
            - host: "{{ app_name }}.{{ domain_name | default('example.com') }}"
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: "{{ app_name }}-service"
                      port:
                        number: 80
```

#### Gestion des ConfigMaps et Secrets

```yaml
# playbooks/k8s-configs.yml

---
- name: Gestion des configurations Kubernetes
  hosts: localhost
  connection: local
  vars:
    k8s_namespace: production

  tasks:
    - name: Cr√©ation de ConfigMap pour la configuration applicative
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: app-config
            namespace: "{{ k8s_namespace }}"
          data:
            database_host: "db.{{ k8s_namespace }}.svc.cluster.local"
            database_port: "5432"
            log_level: "INFO"
            max_connections: "100"

    - name: Cr√©ation de Secret pour les credentials
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: app-secrets
            namespace: "{{ k8s_namespace }}"
          type: Opaque
          data:
            database_password: "{{ vault_db_password | b64encode }}"
            api_key: "{{ vault_api_key | b64encode }}"
            jwt_secret: "{{ vault_jwt_secret | b64encode }}"

    - name: D√©ploiement avec configuration et secrets
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: configured-app
            namespace: "{{ k8s_namespace }}"
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: configured-app
            template:
              metadata:
                labels:
                  app: configured-app
              spec:
                containers:
                - name: app
                  image: myapp:latest
                  envFrom:
                  - configMapRef:
                      name: app-config
                  - secretRef:
                      name: app-secrets
                  volumeMounts:
                  - name: config-volume
                    mountPath: /etc/config
                volumes:
                - name: config-volume
                  configMap:
                    name: app-config
```

### Int√©gration cloud avec Ansible

#### Gestion d'infrastructure AWS

```yaml
# playbooks/aws-infrastructure.yml

---
- name: D√©ploiement infrastructure AWS
  hosts: localhost
  connection: local
  vars:
    aws_region: eu-west-1
    environment: production

  tasks:
    - name: Cr√©ation du VPC
      amazon.aws.ec2_vpc_net:
        name: "{{ environment }}-vpc"
        cidr_block: 10.0.0.0/16
        region: "{{ aws_region }}"
        tags:
          Environment: "{{ environment }}"
          Project: "MyApp"
        state: present
      register: vpc_result

    - name: Cr√©ation du subnet public
      amazon.aws.ec2_vpc_subnet:
        vpc_id: "{{ vpc_result.vpc.id }}"
        cidr: 10.0.1.0/24
        region: "{{ aws_region }}"
        map_public: yes
        tags:
          Name: "{{ environment }}-public-subnet"
          Type: public
        state: present
      register: public_subnet

    - name: Cr√©ation du subnet priv√©
      amazon.aws.ec2_vpc_subnet:
        vpc_id: "{{ vpc_result.vpc.id }}"
        cidr: 10.0.2.0/24
        region: "{{ aws_region }}"
        tags:
          Name: "{{ environment }}-private-subnet"
          Type: private
        state: present
      register: private_subnet

    - name: Cr√©ation Internet Gateway
      amazon.aws.ec2_vpc_igw:
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_region }}"
        tags:
          Name: "{{ environment }}-igw"
        state: present
      register: igw_result

    - name: Cr√©ation de la table de routage publique
      amazon.aws.ec2_vpc_route_table:
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_region }}"
        routes:
          - dest: 0.0.0.0/0
            gateway_id: "{{ igw_result.gateway_id }}"
        subnets:
          - "{{ public_subnet.subnet.id }}"
        tags:
          Name: "{{ environment }}-public-rt"

    - name: Cr√©ation du groupe de s√©curit√© web
      amazon.aws.ec2_security_group:
        name: "{{ environment }}-web-sg"
        description: Security group pour les serveurs web
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_region }}"
        rules:
          - proto: tcp
            ports:
              - 80
              - 443
            cidr_ip: 0.0.0.0/0
            rule_desc: HTTP/HTTPS access
          - proto: tcp
            ports:
              - 22
            cidr_ip: 10.0.0.0/16
            rule_desc: SSH access from VPC
        tags:
          Environment: "{{ environment }}"
      register: web_sg

    - name: Lancement des instances EC2
      amazon.aws.ec2_instance:
        name: "{{ environment }}-web-{{ item }}"
        image_id: ami-0d71ea30463e0ff8d  # Debian 12
        instance_type: t3.micro
        subnet_id: "{{ public_subnet.subnet.id }}"
        security_groups:
          - "{{ web_sg.group_id }}"
        key_name: my-key-pair
        wait: yes
        wait_timeout: 300
        tags:
          Environment: "{{ environment }}"
          Role: webserver
          Index: "{{ item }}"
      loop: [1, 2]
      register: ec2_instances

    - name: Attente de la disponibilit√© SSH
      wait_for:
        host: "{{ item.instances[0].public_ip_address }}"
        port: 22
        timeout: 300
      loop: "{{ ec2_instances.results }}"
```

#### Gestion Azure avec Ansible

```yaml
# playbooks/azure-resources.yml

---
- name: D√©ploiement de ressources Azure
  hosts: localhost
  connection: local
  vars:
    resource_group: rg-ansible-demo
    location: westeurope
    environment: dev

  tasks:
    - name: Cr√©ation du groupe de ressources
      azure.azcollection.azure_rm_resourcegroup:
        name: "{{ resource_group }}"
        location: "{{ location }}"
        tags:
          Environment: "{{ environment }}"
          ManagedBy: ansible

    - name: Cr√©ation du r√©seau virtuel
      azure.azcollection.azure_rm_virtualnetwork:
        resource_group: "{{ resource_group }}"
        name: vnet-ansible
        address_prefixes: ["10.0.0.0/16"]
        tags:
          Environment: "{{ environment }}"

    - name: Cr√©ation du sous-r√©seau
      azure.azcollection.azure_rm_subnet:
        resource_group: "{{ resource_group }}"
        virtual_network: vnet-ansible
        name: subnet-web
        address_prefix: "10.0.1.0/24"

    - name: Cr√©ation du groupe de s√©curit√© r√©seau
      azure.azcollection.azure_rm_securitygroup:
        resource_group: "{{ resource_group }}"
        name: nsg-web
        rules:
          - name: SSH
            protocol: Tcp
            destination_port_range: 22
            access: Allow
            priority: 1001
            direction: Inbound
          - name: HTTP
            protocol: Tcp
            destination_port_range: 80
            access: Allow
            priority: 1002
            direction: Inbound
        tags:
          Environment: "{{ environment }}"

    - name: Cr√©ation des IP publiques
      azure.azcollection.azure_rm_publicipaddress:
        resource_group: "{{ resource_group }}"
        name: "pip-web-{{ item }}"
        allocation_method: Static
        sku: Standard
        tags:
          Environment: "{{ environment }}"
      loop: [1, 2]

    - name: Cr√©ation des interfaces r√©seau
      azure.azcollection.azure_rm_networkinterface:
        resource_group: "{{ resource_group }}"
        name: "nic-web-{{ item }}"
        virtual_network: vnet-ansible
        subnet: subnet-web
        public_ip_name: "pip-web-{{ item }}"
        security_group: nsg-web
        tags:
          Environment: "{{ environment }}"
      loop: [1, 2]

    - name: Cr√©ation des machines virtuelles
      azure.azcollection.azure_rm_virtualmachine:
        resource_group: "{{ resource_group }}"
        name: "vm-web-{{ item }}"
        vm_size: Standard_B1s
        admin_username: azureuser
        ssh_password_enabled: false
        ssh_public_keys:
          - path: /home/azureuser/.ssh/authorized_keys
            key_data: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
        network_interfaces: "nic-web-{{ item }}"
        image:
          offer: debian-11
          publisher: debian
          sku: 11-gen2
          version: latest
        tags:
          Environment: "{{ environment }}"
          Role: webserver
      loop: [1, 2]
```

## 10.2.3 AWX/Tower

### Introduction √† AWX/Tower

**AWX** est la version open source d'**Ansible Tower** (maintenant **Red Hat Ansible Automation Platform**). C'est une interface web qui permet de g√©rer, planifier et ex√©cuter des playbooks Ansible de mani√®re centralis√©e et s√©curis√©e.

### Avantages d'AWX/Tower

**Interface graphique :** Interface web conviviale pour g√©rer les playbooks.

**Contr√¥le d'acc√®s :** Gestion fine des permissions et des r√¥les utilisateurs.

**Planification :** Ex√©cution programm√©e des t√¢ches d'automatisation.

**API REST :** Int√©gration avec d'autres syst√®mes via API.

**Audit :** Tra√ßabilit√© compl√®te des ex√©cutions et des changements.

**Workflow :** Cha√Ænage complexe de jobs avec conditions.

### Installation d'AWX sur Debian

#### Pr√©requis

```bash
# Installation de Docker et Docker Compose
sudo apt update
sudo apt install docker.io docker-compose-plugin git

# Ajout de l'utilisateur au groupe docker
sudo usermod -aG docker $USER

# Red√©marrage de la session ou logout/login
newgrp docker

# V√©rification
docker --version
docker compose version
```

#### Installation via Docker Compose

```bash
# Clone du repository AWX
git clone https://github.com/ansible/awx.git
cd awx

# Checkout de la derni√®re version stable
git checkout tags/$(git describe --tags --abbrev=0)

# G√©n√©ration des fichiers de configuration
make docker-compose

# Configuration personnalis√©e
cp tools/docker-compose/_sources/examples/credentials.py tools/docker-compose/credentials.py

# √âdition du fichier de credentials
nano tools/docker-compose/credentials.py
```

```python
# tools/docker-compose/credentials.py

# Mot de passe admin AWX
default_admin_password = 'admin_password_secure'

# Cl√© secr√®te (g√©n√©rez-en une unique)
import secrets
secret_key = secrets.token_urlsafe(50)

# Configuration de la base de donn√©es PostgreSQL
pg_password = 'postgresql_password_secure'
pg_username = 'awx'
pg_database = 'awx'
pg_port = 5432

# Configuration Redis
redis_password = 'redis_password_secure'

# Configuration du serveur de d√©veloppement
host_port = 8080
```

#### D√©marrage d'AWX

```bash
# Construction et d√©marrage des conteneurs
make docker-compose-build

# D√©marrage des services
make docker-compose

# V√©rification des conteneurs
docker ps

# Suivi des logs
docker compose -f tools/docker-compose/docker-compose.yml logs -f
```

#### Acc√®s √† l'interface AWX

Une fois les conteneurs d√©marr√©s, AWX est accessible √† l'adresse :
- URL : `http://localhost:8080`
- Utilisateur : `admin`
- Mot de passe : celui d√©fini dans `credentials.py`

### Configuration initiale d'AWX

#### Premi√®re connexion et configuration

1. **Acc√®s √† l'interface web**
   - Connectez-vous avec les credentials admin
   - Acceptez les termes d'utilisation si demand√©

2. **Configuration de la licence** (pour Tower uniquement)
   - AWX est gratuit et n'a pas besoin de licence
   - Tower n√©cessite une licence Red Hat

3. **Configuration des param√®tres syst√®me**
   ```
   Administration ‚Üí Settings ‚Üí System
   ```

#### Cr√©ation d'un projet

```yaml
# Configuration d'un projet dans AWX

Nom: Mon Premier Projet
Description: Projet de d√©monstration pour l'apprentissage AWX
Organisation: Default
SCM Type: Git
SCM URL: https://github.com/mon-compte/ansible-playbooks.git
SCM Branch/Tag/Commit: main
SCM Credential: (optionnel si repository public)
```

#### Configuration des inventaires

##### Inventaire statique

```yaml
# Dans AWX : Inventories ‚Üí Create Inventory

Nom: Production
Description: Serveurs de production
Organisation: Default
Type: Inventory

# Ajout d'h√¥tes
Host Name: web01.example.com
Variables:
  ansible_host: 192.168.1.10
  ansible_user: debian
  server_role: webserver

# Ajout de groupes
Group Name: webservers
Variables:
  http_port: 80
  https_port: 443
```

##### Inventaire dynamique

```python
# Custom inventory script pour AWX
#!/usr/bin/env python3

import json
import subprocess
import sys

def get_dynamic_inventory():
    """Script d'inventaire dynamique pour AWX"""

    inventory = {
        '_meta': {
            'hostvars': {}
        },
        'all': {
            'children': ['ungrouped']
        },
        'ungrouped': {
            'hosts': []
        }
    }

    # Exemple : r√©cup√©ration depuis une API
    try:
        # Simulation d'appel API ou commande syst√®me
        servers = [
            {'hostname': 'web01', 'ip': '192.168.1.10', 'role': 'webserver'},
            {'hostname': 'web02', 'ip': '192.168.1.11', 'role': 'webserver'},
            {'hostname': 'db01', 'ip': '192.168.1.20', 'role': 'database'}
        ]

        for server in servers:
            hostname = server['hostname']

            # Variables d'h√¥te
            inventory['_meta']['hostvars'][hostname] = {
                'ansible_host': server['ip'],
                'ansible_user': 'debian',
                'server_role': server['role']
            }

            # Ajout aux groupes
            role_group = f"role_{server['role']}"
            if role_group not in inventory:
                inventory[role_group] = {'hosts': []}
            inventory[role_group]['hosts'].append(hostname)

    except Exception as e:
        print(f"Erreur dans l'inventaire dynamique: {e}", file=sys.stderr)

    return inventory

if __name__ == '__main__':
    if len(sys.argv) == 2 and sys.argv[1] == '--list':
        print(json.dumps(get_dynamic_inventory(), indent=2))
    elif len(sys.argv) == 3 and sys.argv[1] == '--host':
        # AWX peut demander les d√©tails d'un h√¥te sp√©cifique
        print(json.dumps({}))
    else:
        print("Usage: {} --list ou {} --host <hostname>".format(sys.argv[0], sys.argv[0]))
        sys.exit(1)
```

#### Configuration des credentials

##### Credential Machine (SSH)

```yaml
# Dans AWX : Credentials ‚Üí Create Credential

Nom: SSH Production
Description: Cl√©s SSH pour les serveurs de production
Type: Machine
Username: debian
SSH Private Key: |
  -----BEGIN OPENSSH PRIVATE KEY-----
  [contenu de la cl√© priv√©e]
  -----END OPENSSH PRIVATE KEY-----
Privilege Escalation Method: sudo
Privilege Escalation Username: root
```

##### Credential Source Control (Git)

```yaml
Nom: Git Repository Access
Type: Source Control
Username: git_username
Password/Token: ghp_xxxxxxxxxxxxxxxxxxxx
```

##### Credential Cloud (AWS)

```yaml
Nom: AWS Production
Type: Amazon Web Services
Access Key: AKIAIOSFODNN7EXAMPLE
Secret Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

#### Cr√©ation de Job Templates

```yaml
# Configuration d'un Job Template

Nom: Deploy Web Application
Description: D√©ploiement de l'application web sur les serveurs
Job Type: Run
Inventory: Production
Project: Mon Premier Projet
Playbook: site.yml
Credential: SSH Production
Verbosity: Normal (1)
Forks: 5
Limit: webservers
Extra Variables: |
  ---
  environment: production
  app_version: "1.2.3"
  enable_monitoring: true
```

### Workflows et orchestration

#### Cr√©ation d'un Workflow

Les workflows permettent d'encha√Æner plusieurs jobs avec des conditions :

```yaml
# Workflow : D√©ploiement complet application

1. Job: Backup Database
   - Success ‚Üí Continue
   - Failure ‚Üí Stop workflow

2. Job: Deploy Application
   - Success ‚Üí Continue
   - Failure ‚Üí Restore Database

3. Job: Health Check
   - Success ‚Üí Send notification
   - Failure ‚Üí Rollback deployment

4. Job: Cleanup
   - Always run (m√™me en cas d'√©chec pr√©c√©dent)
```

#### Template de workflow avanc√©

```json
{
  "name": "Complete Application Deployment",
  "description": "Workflow complet de d√©ploiement avec rollback",
  "organization": "Default",
  "workflow_job_template_nodes": [
    {
      "id": 1,
      "unified_job_template": "Backup Database",
      "success_nodes": [2],
      "failure_nodes": [],
      "always_nodes": []
    },
    {
      "id": 2,
      "unified_job_template": "Deploy Application",
      "success_nodes": [3],
      "failure_nodes": [5],
      "always_nodes": [6]
    },
    {
      "id": 3,
      "unified_job_template": "Health Check",
      "success_nodes": [4],
      "failure_nodes": [5],
      "always_nodes": []
    },
    {
      "id": 4,
      "unified_job_template": "Send Success Notification",
      "success_nodes": [],
      "failure_nodes": [],
      "always_nodes": [6]
    },
    {
      "id": 5,
      "unified_job_template": "Rollback Deployment",
      "success_nodes": [],
      "failure_nodes": [],
      "always_nodes": [6]
    },
    {
      "id": 6,
      "unified_job_template": "Cleanup Temporary Files",
      "success_nodes": [],
      "failure_nodes": [],
      "always_nodes": []
    }
  ]
}
```

### API REST d'AWX

#### Authentification et utilisation de l'API

```bash
# Obtention d'un token d'authentification
curl -X POST \
  http://localhost:8080/api/v2/tokens/ \
  -H "Content-Type: application/json" \
  -u admin:admin_password_secure \
  -d '{"description":"API Token for automation"}'

# Utilisation du token pour les requ√™tes
export AWX_TOKEN="your_token_here"
```

#### Exemples d'utilisation de l'API

```bash
# Liste des organisations
curl -H "Authorization: Bearer $AWX_TOKEN" \
  http://localhost:8080/api/v2/organizations/

# Liste des projets
curl -H "Authorization: Bearer $AWX_TOKEN" \
  http://localhost:8080/api/v2/projects/

# Lancement d'un job template
curl -X POST \
  -H "Authorization: Bearer $AWX_TOKEN" \
  -H "Content-Type: application/json" \
  http://localhost:8080/api/v2/job_templates/1/launch/ \
  -d '{
    "extra_vars": {
      "environment": "staging",
      "version": "1.3.0"
    }
  }'

# Suivi du statut d'un job
curl -H "Authorization: Bearer $AWX_TOKEN" \
  http://localhost:8080/api/v2/jobs/123/
```

#### Script Python pour automatiser AWX

```python
#!/usr/bin/env python3
# awx_automation.py

import requests
import json
import time

class AWXClient:
    def __init__(self, base_url, token):
        self.base_url = base_url.rstrip('/')
        self.headers = {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json'
        }

    def launch_job_template(self, template_id, extra_vars=None):
        """Lance un job template avec des variables optionnelles"""
        url = f"{self.base_url}/api/v2/job_templates/{template_id}/launch/"

        data = {}
        if extra_vars:
            data['extra_vars'] = extra_vars

        response = requests.post(url, headers=self.headers, data=json.dumps(data))

        if response.status_code == 201:
            job_data = response.json()
            print(f"Job lanc√© avec succ√®s. ID: {job_data['id']}")
            return job_data['id']
        else:
            print(f"Erreur lors du lancement: {response.status_code}")
            print(response.text)
            return None

    def wait_for_job_completion(self, job_id, timeout=3600):
        """Attend la fin d'un job avec timeout"""
        url = f"{self.base_url}/api/v2/jobs/{job_id}/"
        start_time = time.time()

        while time.time() - start_time < timeout:
            response = requests.get(url, headers=self.headers)

            if response.status_code == 200:
                job_data = response.json()
                status = job_data['status']

                print(f"Status du job {job_id}: {status}")

                if status in ['successful', 'failed', 'error', 'canceled']:
                    return status

                time.sleep(10)  # Attendre 10 secondes avant la prochaine v√©rification
            else:
                print(f"Erreur lors de la v√©rification: {response.status_code}")
                return None

        print(f"Timeout atteint pour le job {job_id}")
        return 'timeout'

    def get_job_output(self, job_id):
        """R√©cup√®re la sortie d'un job"""
        url = f"{self.base_url}/api/v2/jobs/{job_id}/stdout/"
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            return response.text
        else:
            return f"Erreur lors de la r√©cup√©ration: {response.status_code}"

# Exemple d'utilisation
if __name__ == "__main__":
    # Configuration
    AWX_URL = "http://localhost:8080"
    AWX_TOKEN = "your_token_here"
    TEMPLATE_ID = 1

    # Initialisation du client
    client = AWXClient(AWX_URL, AWX_TOKEN)

    # Variables pour le d√©ploiement
    deployment_vars = {
        "environment": "production",
        "app_version": "2.1.0",
        "enable_rollback": True
    }

    # Lancement du job
    job_id = client.launch_job_template(TEMPLATE_ID, deployment_vars)

    if job_id:
        # Attente de la fin du job
        final_status = client.wait_for_job_completion(job_id)

        print(f"Job termin√© avec le status: {final_status}")

        if final_status == 'failed':
            # R√©cup√©ration des logs en cas d'√©chec
            output = client.get_job_output(job_id)
            print("Sortie du job:")
            print(output)
```

## 10.2.4 Collections et Galaxy

### Introduction aux Ansible Collections

Les **Collections** sont un format de distribution pour le contenu Ansible qui peut inclure des playbooks, des r√¥les, des modules et des plugins. Elles remplacent progressivement l'ancien syst√®me de r√¥les individuels et permettent une meilleure organisation et distribution du contenu Ansible.

### Structure d'une Collection

```
ansible_collections/
‚îî‚îÄ‚îÄ namespace/
    ‚îî‚îÄ‚îÄ collection_name/
        ‚îú‚îÄ‚îÄ galaxy.yml              # M√©tadonn√©es de la collection
        ‚îú‚îÄ‚îÄ README.md               # Documentation
        ‚îú‚îÄ‚îÄ docs/                   # Documentation d√©taill√©e
        ‚îú‚îÄ‚îÄ plugins/                # Plugins personnalis√©s
        ‚îÇ   ‚îú‚îÄ‚îÄ modules/           # Modules Ansible
        ‚îÇ   ‚îú‚îÄ‚îÄ inventory/         # Plugins d'inventaire
        ‚îÇ   ‚îú‚îÄ‚îÄ lookup/            # Plugins de lookup
        ‚îÇ   ‚îî‚îÄ‚îÄ filter/            # Filtres Jinja2
        ‚îú‚îÄ‚îÄ roles/                 # R√¥les Ansible
        ‚îÇ   ‚îú‚îÄ‚îÄ role1/
        ‚îÇ   ‚îî‚îÄ‚îÄ role2/
        ‚îú‚îÄ‚îÄ playbooks/             # Playbooks
        ‚îú‚îÄ‚îÄ tests/                 # Tests automatis√©s
        ‚îî‚îÄ‚îÄ meta/                  # M√©tadonn√©es des r√¥les
```

### Utilisation d'Ansible Galaxy

#### Installation de collections depuis Galaxy

```bash
# Installation d'une collection sp√©cifique
ansible-galaxy collection install community.general

# Installation avec une version sp√©cifique
ansible-galaxy collection install community.kubernetes:2.0.1

# Installation depuis un fichier requirements
ansible-galaxy collection install -r requirements.yml

# Installation avec mise √† jour forc√©e
ansible-galaxy collection install community.general --force

# Installation dans un r√©pertoire personnalis√©
ansible-galaxy collection install community.general -p ./my_collections/
```

#### Fichier requirements.yml pour les collections

```yaml
# requirements.yml

---
collections:
  # Collection depuis Galaxy avec version
  - name: community.general
    version: ">=5.0.0"

  # Collection depuis un repository Git
  - name: https://github.com/namespace/collection_name.git
    type: git
    version: main

  # Collection depuis un fichier local
  - name: ./local_collections/my_collection.tar.gz
    type: file

  # Collections cloud sp√©cifiques
  - name: amazon.aws
    version: ">=6.0.0"

  - name: azure.azcollection
    version: ">=1.15.0"

  - name: google.cloud
    version: ">=1.1.0"

  # Collections pour Kubernetes
  - name: kubernetes.core
    version: ">=2.4.0"

  - name: community.kubernetes
    version: ">=2.0.0"

  # Collections pour la gestion de syst√®mes
  - name: community.crypto
    version: ">=2.10.0"

  - name: community.mysql
    version: ">=3.5.0"

  - name: community.postgresql
    version: ">=2.3.0"
```

#### Installation et gestion

```bash
# Installation depuis requirements.yml
ansible-galaxy collection install -r requirements.yml

# Mise √† jour de toutes les collections
ansible-galaxy collection install -r requirements.yml --upgrade

# Liste des collections install√©es
ansible-galaxy collection list

# Informations d√©taill√©es sur une collection
ansible-galaxy collection show community.general

# Recherche de collections
ansible-galaxy collection search kubernetes
```

### Collections populaires et leurs usages

#### Community.General

```yaml
# Exemples d'utilisation de community.general

---
- name: Utilisation de modules community.general
  hosts: all
  tasks:
    # Gestion des archives
    - name: Extraction d'archive avec support √©tendu
      community.general.archive:
        path: /path/to/files/*
        dest: /path/to/archive.tar.gz
        format: gz

    # Gestion des certificats
    - name: G√©n√©ration de certificat auto-sign√©
      community.general.openssl_certificate:
        path: /etc/ssl/certs/mysite.crt
        privatekey_path: /etc/ssl/private/mysite.key
        provider: selfsigned

    # Module de notification
    - name: Envoi de notification Slack
      community.general.slack:
        token: "{{ vault_slack_token }}"
        msg: "D√©ploiement termin√© avec succ√®s sur {{ inventory_hostname }}"
        channel: "#deployments"

    # Gestion des packages snap
    - name: Installation d'un package snap
      community.general.snap:
        name: code
        classic: yes
```

#### Amazon.AWS

```yaml
# Exemples avec la collection AWS

---
- name: Gestion des ressources AWS
  hosts: localhost
  connection: local
  tasks:
    # Gestion des instances EC2
    - name: Cr√©ation d'instance EC2
      amazon.aws.ec2_instance:
        name: web-server
        image_id: ami-0abcdef1234567890
        instance_type: t3.micro
        key_name: my-key
        security_groups:
          - web-security-group
        tags:
          Environment: production

    # Gestion S3
    - name: Upload de fichier vers S3
      amazon.aws.s3_object:
        bucket: my-bucket
        object: backup/database-{{ ansible_date_time.date }}.sql
        src: /tmp/database.sql
        mode: put

    # Gestion des Load Balancers
    - name: Cr√©ation d'Application Load Balancer
      amazon.aws.elb_application_lb:
        name: my-app-lb
        security_groups:
          - lb-security-group
        subnets:
          - subnet-12345
          - subnet-67890
        listeners:
          - Protocol: HTTP
            Port: 80
            DefaultActions:
              - Type: forward
                TargetGroupArn: "{{ target_group.target_group_arn }}"
```

#### Kubernetes.Core

```yaml
# Exemples avec kubernetes.core

---
- name: D√©ploiement Kubernetes avanc√©
  hosts: localhost
  connection: local
  tasks:
    # D√©ploiement avec strat√©gie rolling update
    - name: D√©ploiement rolling update
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: web-app
            namespace: production
          spec:
            replicas: 5
            strategy:
              type: RollingUpdate
              rollingUpdate:
                maxSurge: 1
                maxUnavailable: 1
            selector:
              matchLabels:
                app: web-app
            template:
              metadata:
                labels:
                  app: web-app
              spec:
                containers:
                - name: web
                  image: "nginx:{{ app_version }}"
                  resources:
                    requests:
                      memory: "128Mi"
                      cpu: "100m"
                    limits:
                      memory: "256Mi"
                      cpu: "500m"

    # Attente de la disponibilit√© du d√©ploiement
    - name: Attendre que le d√©ploiement soit pr√™t
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        name: web-app
        namespace: production
        wait: true
        wait_condition:
          type: Progressing
          status: "True"
          reason: NewReplicaSetAvailable
        wait_timeout: 600
```

### Cr√©ation d'une collection personnalis√©e

#### Structure initiale

```bash
# Cr√©ation du squelette d'une collection
ansible-galaxy collection init my_namespace.my_collection

# Structure cr√©√©e
my_namespace/
‚îî‚îÄ‚îÄ my_collection/
    ‚îú‚îÄ‚îÄ galaxy.yml
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ docs/
    ‚îú‚îÄ‚îÄ plugins/
    ‚îÇ   ‚îî‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ roles/
    ‚îî‚îÄ‚îÄ tests/
```

#### Configuration galaxy.yml

```yaml
# galaxy.yml

namespace: my_namespace
name: my_collection
version: 1.0.0
readme: README.md

authors:
  - "Votre Nom <email@example.com>"

description: Collection personnalis√©e pour l'infrastructure de mon organisation

license:
  - GPL-2.0-or-later

tags:
  - infrastructure
  - automation
  - debian
  - kubernetes

dependencies:
  "community.general": ">=5.0.0"
  "kubernetes.core": ">=2.4.0"

repository: https://github.com/my_namespace/my_collection
documentation: https://my_namespace.github.io/my_collection
homepage: https://github.com/my_namespace/my_collection
issues: https://github.com/my_namespace/my_collection/issues

build_ignore:
  - "*.tar.gz"
  - ".git"
  - ".gitignore"
  - "tests/"
```

#### Ajout d'un r√¥le personnalis√©

```bash
# Cr√©ation d'un r√¥le dans la collection
cd my_namespace/my_collection/roles
ansible-galaxy role init debian_hardening
```

```yaml
# roles/debian_hardening/tasks/main.yml

---
- name: Mise √† jour du syst√®me
  apt:
    update_cache: yes
    upgrade: dist
    autoremove: yes

- name: Installation des outils de s√©curit√©
  apt:
    name:
      - fail2ban
      - ufw
      - aide
      - unattended-upgrades
    state: present

- name: Configuration SSH s√©curis√©e
  template:
    src: sshd_config.j2
    dest: /etc/ssh/sshd_config
    backup: yes
  notify: restart ssh

- name: Configuration du firewall
  ufw:
    rule: "{{ item.rule }}"
    port: "{{ item.port }}"
    proto: "{{ item.proto | default('tcp') }}"
  loop: "{{ firewall_rules }}"
  notify: enable ufw
```

#### Ajout d'un module personnalis√©

```python
# plugins/modules/system_info.py

#!/usr/bin/python
# -*- coding: utf-8 -*-

DOCUMENTATION = '''
---
module: system_info
short_description: Collecte d'informations syst√®me avanc√©es
description:
    - Module pour collecter des informations syst√®me d√©taill√©es
    - Retourne des m√©triques syst√®me et de performance
version_added: "1.0.0"
author:
    - Votre Nom (@votre_github)
options:
    include_performance:
        description:
            - Inclure les m√©triques de performance
        type: bool
        default: false
    include_network:
        description:
            - Inclure les informations r√©seau d√©taill√©es
        type: bool
        default: true
'''

EXAMPLES = '''
- name: Collecte d'informations basiques
  my_namespace.my_collection.system_info:

- name: Collecte avec m√©triques de performance
  my_namespace.my_collection.system_info:
    include_performance: true
    include_network: true
'''

RETURN = '''
system_info:
    description: Informations syst√®me collect√©es
    returned: always
    type: dict
    sample:
        hostname: "web01"
        os_version: "Debian 12"
        cpu_count: 4
        memory_total: "8GB"
        network_interfaces: ["eth0", "lo"]
'''

from ansible.module_utils.basic import AnsibleModule
import platform
import psutil
import socket

def get_system_info(include_performance=False, include_network=True):
    """Collecte les informations syst√®me"""

    info = {
        'hostname': socket.gethostname(),
        'os_name': platform.system(),
        'os_version': platform.version(),
        'architecture': platform.architecture()[0],
        'cpu_count': psutil.cpu_count(),
        'memory_total': psutil.virtual_memory().total
    }

    if include_performance:
        info.update({
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': {
                '/': psutil.disk_usage('/').percent
            }
        })

    if include_network:
        interfaces = list(psutil.net_if_addrs().keys())
        info['network_interfaces'] = interfaces

    return info

def main():
    module = AnsibleModule(
        argument_spec=dict(
            include_performance=dict(type='bool', default=False),
            include_network=dict(type='bool', default=True)
        ),
        supports_check_mode=True
    )

    try:
        system_info = get_system_info(
            include_performance=module.params['include_performance'],
            include_network=module.params['include_network']
        )

        module.exit_json(
            changed=False,
            system_info=system_info
        )

    except Exception as e:
        module.fail_json(msg=f"Erreur lors de la collecte: {str(e)}")

if __name__ == '__main__':
    main()
```

#### Construction et publication

```bash
# Construction de la collection
ansible-galaxy collection build

# Publication sur Galaxy (n√©cessite un token)
ansible-galaxy collection publish my_namespace-my_collection-1.0.0.tar.gz --api-key=your_galaxy_token

# Installation locale pour test
ansible-galaxy collection install my_namespace-my_collection-1.0.0.tar.gz
```

#### Utilisation de la collection personnalis√©e

```yaml
# playbook utilisant notre collection

---
- name: Test de la collection personnalis√©e
  hosts: debian_servers
  collections:
    - my_namespace.my_collection

  tasks:
    - name: Application du hardening Debian
      include_role:
        name: debian_hardening
      vars:
        firewall_rules:
          - { rule: 'allow', port: '22' }
          - { rule: 'allow', port: '80' }
          - { rule: 'allow', port: '443' }

    - name: Collecte d'informations syst√®me
      system_info:
        include_performance: true
        include_network: true
      register: host_info

    - name: Affichage des informations
      debug:
        var: host_info.system_info
```

Cette section compl√®te le module Ansible avanc√© en couvrant l'installation et configuration d'AWX/Tower ainsi que la gestion des collections Ansible. Les exemples fournis sont pratiques et directement utilisables pour commencer √† automatiser des infrastructures complexes.

‚è≠Ô∏è
