🔝 Retour au [Sommaire](/SOMMAIRE.md)

# 10.2 Ansible avancé

## Introduction à Ansible avancé

Ansible est un outil d'automatisation puissant qui utilise une approche déclarative pour gérer la configuration des systèmes. Contrairement à d'autres outils, Ansible est **agentless** (sans agent), ce qui signifie qu'il n'a besoin d'aucun logiciel spécial installé sur les machines cibles - il utilise simplement SSH pour se connecter et exécuter les tâches.

Dans cette section avancée, nous explorons comment utiliser Ansible pour des tâches complexes incluant la gestion d'infrastructures Kubernetes, l'intégration cloud, et l'utilisation d'outils d'entreprise comme AWX/Tower.

### Rappel des concepts de base

**Playbook :** Un fichier YAML qui définit les tâches à exécuter sur les hôtes cibles.

**Inventory :** Liste des machines sur lesquelles Ansible va opérer.

**Module :** Unité de travail dans Ansible (copie de fichier, installation de paquet, etc.).

**Role :** Organisation réutilisable de playbooks, variables, fichiers et templates.

**Facts :** Informations automatiquement collectées sur les systèmes cibles.

## 10.2.1 Ansible sur Debian

### Installation d'Ansible sur Debian

#### Installation via les dépôts officiels

```bash
# Mise à jour des paquets
sudo apt update

# Installation d'Ansible
sudo apt install ansible

# Vérification de l'installation
ansible --version
```

#### Installation via pip (version plus récente)

```bash
# Installation de pip si nécessaire
sudo apt install python3-pip python3-venv

# Création d'un environnement virtuel (recommandé)
python3 -m venv ansible-env
source ansible-env/bin/activate

# Installation d'Ansible via pip
pip install ansible

# Vérification
ansible --version
```

#### Installation via le PPA Ansible (dernière version)

```bash
# Ajout du PPA Ansible
sudo apt update
sudo apt install software-properties-common
sudo add-apt-repository --yes --update ppa:ansible/ansible

# Installation
sudo apt install ansible

# Vérification
ansible --version
```

### Configuration initiale d'Ansible

#### Fichier de configuration ansible.cfg

Ansible recherche sa configuration dans plusieurs emplacements, dans cet ordre :
1. `ANSIBLE_CONFIG` (variable d'environnement)
2. `ansible.cfg` (dans le répertoire courant)
3. `~/.ansible.cfg` (dans le répertoire home)
4. `/etc/ansible/ansible.cfg` (système)

```ini
# ansible.cfg

[defaults]
# Fichier d'inventaire par défaut
inventory = ./inventory/hosts.yml

# Utilisateur SSH par défaut
remote_user = debian

# Clé SSH privée
private_key_file = ~/.ssh/id_rsa

# Désactiver la vérification des clés d'hôte SSH (attention en production)
host_key_checking = False

# Répertoire des rôles
roles_path = ./roles:~/.ansible/roles:/etc/ansible/roles

# Fichier de log
log_path = ./ansible.log

# Parallélisme (nombre de tâches simultanées)
forks = 10

# Timeout SSH
timeout = 30

# Collecte des facts
gathering = smart
fact_caching = jsonfile
fact_caching_connection = ./facts_cache
fact_caching_timeout = 86400

# Format de sortie
stdout_callback = yaml
bin_ansible_callbacks = True

[inventory]
# Activer les plugins d'inventaire
enable_plugins = yaml, ini, auto

[privilege_escalation]
# Configuration sudo
become = True
become_method = sudo
become_user = root
become_ask_pass = False

[ssh_connection]
# Configuration SSH
ssh_args = -o ControlMaster=auto -o ControlPersist=60s -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
control_path_dir = ~/.ansible/cp
control_path = %(directory)s/%%h-%%p-%%r
pipelining = True
```

#### Structure d'un projet Ansible

```
ansible-project/
├── ansible.cfg                 # Configuration Ansible
├── inventory/                  # Inventaires
│   ├── hosts.yml              # Inventaire principal
│   ├── dev/
│   │   └── hosts.yml          # Inventaire développement
│   └── prod/
│       └── hosts.yml          # Inventaire production
├── group_vars/                # Variables par groupe
│   ├── all.yml               # Variables globales
│   ├── webservers.yml        # Variables pour les serveurs web
│   └── databases.yml         # Variables pour les bases de données
├── host_vars/                # Variables par hôte
│   ├── web01.yml
│   └── db01.yml
├── roles/                    # Rôles personnalisés
│   ├── common/
│   ├── webserver/
│   └── database/
├── playbooks/               # Playbooks
│   ├── site.yml            # Playbook principal
│   ├── webservers.yml      # Playbook serveurs web
│   └── databases.yml       # Playbook bases de données
├── files/                  # Fichiers statiques
├── templates/              # Templates Jinja2
├── vars/                   # Fichiers de variables
└── vault/                  # Fichiers chiffrés avec Ansible Vault
```

### Inventaire avancé

#### Inventaire YAML avec groupes et variables

```yaml
# inventory/hosts.yml

all:
  vars:
    ansible_user: debian
    ansible_ssh_private_key_file: ~/.ssh/id_rsa
    domain_name: example.com

  children:
    webservers:
      vars:
        http_port: 80
        https_port: 443
        nginx_version: latest
      hosts:
        web01:
          ansible_host: 192.168.1.10
          server_id: 1
        web02:
          ansible_host: 192.168.1.11
          server_id: 2
        web03:
          ansible_host: 192.168.1.12
          server_id: 3

    databases:
      vars:
        mysql_port: 3306
        mysql_root_password: "{{ vault_mysql_root_password }}"
      hosts:
        db01:
          ansible_host: 192.168.1.20
          mysql_server_id: 1
          mysql_role: master
        db02:
          ansible_host: 192.168.1.21
          mysql_server_id: 2
          mysql_role: slave

    loadbalancers:
      hosts:
        lb01:
          ansible_host: 192.168.1.5

    monitoring:
      hosts:
        monitor01:
          ansible_host: 192.168.1.30

    # Groupes de groupes
    production:
      children:
        webservers:
        databases:
        loadbalancers:

    backend:
      children:
        databases:

    frontend:
      children:
        webservers:
        loadbalancers:
```

#### Inventaire dynamique pour le cloud

```python
#!/usr/bin/env python3
# inventory/aws_inventory.py

import json
import boto3
from botocore.exceptions import ClientError

def get_aws_inventory():
    """Génère un inventaire dynamique depuis AWS EC2"""

    inventory = {
        '_meta': {
            'hostvars': {}
        },
        'all': {
            'children': ['ungrouped']
        },
        'ungrouped': {
            'hosts': []
        }
    }

    try:
        ec2 = boto3.client('ec2', region_name='eu-west-1')

        # Récupération des instances EC2
        response = ec2.describe_instances(
            Filters=[
                {'Name': 'instance-state-name', 'Values': ['running']}
            ]
        )

        for reservation in response['Reservations']:
            for instance in reservation['Instances']:
                instance_id = instance['InstanceId']

                # Nom de l'instance depuis les tags
                instance_name = instance_id
                for tag in instance.get('Tags', []):
                    if tag['Key'] == 'Name':
                        instance_name = tag['Value']
                        break

                # Variables d'hôte
                hostvars = {
                    'ansible_host': instance.get('PublicIpAddress', instance.get('PrivateIpAddress')),
                    'ansible_user': 'ubuntu',  # ou 'ec2-user' selon l'AMI
                    'instance_id': instance_id,
                    'instance_type': instance['InstanceType'],
                    'availability_zone': instance['Placement']['AvailabilityZone'],
                    'private_ip': instance.get('PrivateIpAddress'),
                    'public_ip': instance.get('PublicIpAddress')
                }

                inventory['_meta']['hostvars'][instance_name] = hostvars
                inventory['ungrouped']['hosts'].append(instance_name)

                # Groupes basés sur les tags
                for tag in instance.get('Tags', []):
                    if tag['Key'] == 'Environment':
                        group_name = f"env_{tag['Value']}"
                        if group_name not in inventory:
                            inventory[group_name] = {'hosts': []}
                        inventory[group_name]['hosts'].append(instance_name)

                    elif tag['Key'] == 'Role':
                        group_name = f"role_{tag['Value']}"
                        if group_name not in inventory:
                            inventory[group_name] = {'hosts': []}
                        inventory[group_name]['hosts'].append(instance_name)

    except ClientError as e:
        print(f"Erreur AWS: {e}")

    return inventory

if __name__ == '__main__':
    print(json.dumps(get_aws_inventory(), indent=2))
```

### Ansible Vault pour la sécurité

#### Création et gestion des secrets

```bash
# Création d'un fichier chiffré
ansible-vault create vault/secrets.yml

# Édition d'un fichier chiffré
ansible-vault edit vault/secrets.yml

# Chiffrement d'un fichier existant
ansible-vault encrypt vars/database.yml

# Déchiffrement d'un fichier
ansible-vault decrypt vars/database.yml

# Affichage du contenu sans déchiffrer
ansible-vault view vault/secrets.yml

# Changement du mot de passe
ansible-vault rekey vault/secrets.yml
```

#### Utilisation avec des fichiers de mots de passe

```bash
# Stockage du mot de passe dans un fichier
echo 'mon_mot_de_passe_vault' > .vault_password

# Configuration dans ansible.cfg
echo 'vault_password_file = ./.vault_password' >> ansible.cfg

# Ou via variable d'environnement
export ANSIBLE_VAULT_PASSWORD_FILE=./.vault_password
```

#### Exemple de fichier chiffré

```yaml
# vault/secrets.yml (contenu chiffré)

$ANSIBLE_VAULT;1.1;AES256
66663433383862623039323739353766623364383963356264393835336634326439653035623730
3539323434336662346565643038343734656536656235300a386665356564656430373665306163
...
```

```yaml
# Contenu déchiffré pour référence (NE PAS stocker en clair)
vault_mysql_root_password: "super_secret_password"
vault_api_key: "api_key_secret"
vault_ssl_private_key: |
  -----BEGIN PRIVATE KEY-----
  MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQC...
  -----END PRIVATE KEY-----
```

### Playbooks avancés pour Debian

#### Playbook de hardening système

```yaml
# playbooks/debian-hardening.yml

---
- name: Hardening système Debian
  hosts: all
  become: yes
  vars:
    ssh_port: 2222
    allowed_users: ['debian', 'admin']

  tasks:
    - name: Mise à jour du système
      apt:
        update_cache: yes
        upgrade: dist
        autoremove: yes
        autoclean: yes
      register: apt_result

    - name: Redémarrage si nécessaire
      reboot:
        reboot_timeout: 300
      when: apt_result.changed and ansible_facts['kernel'] not in ansible_facts['kernel_modules']

    - name: Installation des paquets de sécurité
      apt:
        name:
          - fail2ban
          - ufw
          - unattended-upgrades
          - aide
          - rkhunter
          - chkrootkit
        state: present

    - name: Configuration SSH sécurisée
      template:
        src: sshd_config.j2
        dest: /etc/ssh/sshd_config
        backup: yes
      notify: restart ssh

    - name: Configuration du firewall UFW
      ufw:
        rule: "{{ item.rule }}"
        port: "{{ item.port }}"
        proto: "{{ item.proto | default('tcp') }}"
        src: "{{ item.src | default('any') }}"
      loop:
        - { rule: 'allow', port: '{{ ssh_port }}', src: '192.168.0.0/16' }
        - { rule: 'allow', port: '80' }
        - { rule: 'allow', port: '443' }
      notify: enable ufw

    - name: Configuration de fail2ban
      template:
        src: jail.local.j2
        dest: /etc/fail2ban/jail.local
      notify: restart fail2ban

    - name: Configuration des mises à jour automatiques
      template:
        src: 50unattended-upgrades.j2
        dest: /etc/apt/apt.conf.d/50unattended-upgrades

    - name: Suppression des paquets inutiles
      apt:
        name:
          - telnet
          - rsh-client
          - rsh-redone-client
        state: absent

    - name: Configuration des limites système
      template:
        src: limits.conf.j2
        dest: /etc/security/limits.conf

  handlers:
    - name: restart ssh
      service:
        name: ssh
        state: restarted

    - name: enable ufw
      ufw:
        state: enabled

    - name: restart fail2ban
      service:
        name: fail2ban
        state: restarted
```

#### Template SSH sécurisé

```jinja2
# templates/sshd_config.j2

# Configuration SSH sécurisée pour {{ inventory_hostname }}
Port {{ ssh_port }}
Protocol 2

# Authentification
PermitRootLogin no
PasswordAuthentication no
ChallengeResponseAuthentication no
UsePAM yes

# Utilisateurs autorisés
{% for user in allowed_users %}
AllowUsers {{ user }}
{% endfor %}

# Sécurité
X11Forwarding no
ClientAliveInterval 300
ClientAliveCountMax 2
MaxAuthTries 3
MaxSessions 2

# Chiffrement
Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com
MACs hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com
KexAlgorithms curve25519-sha256@libssh.org,diffie-hellman-group16-sha512

# Subsystèmes
Subsystem sftp /usr/lib/openssh/sftp-server

# Logging
SyslogFacility AUTH
LogLevel INFO
```

## 10.2.2 Playbooks Kubernetes et cloud

### Gestion de Kubernetes avec Ansible

#### Installation du module Kubernetes

```bash
# Installation via pip
pip install kubernetes openshift

# Ou via les collections Ansible
ansible-galaxy collection install kubernetes.core
ansible-galaxy collection install community.kubernetes
```

#### Configuration et connexion à Kubernetes

```yaml
# playbooks/k8s-setup.yml

---
- name: Configuration Kubernetes avec Ansible
  hosts: localhost
  connection: local
  vars:
    k8s_namespace: production
    app_name: webapp
    replicas: 3

  tasks:
    - name: Vérification de la connexion au cluster
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Node
      register: cluster_nodes

    - name: Affichage des nœuds du cluster
      debug:
        msg: "Cluster avec {{ cluster_nodes.resources | length }} nœuds"

    - name: Création du namespace
      kubernetes.core.k8s:
        name: "{{ k8s_namespace }}"
        api_version: v1
        kind: Namespace
        state: present

    - name: Déploiement de l'application
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: "{{ app_name }}"
            namespace: "{{ k8s_namespace }}"
            labels:
              app: "{{ app_name }}"
          spec:
            replicas: "{{ replicas }}"
            selector:
              matchLabels:
                app: "{{ app_name }}"
            template:
              metadata:
                labels:
                  app: "{{ app_name }}"
              spec:
                containers:
                - name: webapp
                  image: nginx:1.21
                  ports:
                  - containerPort: 80
                  resources:
                    requests:
                      memory: "64Mi"
                      cpu: "250m"
                    limits:
                      memory: "128Mi"
                      cpu: "500m"

    - name: Création du service
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Service
          metadata:
            name: "{{ app_name }}-service"
            namespace: "{{ k8s_namespace }}"
          spec:
            selector:
              app: "{{ app_name }}"
            ports:
            - protocol: TCP
              port: 80
              targetPort: 80
            type: ClusterIP

    - name: Création de l'Ingress
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: "{{ app_name }}-ingress"
            namespace: "{{ k8s_namespace }}"
            annotations:
              nginx.ingress.kubernetes.io/rewrite-target: /
          spec:
            rules:
            - host: "{{ app_name }}.{{ domain_name | default('example.com') }}"
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: "{{ app_name }}-service"
                      port:
                        number: 80
```

#### Gestion des ConfigMaps et Secrets

```yaml
# playbooks/k8s-configs.yml

---
- name: Gestion des configurations Kubernetes
  hosts: localhost
  connection: local
  vars:
    k8s_namespace: production

  tasks:
    - name: Création de ConfigMap pour la configuration applicative
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: app-config
            namespace: "{{ k8s_namespace }}"
          data:
            database_host: "db.{{ k8s_namespace }}.svc.cluster.local"
            database_port: "5432"
            log_level: "INFO"
            max_connections: "100"

    - name: Création de Secret pour les credentials
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: v1
          kind: Secret
          metadata:
            name: app-secrets
            namespace: "{{ k8s_namespace }}"
          type: Opaque
          data:
            database_password: "{{ vault_db_password | b64encode }}"
            api_key: "{{ vault_api_key | b64encode }}"
            jwt_secret: "{{ vault_jwt_secret | b64encode }}"

    - name: Déploiement avec configuration et secrets
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: configured-app
            namespace: "{{ k8s_namespace }}"
          spec:
            replicas: 2
            selector:
              matchLabels:
                app: configured-app
            template:
              metadata:
                labels:
                  app: configured-app
              spec:
                containers:
                - name: app
                  image: myapp:latest
                  envFrom:
                  - configMapRef:
                      name: app-config
                  - secretRef:
                      name: app-secrets
                  volumeMounts:
                  - name: config-volume
                    mountPath: /etc/config
                volumes:
                - name: config-volume
                  configMap:
                    name: app-config
```

### Intégration cloud avec Ansible

#### Gestion d'infrastructure AWS

```yaml
# playbooks/aws-infrastructure.yml

---
- name: Déploiement infrastructure AWS
  hosts: localhost
  connection: local
  vars:
    aws_region: eu-west-1
    environment: production

  tasks:
    - name: Création du VPC
      amazon.aws.ec2_vpc_net:
        name: "{{ environment }}-vpc"
        cidr_block: 10.0.0.0/16
        region: "{{ aws_region }}"
        tags:
          Environment: "{{ environment }}"
          Project: "MyApp"
        state: present
      register: vpc_result

    - name: Création du subnet public
      amazon.aws.ec2_vpc_subnet:
        vpc_id: "{{ vpc_result.vpc.id }}"
        cidr: 10.0.1.0/24
        region: "{{ aws_region }}"
        map_public: yes
        tags:
          Name: "{{ environment }}-public-subnet"
          Type: public
        state: present
      register: public_subnet

    - name: Création du subnet privé
      amazon.aws.ec2_vpc_subnet:
        vpc_id: "{{ vpc_result.vpc.id }}"
        cidr: 10.0.2.0/24
        region: "{{ aws_region }}"
        tags:
          Name: "{{ environment }}-private-subnet"
          Type: private
        state: present
      register: private_subnet

    - name: Création Internet Gateway
      amazon.aws.ec2_vpc_igw:
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_region }}"
        tags:
          Name: "{{ environment }}-igw"
        state: present
      register: igw_result

    - name: Création de la table de routage publique
      amazon.aws.ec2_vpc_route_table:
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_region }}"
        routes:
          - dest: 0.0.0.0/0
            gateway_id: "{{ igw_result.gateway_id }}"
        subnets:
          - "{{ public_subnet.subnet.id }}"
        tags:
          Name: "{{ environment }}-public-rt"

    - name: Création du groupe de sécurité web
      amazon.aws.ec2_security_group:
        name: "{{ environment }}-web-sg"
        description: Security group pour les serveurs web
        vpc_id: "{{ vpc_result.vpc.id }}"
        region: "{{ aws_region }}"
        rules:
          - proto: tcp
            ports:
              - 80
              - 443
            cidr_ip: 0.0.0.0/0
            rule_desc: HTTP/HTTPS access
          - proto: tcp
            ports:
              - 22
            cidr_ip: 10.0.0.0/16
            rule_desc: SSH access from VPC
        tags:
          Environment: "{{ environment }}"
      register: web_sg

    - name: Lancement des instances EC2
      amazon.aws.ec2_instance:
        name: "{{ environment }}-web-{{ item }}"
        image_id: ami-0d71ea30463e0ff8d  # Debian 12
        instance_type: t3.micro
        subnet_id: "{{ public_subnet.subnet.id }}"
        security_groups:
          - "{{ web_sg.group_id }}"
        key_name: my-key-pair
        wait: yes
        wait_timeout: 300
        tags:
          Environment: "{{ environment }}"
          Role: webserver
          Index: "{{ item }}"
      loop: [1, 2]
      register: ec2_instances

    - name: Attente de la disponibilité SSH
      wait_for:
        host: "{{ item.instances[0].public_ip_address }}"
        port: 22
        timeout: 300
      loop: "{{ ec2_instances.results }}"
```

#### Gestion Azure avec Ansible

```yaml
# playbooks/azure-resources.yml

---
- name: Déploiement de ressources Azure
  hosts: localhost
  connection: local
  vars:
    resource_group: rg-ansible-demo
    location: westeurope
    environment: dev

  tasks:
    - name: Création du groupe de ressources
      azure.azcollection.azure_rm_resourcegroup:
        name: "{{ resource_group }}"
        location: "{{ location }}"
        tags:
          Environment: "{{ environment }}"
          ManagedBy: ansible

    - name: Création du réseau virtuel
      azure.azcollection.azure_rm_virtualnetwork:
        resource_group: "{{ resource_group }}"
        name: vnet-ansible
        address_prefixes: ["10.0.0.0/16"]
        tags:
          Environment: "{{ environment }}"

    - name: Création du sous-réseau
      azure.azcollection.azure_rm_subnet:
        resource_group: "{{ resource_group }}"
        virtual_network: vnet-ansible
        name: subnet-web
        address_prefix: "10.0.1.0/24"

    - name: Création du groupe de sécurité réseau
      azure.azcollection.azure_rm_securitygroup:
        resource_group: "{{ resource_group }}"
        name: nsg-web
        rules:
          - name: SSH
            protocol: Tcp
            destination_port_range: 22
            access: Allow
            priority: 1001
            direction: Inbound
          - name: HTTP
            protocol: Tcp
            destination_port_range: 80
            access: Allow
            priority: 1002
            direction: Inbound
        tags:
          Environment: "{{ environment }}"

    - name: Création des IP publiques
      azure.azcollection.azure_rm_publicipaddress:
        resource_group: "{{ resource_group }}"
        name: "pip-web-{{ item }}"
        allocation_method: Static
        sku: Standard
        tags:
          Environment: "{{ environment }}"
      loop: [1, 2]

    - name: Création des interfaces réseau
      azure.azcollection.azure_rm_networkinterface:
        resource_group: "{{ resource_group }}"
        name: "nic-web-{{ item }}"
        virtual_network: vnet-ansible
        subnet: subnet-web
        public_ip_name: "pip-web-{{ item }}"
        security_group: nsg-web
        tags:
          Environment: "{{ environment }}"
      loop: [1, 2]

    - name: Création des machines virtuelles
      azure.azcollection.azure_rm_virtualmachine:
        resource_group: "{{ resource_group }}"
        name: "vm-web-{{ item }}"
        vm_size: Standard_B1s
        admin_username: azureuser
        ssh_password_enabled: false
        ssh_public_keys:
          - path: /home/azureuser/.ssh/authorized_keys
            key_data: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
        network_interfaces: "nic-web-{{ item }}"
        image:
          offer: debian-11
          publisher: debian
          sku: 11-gen2
          version: latest
        tags:
          Environment: "{{ environment }}"
          Role: webserver
      loop: [1, 2]
```

## 10.2.3 AWX/Tower

### Introduction à AWX/Tower

**AWX** est la version open source d'**Ansible Tower** (maintenant **Red Hat Ansible Automation Platform**). C'est une interface web qui permet de gérer, planifier et exécuter des playbooks Ansible de manière centralisée et sécurisée.

### Avantages d'AWX/Tower

**Interface graphique :** Interface web conviviale pour gérer les playbooks.

**Contrôle d'accès :** Gestion fine des permissions et des rôles utilisateurs.

**Planification :** Exécution programmée des tâches d'automatisation.

**API REST :** Intégration avec d'autres systèmes via API.

**Audit :** Traçabilité complète des exécutions et des changements.

**Workflow :** Chaînage complexe de jobs avec conditions.

### Installation d'AWX sur Debian

#### Prérequis

```bash
# Installation de Docker et Docker Compose
sudo apt update
sudo apt install docker.io docker-compose-plugin git

# Ajout de l'utilisateur au groupe docker
sudo usermod -aG docker $USER

# Redémarrage de la session ou logout/login
newgrp docker

# Vérification
docker --version
docker compose version
```

#### Installation via Docker Compose

```bash
# Clone du repository AWX
git clone https://github.com/ansible/awx.git
cd awx

# Checkout de la dernière version stable
git checkout tags/$(git describe --tags --abbrev=0)

# Génération des fichiers de configuration
make docker-compose

# Configuration personnalisée
cp tools/docker-compose/_sources/examples/credentials.py tools/docker-compose/credentials.py

# Édition du fichier de credentials
nano tools/docker-compose/credentials.py
```

```python
# tools/docker-compose/credentials.py

# Mot de passe admin AWX
default_admin_password = 'admin_password_secure'

# Clé secrète (générez-en une unique)
import secrets
secret_key = secrets.token_urlsafe(50)

# Configuration de la base de données PostgreSQL
pg_password = 'postgresql_password_secure'
pg_username = 'awx'
pg_database = 'awx'
pg_port = 5432

# Configuration Redis
redis_password = 'redis_password_secure'

# Configuration du serveur de développement
host_port = 8080
```

#### Démarrage d'AWX

```bash
# Construction et démarrage des conteneurs
make docker-compose-build

# Démarrage des services
make docker-compose

# Vérification des conteneurs
docker ps

# Suivi des logs
docker compose -f tools/docker-compose/docker-compose.yml logs -f
```

#### Accès à l'interface AWX

Une fois les conteneurs démarrés, AWX est accessible à l'adresse :
- URL : `http://localhost:8080`
- Utilisateur : `admin`
- Mot de passe : celui défini dans `credentials.py`

### Configuration initiale d'AWX

#### Première connexion et configuration

1. **Accès à l'interface web**
   - Connectez-vous avec les credentials admin
   - Acceptez les termes d'utilisation si demandé

2. **Configuration de la licence** (pour Tower uniquement)
   - AWX est gratuit et n'a pas besoin de licence
   - Tower nécessite une licence Red Hat

3. **Configuration des paramètres système**
   ```
   Administration → Settings → System
   ```

#### Création d'un projet

```yaml
# Configuration d'un projet dans AWX

Nom: Mon Premier Projet
Description: Projet de démonstration pour l'apprentissage AWX
Organisation: Default
SCM Type: Git
SCM URL: https://github.com/mon-compte/ansible-playbooks.git
SCM Branch/Tag/Commit: main
SCM Credential: (optionnel si repository public)
```

#### Configuration des inventaires

##### Inventaire statique

```yaml
# Dans AWX : Inventories → Create Inventory

Nom: Production
Description: Serveurs de production
Organisation: Default
Type: Inventory

# Ajout d'hôtes
Host Name: web01.example.com
Variables:
  ansible_host: 192.168.1.10
  ansible_user: debian
  server_role: webserver

# Ajout de groupes
Group Name: webservers
Variables:
  http_port: 80
  https_port: 443
```

##### Inventaire dynamique

```python
# Custom inventory script pour AWX
#!/usr/bin/env python3

import json
import subprocess
import sys

def get_dynamic_inventory():
    """Script d'inventaire dynamique pour AWX"""

    inventory = {
        '_meta': {
            'hostvars': {}
        },
        'all': {
            'children': ['ungrouped']
        },
        'ungrouped': {
            'hosts': []
        }
    }

    # Exemple : récupération depuis une API
    try:
        # Simulation d'appel API ou commande système
        servers = [
            {'hostname': 'web01', 'ip': '192.168.1.10', 'role': 'webserver'},
            {'hostname': 'web02', 'ip': '192.168.1.11', 'role': 'webserver'},
            {'hostname': 'db01', 'ip': '192.168.1.20', 'role': 'database'}
        ]

        for server in servers:
            hostname = server['hostname']

            # Variables d'hôte
            inventory['_meta']['hostvars'][hostname] = {
                'ansible_host': server['ip'],
                'ansible_user': 'debian',
                'server_role': server['role']
            }

            # Ajout aux groupes
            role_group = f"role_{server['role']}"
            if role_group not in inventory:
                inventory[role_group] = {'hosts': []}
            inventory[role_group]['hosts'].append(hostname)

    except Exception as e:
        print(f"Erreur dans l'inventaire dynamique: {e}", file=sys.stderr)

    return inventory

if __name__ == '__main__':
    if len(sys.argv) == 2 and sys.argv[1] == '--list':
        print(json.dumps(get_dynamic_inventory(), indent=2))
    elif len(sys.argv) == 3 and sys.argv[1] == '--host':
        # AWX peut demander les détails d'un hôte spécifique
        print(json.dumps({}))
    else:
        print("Usage: {} --list ou {} --host <hostname>".format(sys.argv[0], sys.argv[0]))
        sys.exit(1)
```

#### Configuration des credentials

##### Credential Machine (SSH)

```yaml
# Dans AWX : Credentials → Create Credential

Nom: SSH Production
Description: Clés SSH pour les serveurs de production
Type: Machine
Username: debian
SSH Private Key: |
  -----BEGIN OPENSSH PRIVATE KEY-----
  [contenu de la clé privée]
  -----END OPENSSH PRIVATE KEY-----
Privilege Escalation Method: sudo
Privilege Escalation Username: root
```

##### Credential Source Control (Git)

```yaml
Nom: Git Repository Access
Type: Source Control
Username: git_username
Password/Token: ghp_xxxxxxxxxxxxxxxxxxxx
```

##### Credential Cloud (AWS)

```yaml
Nom: AWS Production
Type: Amazon Web Services
Access Key: AKIAIOSFODNN7EXAMPLE
Secret Key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

#### Création de Job Templates

```yaml
# Configuration d'un Job Template

Nom: Deploy Web Application
Description: Déploiement de l'application web sur les serveurs
Job Type: Run
Inventory: Production
Project: Mon Premier Projet
Playbook: site.yml
Credential: SSH Production
Verbosity: Normal (1)
Forks: 5
Limit: webservers
Extra Variables: |
  ---
  environment: production
  app_version: "1.2.3"
  enable_monitoring: true
```

### Workflows et orchestration

#### Création d'un Workflow

Les workflows permettent d'enchaîner plusieurs jobs avec des conditions :

```yaml
# Workflow : Déploiement complet application

1. Job: Backup Database
   - Success → Continue
   - Failure → Stop workflow

2. Job: Deploy Application
   - Success → Continue
   - Failure → Restore Database

3. Job: Health Check
   - Success → Send notification
   - Failure → Rollback deployment

4. Job: Cleanup
   - Always run (même en cas d'échec précédent)
```

#### Template de workflow avancé

```json
{
  "name": "Complete Application Deployment",
  "description": "Workflow complet de déploiement avec rollback",
  "organization": "Default",
  "workflow_job_template_nodes": [
    {
      "id": 1,
      "unified_job_template": "Backup Database",
      "success_nodes": [2],
      "failure_nodes": [],
      "always_nodes": []
    },
    {
      "id": 2,
      "unified_job_template": "Deploy Application",
      "success_nodes": [3],
      "failure_nodes": [5],
      "always_nodes": [6]
    },
    {
      "id": 3,
      "unified_job_template": "Health Check",
      "success_nodes": [4],
      "failure_nodes": [5],
      "always_nodes": []
    },
    {
      "id": 4,
      "unified_job_template": "Send Success Notification",
      "success_nodes": [],
      "failure_nodes": [],
      "always_nodes": [6]
    },
    {
      "id": 5,
      "unified_job_template": "Rollback Deployment",
      "success_nodes": [],
      "failure_nodes": [],
      "always_nodes": [6]
    },
    {
      "id": 6,
      "unified_job_template": "Cleanup Temporary Files",
      "success_nodes": [],
      "failure_nodes": [],
      "always_nodes": []
    }
  ]
}
```

### API REST d'AWX

#### Authentification et utilisation de l'API

```bash
# Obtention d'un token d'authentification
curl -X POST \
  http://localhost:8080/api/v2/tokens/ \
  -H "Content-Type: application/json" \
  -u admin:admin_password_secure \
  -d '{"description":"API Token for automation"}'

# Utilisation du token pour les requêtes
export AWX_TOKEN="your_token_here"
```

#### Exemples d'utilisation de l'API

```bash
# Liste des organisations
curl -H "Authorization: Bearer $AWX_TOKEN" \
  http://localhost:8080/api/v2/organizations/

# Liste des projets
curl -H "Authorization: Bearer $AWX_TOKEN" \
  http://localhost:8080/api/v2/projects/

# Lancement d'un job template
curl -X POST \
  -H "Authorization: Bearer $AWX_TOKEN" \
  -H "Content-Type: application/json" \
  http://localhost:8080/api/v2/job_templates/1/launch/ \
  -d '{
    "extra_vars": {
      "environment": "staging",
      "version": "1.3.0"
    }
  }'

# Suivi du statut d'un job
curl -H "Authorization: Bearer $AWX_TOKEN" \
  http://localhost:8080/api/v2/jobs/123/
```

#### Script Python pour automatiser AWX

```python
#!/usr/bin/env python3
# awx_automation.py

import requests
import json
import time

class AWXClient:
    def __init__(self, base_url, token):
        self.base_url = base_url.rstrip('/')
        self.headers = {
            'Authorization': f'Bearer {token}',
            'Content-Type': 'application/json'
        }

    def launch_job_template(self, template_id, extra_vars=None):
        """Lance un job template avec des variables optionnelles"""
        url = f"{self.base_url}/api/v2/job_templates/{template_id}/launch/"

        data = {}
        if extra_vars:
            data['extra_vars'] = extra_vars

        response = requests.post(url, headers=self.headers, data=json.dumps(data))

        if response.status_code == 201:
            job_data = response.json()
            print(f"Job lancé avec succès. ID: {job_data['id']}")
            return job_data['id']
        else:
            print(f"Erreur lors du lancement: {response.status_code}")
            print(response.text)
            return None

    def wait_for_job_completion(self, job_id, timeout=3600):
        """Attend la fin d'un job avec timeout"""
        url = f"{self.base_url}/api/v2/jobs/{job_id}/"
        start_time = time.time()

        while time.time() - start_time < timeout:
            response = requests.get(url, headers=self.headers)

            if response.status_code == 200:
                job_data = response.json()
                status = job_data['status']

                print(f"Status du job {job_id}: {status}")

                if status in ['successful', 'failed', 'error', 'canceled']:
                    return status

                time.sleep(10)  # Attendre 10 secondes avant la prochaine vérification
            else:
                print(f"Erreur lors de la vérification: {response.status_code}")
                return None

        print(f"Timeout atteint pour le job {job_id}")
        return 'timeout'

    def get_job_output(self, job_id):
        """Récupère la sortie d'un job"""
        url = f"{self.base_url}/api/v2/jobs/{job_id}/stdout/"
        response = requests.get(url, headers=self.headers)

        if response.status_code == 200:
            return response.text
        else:
            return f"Erreur lors de la récupération: {response.status_code}"

# Exemple d'utilisation
if __name__ == "__main__":
    # Configuration
    AWX_URL = "http://localhost:8080"
    AWX_TOKEN = "your_token_here"
    TEMPLATE_ID = 1

    # Initialisation du client
    client = AWXClient(AWX_URL, AWX_TOKEN)

    # Variables pour le déploiement
    deployment_vars = {
        "environment": "production",
        "app_version": "2.1.0",
        "enable_rollback": True
    }

    # Lancement du job
    job_id = client.launch_job_template(TEMPLATE_ID, deployment_vars)

    if job_id:
        # Attente de la fin du job
        final_status = client.wait_for_job_completion(job_id)

        print(f"Job terminé avec le status: {final_status}")

        if final_status == 'failed':
            # Récupération des logs en cas d'échec
            output = client.get_job_output(job_id)
            print("Sortie du job:")
            print(output)
```

## 10.2.4 Collections et Galaxy

### Introduction aux Ansible Collections

Les **Collections** sont un format de distribution pour le contenu Ansible qui peut inclure des playbooks, des rôles, des modules et des plugins. Elles remplacent progressivement l'ancien système de rôles individuels et permettent une meilleure organisation et distribution du contenu Ansible.

### Structure d'une Collection

```
ansible_collections/
└── namespace/
    └── collection_name/
        ├── galaxy.yml              # Métadonnées de la collection
        ├── README.md               # Documentation
        ├── docs/                   # Documentation détaillée
        ├── plugins/                # Plugins personnalisés
        │   ├── modules/           # Modules Ansible
        │   ├── inventory/         # Plugins d'inventaire
        │   ├── lookup/            # Plugins de lookup
        │   └── filter/            # Filtres Jinja2
        ├── roles/                 # Rôles Ansible
        │   ├── role1/
        │   └── role2/
        ├── playbooks/             # Playbooks
        ├── tests/                 # Tests automatisés
        └── meta/                  # Métadonnées des rôles
```

### Utilisation d'Ansible Galaxy

#### Installation de collections depuis Galaxy

```bash
# Installation d'une collection spécifique
ansible-galaxy collection install community.general

# Installation avec une version spécifique
ansible-galaxy collection install community.kubernetes:2.0.1

# Installation depuis un fichier requirements
ansible-galaxy collection install -r requirements.yml

# Installation avec mise à jour forcée
ansible-galaxy collection install community.general --force

# Installation dans un répertoire personnalisé
ansible-galaxy collection install community.general -p ./my_collections/
```

#### Fichier requirements.yml pour les collections

```yaml
# requirements.yml

---
collections:
  # Collection depuis Galaxy avec version
  - name: community.general
    version: ">=5.0.0"

  # Collection depuis un repository Git
  - name: https://github.com/namespace/collection_name.git
    type: git
    version: main

  # Collection depuis un fichier local
  - name: ./local_collections/my_collection.tar.gz
    type: file

  # Collections cloud spécifiques
  - name: amazon.aws
    version: ">=6.0.0"

  - name: azure.azcollection
    version: ">=1.15.0"

  - name: google.cloud
    version: ">=1.1.0"

  # Collections pour Kubernetes
  - name: kubernetes.core
    version: ">=2.4.0"

  - name: community.kubernetes
    version: ">=2.0.0"

  # Collections pour la gestion de systèmes
  - name: community.crypto
    version: ">=2.10.0"

  - name: community.mysql
    version: ">=3.5.0"

  - name: community.postgresql
    version: ">=2.3.0"
```

#### Installation et gestion

```bash
# Installation depuis requirements.yml
ansible-galaxy collection install -r requirements.yml

# Mise à jour de toutes les collections
ansible-galaxy collection install -r requirements.yml --upgrade

# Liste des collections installées
ansible-galaxy collection list

# Informations détaillées sur une collection
ansible-galaxy collection show community.general

# Recherche de collections
ansible-galaxy collection search kubernetes
```

### Collections populaires et leurs usages

#### Community.General

```yaml
# Exemples d'utilisation de community.general

---
- name: Utilisation de modules community.general
  hosts: all
  tasks:
    # Gestion des archives
    - name: Extraction d'archive avec support étendu
      community.general.archive:
        path: /path/to/files/*
        dest: /path/to/archive.tar.gz
        format: gz

    # Gestion des certificats
    - name: Génération de certificat auto-signé
      community.general.openssl_certificate:
        path: /etc/ssl/certs/mysite.crt
        privatekey_path: /etc/ssl/private/mysite.key
        provider: selfsigned

    # Module de notification
    - name: Envoi de notification Slack
      community.general.slack:
        token: "{{ vault_slack_token }}"
        msg: "Déploiement terminé avec succès sur {{ inventory_hostname }}"
        channel: "#deployments"

    # Gestion des packages snap
    - name: Installation d'un package snap
      community.general.snap:
        name: code
        classic: yes
```

#### Amazon.AWS

```yaml
# Exemples avec la collection AWS

---
- name: Gestion des ressources AWS
  hosts: localhost
  connection: local
  tasks:
    # Gestion des instances EC2
    - name: Création d'instance EC2
      amazon.aws.ec2_instance:
        name: web-server
        image_id: ami-0abcdef1234567890
        instance_type: t3.micro
        key_name: my-key
        security_groups:
          - web-security-group
        tags:
          Environment: production

    # Gestion S3
    - name: Upload de fichier vers S3
      amazon.aws.s3_object:
        bucket: my-bucket
        object: backup/database-{{ ansible_date_time.date }}.sql
        src: /tmp/database.sql
        mode: put

    # Gestion des Load Balancers
    - name: Création d'Application Load Balancer
      amazon.aws.elb_application_lb:
        name: my-app-lb
        security_groups:
          - lb-security-group
        subnets:
          - subnet-12345
          - subnet-67890
        listeners:
          - Protocol: HTTP
            Port: 80
            DefaultActions:
              - Type: forward
                TargetGroupArn: "{{ target_group.target_group_arn }}"
```

#### Kubernetes.Core

```yaml
# Exemples avec kubernetes.core

---
- name: Déploiement Kubernetes avancé
  hosts: localhost
  connection: local
  tasks:
    # Déploiement avec stratégie rolling update
    - name: Déploiement rolling update
      kubernetes.core.k8s:
        state: present
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: web-app
            namespace: production
          spec:
            replicas: 5
            strategy:
              type: RollingUpdate
              rollingUpdate:
                maxSurge: 1
                maxUnavailable: 1
            selector:
              matchLabels:
                app: web-app
            template:
              metadata:
                labels:
                  app: web-app
              spec:
                containers:
                - name: web
                  image: "nginx:{{ app_version }}"
                  resources:
                    requests:
                      memory: "128Mi"
                      cpu: "100m"
                    limits:
                      memory: "256Mi"
                      cpu: "500m"

    # Attente de la disponibilité du déploiement
    - name: Attendre que le déploiement soit prêt
      kubernetes.core.k8s_info:
        api_version: apps/v1
        kind: Deployment
        name: web-app
        namespace: production
        wait: true
        wait_condition:
          type: Progressing
          status: "True"
          reason: NewReplicaSetAvailable
        wait_timeout: 600
```

### Création d'une collection personnalisée

#### Structure initiale

```bash
# Création du squelette d'une collection
ansible-galaxy collection init my_namespace.my_collection

# Structure créée
my_namespace/
└── my_collection/
    ├── galaxy.yml
    ├── README.md
    ├── docs/
    ├── plugins/
    │   └── README.md
    ├── roles/
    └── tests/
```

#### Configuration galaxy.yml

```yaml
# galaxy.yml

namespace: my_namespace
name: my_collection
version: 1.0.0
readme: README.md

authors:
  - "Votre Nom <email@example.com>"

description: Collection personnalisée pour l'infrastructure de mon organisation

license:
  - GPL-2.0-or-later

tags:
  - infrastructure
  - automation
  - debian
  - kubernetes

dependencies:
  "community.general": ">=5.0.0"
  "kubernetes.core": ">=2.4.0"

repository: https://github.com/my_namespace/my_collection
documentation: https://my_namespace.github.io/my_collection
homepage: https://github.com/my_namespace/my_collection
issues: https://github.com/my_namespace/my_collection/issues

build_ignore:
  - "*.tar.gz"
  - ".git"
  - ".gitignore"
  - "tests/"
```

#### Ajout d'un rôle personnalisé

```bash
# Création d'un rôle dans la collection
cd my_namespace/my_collection/roles
ansible-galaxy role init debian_hardening
```

```yaml
# roles/debian_hardening/tasks/main.yml

---
- name: Mise à jour du système
  apt:
    update_cache: yes
    upgrade: dist
    autoremove: yes

- name: Installation des outils de sécurité
  apt:
    name:
      - fail2ban
      - ufw
      - aide
      - unattended-upgrades
    state: present

- name: Configuration SSH sécurisée
  template:
    src: sshd_config.j2
    dest: /etc/ssh/sshd_config
    backup: yes
  notify: restart ssh

- name: Configuration du firewall
  ufw:
    rule: "{{ item.rule }}"
    port: "{{ item.port }}"
    proto: "{{ item.proto | default('tcp') }}"
  loop: "{{ firewall_rules }}"
  notify: enable ufw
```

#### Ajout d'un module personnalisé

```python
# plugins/modules/system_info.py

#!/usr/bin/python
# -*- coding: utf-8 -*-

DOCUMENTATION = '''
---
module: system_info
short_description: Collecte d'informations système avancées
description:
    - Module pour collecter des informations système détaillées
    - Retourne des métriques système et de performance
version_added: "1.0.0"
author:
    - Votre Nom (@votre_github)
options:
    include_performance:
        description:
            - Inclure les métriques de performance
        type: bool
        default: false
    include_network:
        description:
            - Inclure les informations réseau détaillées
        type: bool
        default: true
'''

EXAMPLES = '''
- name: Collecte d'informations basiques
  my_namespace.my_collection.system_info:

- name: Collecte avec métriques de performance
  my_namespace.my_collection.system_info:
    include_performance: true
    include_network: true
'''

RETURN = '''
system_info:
    description: Informations système collectées
    returned: always
    type: dict
    sample:
        hostname: "web01"
        os_version: "Debian 12"
        cpu_count: 4
        memory_total: "8GB"
        network_interfaces: ["eth0", "lo"]
'''

from ansible.module_utils.basic import AnsibleModule
import platform
import psutil
import socket

def get_system_info(include_performance=False, include_network=True):
    """Collecte les informations système"""

    info = {
        'hostname': socket.gethostname(),
        'os_name': platform.system(),
        'os_version': platform.version(),
        'architecture': platform.architecture()[0],
        'cpu_count': psutil.cpu_count(),
        'memory_total': psutil.virtual_memory().total
    }

    if include_performance:
        info.update({
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': {
                '/': psutil.disk_usage('/').percent
            }
        })

    if include_network:
        interfaces = list(psutil.net_if_addrs().keys())
        info['network_interfaces'] = interfaces

    return info

def main():
    module = AnsibleModule(
        argument_spec=dict(
            include_performance=dict(type='bool', default=False),
            include_network=dict(type='bool', default=True)
        ),
        supports_check_mode=True
    )

    try:
        system_info = get_system_info(
            include_performance=module.params['include_performance'],
            include_network=module.params['include_network']
        )

        module.exit_json(
            changed=False,
            system_info=system_info
        )

    except Exception as e:
        module.fail_json(msg=f"Erreur lors de la collecte: {str(e)}")

if __name__ == '__main__':
    main()
```

#### Construction et publication

```bash
# Construction de la collection
ansible-galaxy collection build

# Publication sur Galaxy (nécessite un token)
ansible-galaxy collection publish my_namespace-my_collection-1.0.0.tar.gz --api-key=your_galaxy_token

# Installation locale pour test
ansible-galaxy collection install my_namespace-my_collection-1.0.0.tar.gz
```

#### Utilisation de la collection personnalisée

```yaml
# playbook utilisant notre collection

---
- name: Test de la collection personnalisée
  hosts: debian_servers
  collections:
    - my_namespace.my_collection

  tasks:
    - name: Application du hardening Debian
      include_role:
        name: debian_hardening
      vars:
        firewall_rules:
          - { rule: 'allow', port: '22' }
          - { rule: 'allow', port: '80' }
          - { rule: 'allow', port: '443' }

    - name: Collecte d'informations système
      system_info:
        include_performance: true
        include_network: true
      register: host_info

    - name: Affichage des informations
      debug:
        var: host_info.system_info
```

Cette section complète le module Ansible avancé en couvrant l'installation et configuration d'AWX/Tower ainsi que la gestion des collections Ansible. Les exemples fournis sont pratiques et directement utilisables pour commencer à automatiser des infrastructures complexes.

⏭️
