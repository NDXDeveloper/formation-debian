🔝 Retour au [Sommaire](/SOMMAIRE.md)

# 9.5 GitOps et CI/CD

*Module 9 - Kubernetes et orchestration | Niveau : Avancé*

## Vue d'ensemble

L'intégration continue (CI) et le déploiement continu (CD) sont devenus essentiels dans le développement moderne. Avec Kubernetes, ces pratiques évoluent vers **GitOps**, une méthodologie qui utilise Git comme source unique de vérité pour les déploiements.

**Qu'est-ce que GitOps ?**
- **Git comme source de vérité** : Toute configuration est versionnée dans Git
- **Pull-based deployment** : Les agents tirent les changements depuis Git
- **Déclaratif** : L'état désiré est défini, pas les actions
- **Observable** : Audit trail complet des changements

### Évolution vers GitOps

```
CI/CD Traditionnel          GitOps
================            ========

Git → CI → Push → Cluster   Git → CI → Git Repo
                           ↑                  ↓
                           Agent ← Pull ← Cluster
```

### Avantages de GitOps

**Sécurité**
- Pas d'accès direct au cluster depuis CI
- Révision de code pour tous changements
- Audit trail complet

**Fiabilité**
- État convergent automatique
- Recovery automatique en cas de drift
- Rollback simple via Git

**Transparence**
- Historique complet des déploiements
- Collaboration via pull requests
- Documentation intégrée

### Outils couverts dans cette section

| Outil | Type | Fonction | Complexité |
|-------|------|----------|------------|
| **ArgoCD** | GitOps | Déploiement pull-based | Modérée |
| **Flux** | GitOps | Alternative ArgoCD | Modérée |
| **Tekton** | CI/CD natif K8s | Pipelines cloud-native | Élevée |
| **Jenkins** | CI/CD classique | CI/CD sur Kubernetes | Modérée |
| **GitLab CI** | Platform CI/CD | CI/CD intégré | Faible |

---

## 9.5.1 ArgoCD et Flux

### Introduction à ArgoCD

**ArgoCD** est un outil GitOps déclaratif pour Kubernetes qui synchronise automatiquement l'état du cluster avec les configurations stockées dans Git.

#### Architecture ArgoCD

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Git Repos     │───▶│     ArgoCD      │───▶│   Kubernetes    │
│ (Manifests YAML)│    │   (Controller)  │    │    Cluster      │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         ▲                       │                       │
         │                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Developers    │    │   ArgoCD UI     │    │   Applications  │
│  (Git commits)  │    │ (Management)    │    │   (Running)     │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

### Installation d'ArgoCD

#### Installation via manifests

```bash
# Créer le namespace
kubectl create namespace argocd

# Installer ArgoCD
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Vérifier l'installation
kubectl get pods -n argocd
```

#### Installation via Helm (Recommandé)

```bash
# Ajouter le repository Helm
helm repo add argo https://argoproj.github.io/argo-helm
helm repo update

# Créer le fichier de valeurs personnalisées
cat <<EOF > argocd-values.yaml
global:
  domain: argocd.example.com

server:
  # Configuration Ingress
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
      cert-manager.io/cluster-issuer: letsencrypt-prod
    hosts:
      - argocd.example.com
    tls:
      - hosts:
          - argocd.example.com
        secretName: argocd-server-tls

  # Configuration additionnelle
  config:
    # Désactiver l'authentification pour demo (pas en production!)
    # users.anonymous.enabled: true

    # Configuration OIDC (optionnel)
    oidc.config: |
      name: OIDC
      issuer: https://your-oidc-provider.com
      clientId: argocd
      clientSecret: $oidc.clientSecret
      requestedScopes: ["openid", "profile", "email"]

  # Repositories GitOps
  additionalProjects:
    - name: default
      namespace: argocd
      additionalLabels: {}
      description: Default project
      sourceRepos:
        - '*'
      destinations:
        - namespace: '*'
          server: https://kubernetes.default.svc
      clusterResourceWhitelist:
        - group: '*'
          kind: '*'

# Configuration des dépôts
configs:
  repositories:
    my-private-repo:
      url: https://github.com/company/k8s-configs
      type: git
      sshPrivateKey: |
        -----BEGIN OPENSSH PRIVATE KEY-----
        b3BlbnNzaC1rZXktdjEAAAAABG5vbmUAAAAEbm9uZQAAAAAAAAABAAAAlwAAAAdzc2gtcn
        ...
        -----END OPENSSH PRIVATE KEY-----

repoServer:
  # Configuration pour repositories privés
  env:
    - name: ARGOCD_EXEC_TIMEOUT
      value: "300s"

  # Ressources pour traitement des gros repos
  resources:
    requests:
      cpu: 250m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1Gi

# Persistance pour les données
redis:
  enabled: true

controller:
  # Métriques pour monitoring
  metrics:
    enabled: true
    serviceMonitor:
      enabled: true
      namespace: monitoring
EOF

# Installer ArgoCD
helm install argocd argo/argo-cd -n argocd --create-namespace -f argocd-values.yaml
```

### Configuration initiale d'ArgoCD

#### Accès à l'interface web

```bash
# Récupérer le mot de passe admin par défaut
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# Port-forward pour accès local (développement)
kubectl port-forward svc/argocd-server -n argocd 8080:443

# Accès via https://localhost:8080
# Username: admin
# Password: [mot de passe récupéré ci-dessus]
```

#### Connexion avec CLI ArgoCD

```bash
# Installation du CLI ArgoCD
curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
sudo install -m 555 argocd-linux-amd64 /usr/local/bin/argocd

# Connexion au serveur
argocd login argocd.example.com

# Ou via port-forward
argocd login localhost:8080 --insecure

# Changer le mot de passe admin
argocd account update-password
```

### Création d'applications ArgoCD

#### Structure de projet GitOps

```
k8s-gitops-repo/
├── applications/           # Définitions ArgoCD Apps
│   ├── production/
│   │   ├── frontend.yaml
│   │   └── backend.yaml
│   └── staging/
│       ├── frontend.yaml
│       └── backend.yaml
├── manifests/             # Manifests Kubernetes
│   ├── frontend/
│   │   ├── base/
│   │   │   ├── deployment.yaml
│   │   │   ├── service.yaml
│   │   │   └── kustomization.yaml
│   │   └── overlays/
│   │       ├── production/
│   │       │   ├── kustomization.yaml
│   │       │   └── ingress.yaml
│   │       └── staging/
│   │           ├── kustomization.yaml
│   │           └── patches.yaml
│   └── backend/
│       └── ... (structure similaire)
└── charts/               # Helm charts personnalisés
    └── myapp/
        ├── Chart.yaml
        ├── values.yaml
        └── templates/
```

#### Application ArgoCD basique

```yaml
# applications/production/frontend.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: frontend-prod
  namespace: argocd
  labels:
    app: frontend
    env: production
  # Finalizers pour cleanup automatique
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  # Projet ArgoCD (RBAC et policies)
  project: default

  # Source Git
  source:
    repoURL: https://github.com/company/k8s-configs
    path: manifests/frontend/overlays/production
    targetRevision: main  # ou un tag/commit spécifique

    # Si utilisant Kustomize
    kustomize:
      images:
        - newName: registry.company.com/frontend
          newTag: v1.2.3

      # Patches additionnels
      patchesStrategicMerge:
        - |-
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: frontend
          spec:
            replicas: 3

  # Destination
  destination:
    server: https://kubernetes.default.svc  # Cluster local
    namespace: production

  # Politiques de synchronisation
  syncPolicy:
    # Synchronisation automatique
    automated:
      prune: true      # Supprime les ressources obsolètes
      selfHeal: true   # Corrige le drift automatiquement
      allowEmpty: false

    # Hooks de synchronisation
    syncOptions:
      - CreateNamespace=true  # Crée le namespace si inexistant
      - PruneLast=true       # Supprime en dernier
      - RespectIgnoreDifferences=true

    # Stratégie de retry
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m

  # Ignorer certaines différences
  ignoreDifferences:
    - group: apps
      kind: Deployment
      jsonPointers:
        - /spec/replicas  # Ignore les changements HPA
    - group: ""
      kind: Service
      managedFieldsManagers:
        - kube-controller-manager  # Ignore les changements automatiques
```

#### Application avec Helm Chart

```yaml
# applications/production/backend.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: backend-prod
  namespace: argocd
spec:
  project: default

  source:
    repoURL: https://github.com/company/helm-charts
    path: backend
    targetRevision: v2.1.0

    helm:
      # Fichier de valeurs personnalisé
      valueFiles:
        - values-production.yaml

      # Valeurs en ligne (override)
      values: |
        image:
          tag: "v2.1.0"

        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi

        autoscaling:
          enabled: true
          minReplicas: 3
          maxReplicas: 10

      # Paramètres Helm
      parameters:
        - name: service.type
          value: ClusterIP
        - name: ingress.enabled
          value: "true"

  destination:
    server: https://kubernetes.default.svc
    namespace: production

  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
```

### Gestion des applications ArgoCD

#### Via CLI ArgoCD

```bash
# Créer une application
argocd app create frontend-prod \
  --repo https://github.com/company/k8s-configs \
  --path manifests/frontend/overlays/production \
  --dest-server https://kubernetes.default.svc \
  --dest-namespace production \
  --sync-policy automated \
  --auto-prune \
  --self-heal

# Lister les applications
argocd app list

# Obtenir les détails d'une application
argocd app get frontend-prod

# Synchroniser une application
argocd app sync frontend-prod

# Voir l'historique des syncs
argocd app history frontend-prod

# Rollback vers une version précédente
argocd app rollback frontend-prod 10  # ID de l'historique

# Supprimer une application
argocd app delete frontend-prod
```

#### Patterns de déploiement avancés

##### Blue/Green avec ArgoCD

```yaml
# applications/production/frontend-blue.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: frontend-blue
  namespace: argocd
spec:
  source:
    repoURL: https://github.com/company/k8s-configs
    path: manifests/frontend/overlays/production
    targetRevision: v1.2.3  # Version stable
    kustomize:
      namePrefix: blue-
      commonLabels:
        version: blue
        deployment-strategy: blue-green
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
---
# applications/production/frontend-green.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: frontend-green
  namespace: argocd
spec:
  source:
    repoURL: https://github.com/company/k8s-configs
    path: manifests/frontend/overlays/production
    targetRevision: v1.3.0  # Nouvelle version
    kustomize:
      namePrefix: green-
      commonLabels:
        version: green
        deployment-strategy: blue-green
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  syncPolicy:
    automated:
      prune: false  # Ne pas supprimer automatiquement
      selfHeal: true
```

### Introduction à Flux

**Flux** est une alternative à ArgoCD, particulièrement populaire dans l'écosystème CNCF.

#### Différences principales Flux vs ArgoCD

| Aspect | ArgoCD | Flux |
|--------|--------|------|
| **Architecture** | Monolithique + UI | Modulaire, controllers |
| **Interface** | Web UI riche | CLI + Kubernetes native |
| **Multi-tenancy** | Projects + RBAC | Namespaces + RBAC |
| **Helm support** | Intégré | Controller séparé |
| **Complexité** | Moyenne | Plus élevée |
| **Écosystème** | Autonome | Intégré CNCF |

#### Installation de Flux

```bash
# Installation du CLI Flux
curl -s https://fluxcd.io/install.sh | sudo bash

# Vérification des prérequis
flux check --pre

# Bootstrap du cluster (installe Flux et configure le repo)
flux bootstrap github \
  --owner=company \
  --repository=k8s-flux-config \
  --branch=main \
  --path=clusters/production \
  --personal

# Ou pour un repo existant
flux bootstrap git \
  --url=https://github.com/company/k8s-flux-config \
  --branch=main \
  --path=clusters/production
```

#### Configuration Flux avec GitRepository et Kustomization

```yaml
# flux-system/gotk-sync.yaml (généré automatiquement)
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: GitRepository
metadata:
  name: flux-system
  namespace: flux-system
spec:
  interval: 1m0s
  ref:
    branch: main
  secretRef:
    name: flux-system
  url: https://github.com/company/k8s-flux-config
---
apiVersion: kustomize.toolkit.fluxcd.io/v1beta2
kind: Kustomization
metadata:
  name: flux-system
  namespace: flux-system
spec:
  interval: 10m0s
  path: ./clusters/production
  prune: true
  sourceRef:
    kind: GitRepository
    name: flux-system
```

#### Application Flux

```yaml
# apps/frontend/gitrepository.yaml
apiVersion: source.toolkit.fluxcd.io/v1beta2
kind: GitRepository
metadata:
  name: frontend-source
  namespace: flux-system
spec:
  interval: 1m
  ref:
    branch: main
  url: https://github.com/company/frontend-k8s-config
---
# apps/frontend/kustomization.yaml
apiVersion: kustomize.toolkit.fluxcd.io/v1beta2
kind: Kustomization
metadata:
  name: frontend
  namespace: flux-system
spec:
  interval: 5m
  path: "./overlays/production"
  prune: true
  sourceRef:
    kind: GitRepository
    name: frontend-source
  targetNamespace: production

  # Health checks
  healthChecks:
    - apiVersion: apps/v1
      kind: Deployment
      name: frontend
      namespace: production

  # Post-deployment notifications
  postBuild:
    substitute:
      cluster_name: "production-cluster"
    substituteFrom:
      - kind: ConfigMap
        name: cluster-vars
```

---

## 9.5.2 Tekton Pipelines

### Introduction à Tekton

**Tekton** est un framework CI/CD cloud-native conçu spécifiquement pour Kubernetes. Il fournit des ressources Kubernetes pour créer des pipelines de build et de déploiement.

#### Concepts Tekton

**Task**
- Unité de travail atomique
- Collection d'étapes (steps)
- Réutilisable et paramétrable

**Pipeline**
- Collection de tâches ordonnées
- Définit le workflow complet
- Gère les dépendances entre tâches

**PipelineRun**
- Instance d'exécution d'un Pipeline
- Contient les paramètres et ressources spécifiques
- Équivaut à un "job" de CI

**TaskRun**
- Instance d'exécution d'une Task
- Généralement créé automatiquement par PipelineRun

### Installation de Tekton

```bash
# Installer Tekton Pipelines
kubectl apply --filename https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml

# Installer Tekton Dashboard (optionnel)
kubectl apply --filename https://storage.googleapis.com/tekton-releases/dashboard/latest/release.yaml

# Installer Tekton CLI
curl -LO https://github.com/tektoncd/cli/releases/download/v0.32.0/tkn_0.32.0_Linux_x86_64.tar.gz
tar xvzf tkn_0.32.0_Linux_x86_64.tar.gz
sudo install -o root -g root -m 0755 tkn /usr/local/bin/tkn

# Vérifier l'installation
kubectl get pods --namespace tekton-pipelines
tkn version
```

### Création de Tasks Tekton

#### Task simple - Git clone

```yaml
# tasks/git-clone-task.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: git-clone
  labels:
    app.kubernetes.io/version: "0.1"
spec:
  description: Clone un repository Git

  params:
    - name: url
      description: URL du repository Git
      type: string
    - name: revision
      description: Branch/tag/commit à cloner
      type: string
      default: "main"
    - name: subdirectory
      description: Sous-répertoire pour cloner
      type: string
      default: ""

  workspaces:
    - name: output
      description: Workspace pour stocker le code source

  steps:
    - name: clone
      image: alpine/git:latest
      workingDir: $(workspaces.output.path)
      script: |
        #!/usr/bin/env sh
        set -eu

        if [ "$(params.subdirectory)" != "" ]; then
          cleandir=$(echo "$(params.subdirectory)" | sed 's|/||g')
          mkdir -p ${cleandir}
          cd ${cleandir}
        fi

        echo "Cloning $(params.url) at revision $(params.revision)"
        git clone $(params.url) .
        git checkout $(params.revision)
        echo "Successfully cloned repository"

        # Afficher les informations du commit
        echo "=== Git Information ==="
        echo "Commit: $(git rev-parse HEAD)"
        echo "Author: $(git log -1 --pretty=format:'%an <%ae>')"
        echo "Date: $(git log -1 --pretty=format:'%ad')"
        echo "Message: $(git log -1 --pretty=format:'%s')"
```

#### Task build - Docker

```yaml
# tasks/docker-build-task.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: docker-build-push
spec:
  description: Build et push d'une image Docker

  params:
    - name: image
      description: Nom complet de l'image (registry/repo:tag)
      type: string
    - name: dockerfile
      description: Chemin vers le Dockerfile
      type: string
      default: "Dockerfile"
    - name: context
      description: Contexte de build Docker
      type: string
      default: "."

  workspaces:
    - name: source
      description: Workspace contenant le code source
    - name: dockerconfig
      description: Configuration Docker registry
      optional: true

  steps:
    - name: build-and-push
      image: gcr.io/kaniko-project/executor:latest
      workingDir: $(workspaces.source.path)
      env:
        - name: DOCKER_CONFIG
          value: $(workspaces.dockerconfig.path)
      command:
        - /kaniko/executor
      args:
        - --dockerfile=$(params.dockerfile)
        - --context=$(workspaces.source.path)/$(params.context)
        - --destination=$(params.image)
        - --cache=true
        - --cache-ttl=24h
        - --skip-tls-verify  # Seulement pour registries privés sans cert valide

    - name: image-info
      image: alpine:latest
      script: |
        #!/bin/sh
        echo "Image built and pushed successfully:"
        echo "Image: $(params.image)"
        echo "Dockerfile: $(params.dockerfile)"
        echo "Context: $(params.context)"
```

#### Task test - Application

```yaml
# tasks/test-task.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: run-tests
spec:
  description: Exécute les tests unitaires et d'intégration

  params:
    - name: test-command
      description: Commande pour exécuter les tests
      type: string
      default: "npm test"
    - name: image
      description: Image pour exécuter les tests
      type: string
      default: "node:16"

  workspaces:
    - name: source
      description: Workspace contenant le code source

  steps:
    - name: install-dependencies
      image: $(params.image)
      workingDir: $(workspaces.source.path)
      script: |
        #!/bin/bash
        set -e

        # Installation des dépendances selon le type de projet
        if [ -f "package.json" ]; then
          echo "Installing npm dependencies..."
          npm ci
        elif [ -f "requirements.txt" ]; then
          echo "Installing pip dependencies..."
          pip install -r requirements.txt
        elif [ -f "go.mod" ]; then
          echo "Installing go dependencies..."
          go mod download
        else
          echo "No known dependency file found"
        fi

    - name: run-unit-tests
      image: $(params.image)
      workingDir: $(workspaces.source.path)
      script: |
        #!/bin/bash
        set -e

        echo "Running unit tests..."
        $(params.test-command)

        # Générer un rapport de couverture si possible
        if [ -f "package.json" ]; then
          npm run coverage || echo "No coverage script found"
        fi

    - name: test-results
      image: alpine:latest
      script: |
        #!/bin/sh
        echo "=== Test Results ==="
        echo "Tests completed successfully"
        echo "Test command: $(params.test-command)"
        echo "Image used: $(params.image)"
```

### Création de Pipelines

#### Pipeline complet CI/CD

```yaml
# pipelines/app-ci-cd-pipeline.yaml
apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: app-ci-cd-pipeline
spec:
  description: Pipeline complet de CI/CD pour application

  params:
    - name: git-url
      type: string
      description: URL du repository Git
    - name: git-revision
      type: string
      description: Branch/tag/commit Git
      default: main
    - name: image-registry
      type: string
      description: Registry pour les images Docker
      default: "registry.example.com"
    - name: image-name
      type: string
      description: Nom de l'image
    - name: deploy-environment
      type: string
      description: Environnement de déploiement
      default: "staging"

  workspaces:
    - name: shared-data
      description: Workspace partagé entre les tâches
    - name: docker-credentials
      description: Credentials pour Docker registry

  tasks:
    # 1. Cloner le code source
    - name: fetch-source
      taskRef:
        name: git-clone
      params:
        - name: url
          value: $(params.git-url)
        - name: revision
          value: $(params.git-revision)
      workspaces:
        - name: output
          workspace: shared-data

    # 2. Exécuter les tests
    - name: run-tests
      taskRef:
        name: run-tests
      params:
        - name: test-command
          value: "npm test"
      workspaces:
        - name: source
          workspace: shared-data
      runAfter:
        - fetch-source

    # 3. Build et push de l'image Docker
    - name: build-image
      taskRef:
        name: docker-build-push
      params:
        - name: image
          value: "$(params.image-registry)/$(params.image-name):$(tasks.fetch-source.results.commit)"
        - name: dockerfile
          value: "Dockerfile"
      workspaces:
        - name: source
          workspace: shared-data
        - name: dockerconfig
          workspace: docker-credentials
      runAfter:
        - run-tests

    # 4. Déploiement via GitOps
    - name: update-gitops-repo
      taskRef:
        name: update-deployment
      params:
        - name: image
          value: "$(params.image-registry)/$(params.image-name):$(tasks.fetch-source.results.commit)"
        - name: environment
          value: $(params.deploy-environment)
        - name: gitops-repo
          value: "https://github.com/company/k8s-gitops-config"
      runAfter:
        - build-image

  # Résultats du pipeline
  results:
    - name: image-url
      description: URL complète de l'image buildée
      value: "$(tasks.build-image.results.IMAGE_URL)"
    - name: git-commit
      description: Commit SHA déployé
      value: "$(tasks.fetch-source.results.commit)"
```

#### Task GitOps - Mise à jour des manifests

```yaml
# tasks/gitops-update-task.yaml
apiVersion: tekton.dev/v1beta1
kind: Task
metadata:
  name: update-deployment
spec:
  description: Met à jour les manifests GitOps avec la nouvelle image

  params:
    - name: image
      type: string
      description: Nouvelle image à déployer
    - name: environment
      type: string
      description: Environnement cible
    - name: gitops-repo
      type: string
      description: Repository GitOps
    - name: app-name
      type: string
      default: "myapp"

  workspaces:
    - name: gitops-workspace
      description: Workspace pour le repo GitOps

  steps:
    - name: update-manifests
      image: alpine/git:latest
      workingDir: $(workspaces.gitops-workspace.path)
      script: |
        #!/usr/bin/env sh
        set -e

        # Cloner le repo GitOps
        git clone $(params.gitops-repo) gitops-repo
        cd gitops-repo

        # Configuration Git
        git config user.email "tekton@company.com"
        git config user.name "Tekton Pipeline"

        # Trouver et mettre à jour les fichiers Kustomization
        KUSTOMIZATION_FILE="applications/$(params.environment)/$(params.app-name)/kustomization.yaml"

        if [ -f "$KUSTOMIZATION_FILE" ]; then
          echo "Updating image in $KUSTOMIZATION_FILE"

          # Utiliser kustomize pour mettre à jour l'image
          curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
          ./kustomize edit set image myapp=$(params.image)

          # Vérifier les changements
          git diff

          # Commit et push
          git add .
          git commit -m "Update $(params.app-name) image to $(params.image) in $(params.environment)

          Triggered by: Tekton Pipeline
          Environment: $(params.environment)
          Image: $(params.image)"

          git push origin main

          echo "Successfully updated GitOps repository"
        else
          echo "Error: Kustomization file not found at $KUSTOMIZATION_FILE"
          exit 1
        fi

    - name: notify-success
      image: curlimages/curl:latest
      script: |
        #!/bin/sh
        echo "GitOps update completed successfully!"
        echo "Image: $(params.image)"
        echo "Environment: $(params.environment)"
        echo "Application: $(params.app-name)"

        # Optionnel: notification Slack/Teams
        # curl -X POST -H 'Content-type: application/json' \
        #   --data '{"text":"Deployment updated: $(params.app-name) → $(params.image)"}' \
        #   $SLACK_WEBHOOK_URL
```

### Exécution des Pipelines

#### PipelineRun - Exécution manuelle

```yaml
# pipelineruns/manual-run.yaml
apiVersion: tekton.dev/v1beta1
kind: PipelineRun
metadata:
  name: app-build-run-20240101-001
  labels:
    app: myapp
    environment: staging
    trigger: manual
spec:
  pipelineRef:
    name: app-ci-cd-pipeline

  # Paramètres spécifiques à cette exécution
  params:
    - name: git-url
      value: "https://github.com/company/myapp"
    - name: git-revision
      value: "v1.2.3"
    - name: image-registry
      value: "registry.company.com"
    - name: image-name
      value: "myapp"
    - name: deploy-environment
      value: "staging"

  # Workspaces avec stockage
  workspaces:
    - name: shared-data
      persistentVolumeClaim:
        claimName: tekton-workspace-pvc
    - name: docker-credentials
      secret:
        secretName: docker-registry-credentials

  # Timeout global
  timeouts:
    pipeline: "1h0m0s"
    tasks: "30m0s"

  # Stratégie de retry
  retries: 1
```

#### PVC pour workspace Tekton

```yaml
# storage/tekton-workspace-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: tekton-workspace-pvc
  namespace: tekton-pipelines
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: local-storage
---
# Secret pour registry Docker
apiVersion: v1
kind: Secret
metadata:
  name: docker-registry-credentials
  namespace: tekton-pipelines
  annotations:
    tekton.dev/docker-0: "registry.company.com"
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: eyJhdXRocyI6eyJyZWdpc3RyeS5jb21wYW55LmNvbSI6eyJ1c2VybmFtZSI6InRla3RvbiIsInBhc3N3b3JkIjoic2VjcmV0IiwiYXV0aCI6ImRHVnJkRzl1T25ObFkzSmxkQT09In19fQ==
```

### Triggers et automatisation

#### EventListener pour Git webhooks

```yaml
# triggers/github-eventlistener.yaml
apiVersion: triggers.tekton.dev/v1beta1
kind: EventListener
metadata:
  name: github-webhook-listener
  namespace: tekton-pipelines
spec:
  serviceAccountName: tekton-triggers-sa

  triggers:
    - name: github-push-trigger
      interceptors:
        # Filtre pour les événements GitHub
        - name: github
          params:
            - name: secretRef
              value:
                secretName: github-webhook-secret
                secretKey: secretToken
            - name: eventTypes
              value: ["push"]

        # Filtre pour la branche main uniquement
        - name: cel
          params:
            - name: filter
              value: "body.ref == 'refs/heads/main'"

      bindings:
        - ref: github-push-binding

      template:
        ref: app-pipeline-template

---
# TriggerBinding pour extraire les données du webhook
apiVersion: triggers.tekton.dev/v1beta1
kind: TriggerBinding
metadata:
  name: github-push-binding
spec:
  params:
    - name: git-repo-url
      value: $(body.repository.clone_url)
    - name: git-repo-name
      value: $(body.repository.name)
    - name: git-revision
      value: $(body.head_commit.id)
    - name: git-commit-message
      value: $(body.head_commit.message)
    - name: git-commit-author
      value: $(body.head_commit.author.name)

---
# TriggerTemplate pour créer le PipelineRun
apiVersion: triggers.tekton.dev/v1beta1
kind: TriggerTemplate
metadata:
  name: app-pipeline-template
spec:
  params:
    - name: git-repo-url
      description: URL du repository Git
    - name: git-repo-name
      description: Nom du repository
    - name: git-revision
      description: Commit SHA
    - name: git-commit-message
      description: Message du commit
    - name: git-commit-author
      description: Auteur du commit

  resourcetemplates:
    - apiVersion: tekton.dev/v1beta1
      kind: PipelineRun
      metadata:
        generateName: $(tt.params.git-repo-name)-run-
        labels:
          app: $(tt.params.git-repo-name)
          trigger: webhook
          commit: $(tt.params.git-revision)
      spec:
        pipelineRef:
          name: app-ci-cd-pipeline
        params:
          - name: git-url
            value: $(tt.params.git-repo-url)
          - name: git-revision
            value: $(tt.params.git-revision)
          - name: image-name
            value: $(tt.params.git-repo-name)
          - name: deploy-environment
            value: staging
        workspaces:
          - name: shared-data
            persistentVolumeClaim:
              claimName: tekton-workspace-pvc
          - name: docker-credentials
            secret:
              secretName: docker-registry-credentials
```

#### Service et Ingress pour EventListener

```yaml
# triggers/eventlistener-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: el-github-webhook-listener
  namespace: tekton-pipelines
spec:
  selector:
    eventlistener: github-webhook-listener
  ports:
    - port: 8080
      targetPort: 8080
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tekton-webhooks
  namespace: tekton-pipelines
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - tekton-webhooks.example.com
      secretName: tekton-webhooks-tls
  rules:
    - host: tekton-webhooks.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: el-github-webhook-listener
                port:
                  number: 8080
```

---

## 9.5.3 Jenkins sur Kubernetes

### Introduction Jenkins sur K8s

**Jenkins** reste un choix populaire pour CI/CD, et son exécution sur Kubernetes offre de nombreux avantages : scalabilité, isolation des builds, et gestion simplifiée des agents.

#### Avantages Jenkins sur Kubernetes

**Scalabilité dynamique**
- Agents créés à la demande
- Pas de gestion d'infrastructure fixe
- Coûts optimisés

**Isolation**
- Chaque build dans un pod séparé
- Pas de pollution entre builds
- Sécurité renforcée

**Maintenance simplifiée**
- Pas de configuration d'agents
- Images standardisées
- Deployment déclaratif

### Installation Jenkins avec Helm

```bash
# Ajouter le repository Jenkins
helm repo add jenkins https://charts.jenkins.io
helm repo update

# Créer le namespace
kubectl create namespace jenkins

# Fichier de configuration personnalisée
cat <<EOF > jenkins-values.yaml
controller:
  # Image Jenkins LTS
  image: "jenkins/jenkins"
  tag: "lts"

  # Ressources pour le master
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi

  # Stockage persistant
  persistence:
    enabled: true
    storageClass: local-storage
    size: 50Gi

  # Configuration JVM
  javaOpts: "-Xmx3g -Xms1g"

  # Ingress pour accès externe
  ingress:
    enabled: true
    ingressClassName: nginx
    hostName: jenkins.example.com
    annotations:
      nginx.ingress.kubernetes.io/ssl-redirect: "true"
      cert-manager.io/cluster-issuer: letsencrypt-prod
    tls:
      - secretName: jenkins-tls
        hosts:
          - jenkins.example.com

  # Sécurité et authentification
  securityRealm: |-
    <securityRealm class="hudson.security.HudsonPrivateSecurityRealm">
      <disableSignup>true</disableSignup>
      <enableCaptcha>false</enableCaptcha>
    </securityRealm>

  authorizationStrategy: |-
    <authorizationStrategy class="hudson.security.FullControlOnceLoggedInAuthorizationStrategy">
      <denyAnonymousReadAccess>true</denyAnonymousReadAccess>
    </authorizationStrategy>

  # Plugins Jenkins à installer automatiquement
  installPlugins:
    - kubernetes:4000.v277f311e8a_b_5  # Support Kubernetes
    - workflow-aggregator:596.v8c21c963d92d  # Pipeline
    - git:5.0.0  # Git SCM
    - configuration-as-code:1569.vb_72405b_80249  # JCasC
    - blueocean:1.25.8  # Interface moderne
    - docker-workflow:572.v950f58993843  # Docker
    - kubernetes-credentials-provider:1.208.v128ee9800c04
    - prometheus:2.2.3  # Métriques
    - github-branch-source:1703.vd5a_2b_29c6cdc
    - pipeline-stage-view:2.25

  # Configuration as Code (JCasC)
  JCasC:
    defaultConfig: true
    configScripts:
      kubernetes-config: |
        jenkins:
          clouds:
            - kubernetes:
                name: "kubernetes"
                serverUrl: "https://kubernetes.default"
                namespace: "jenkins"
                jenkinsUrl: "http://jenkins.jenkins.svc.cluster.local:8080"
                jenkinsTunnel: "jenkins-agent.jenkins.svc.cluster.local:50000"
                connectTimeout: 5
                readTimeout: 15
                retentionTimeout: 5
                maxRequestsPerHost: 32
                templates:
                  - name: "default-agent"
                    label: "jenkins-agent"
                    nodeUsageMode: NORMAL
                    containers:
                      - name: "jnlp"
                        image: "jenkins/inbound-agent:latest"
                        workingDir: "/home/jenkins/agent"
                        resourceRequestCpu: "500m"
                        resourceRequestMemory: "1Gi"
                        resourceLimitCpu: "1000m"
                        resourceLimitMemory: "2Gi"
                  - name: "docker-agent"
                    label: "docker"
                    nodeUsageMode: NORMAL
                    containers:
                      - name: "docker"
                        image: "docker:dind"
                        privileged: true
                        resourceRequestCpu: "500m"
                        resourceRequestMemory: "1Gi"
                        command: "dockerd"
                        args: "--host=unix:///var/run/docker.sock --host=tcp://0.0.0.0:2376"
                      - name: "jnlp"
                        image: "jenkins/inbound-agent:latest"
                        resourceRequestCpu: "100m"
                        resourceRequestMemory: "256Mi"

# Désactiver les agents statiques
agent:
  enabled: false

# Service Account avec permissions
serviceAccount:
  create: true
  name: jenkins
  annotations:
    meta.helm.sh/release-name: jenkins
    meta.helm.sh/release-namespace: jenkins

rbac:
  create: true
  readSecrets: true
EOF

# Installer Jenkins
helm install jenkins jenkins/jenkins -n jenkins -f jenkins-values.yaml
```

### Configuration RBAC pour Jenkins

```yaml
# rbac/jenkins-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: jenkins
  namespace: jenkins
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: jenkins-admin
rules:
  # Permissions pour gérer les pods (agents)
  - apiGroups: [""]
    resources: ["pods", "pods/exec", "pods/log"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]

  # Permissions pour les services
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]

  # Permissions pour les secrets et configmaps
  - apiGroups: [""]
    resources: ["secrets", "configmaps"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]

  # Permissions pour les déploiements
  - apiGroups: ["apps"]
    resources: ["deployments", "replicasets"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]

  # Permissions pour les ingress
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses"]
    verbs: ["create", "delete", "get", "list", "patch", "update", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: jenkins-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: jenkins-admin
subjects:
  - kind: ServiceAccount
    name: jenkins
    namespace: jenkins
```

### Pipelines Jenkins pour Kubernetes

#### Pipeline basique - Jenkinsfile

```groovy
// Jenkinsfile pour application Kubernetes
pipeline {
    agent {
        kubernetes {
            yaml """
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: docker
    image: docker:dind
    securityContext:
      privileged: true
    volumeMounts:
    - name: docker-sock
      mountPath: /var/run/docker.sock
  - name: kubectl
    image: bitnami/kubectl:latest
    command: ['cat']
    tty: true
  - name: helm
    image: alpine/helm:latest
    command: ['cat']
    tty: true
  volumes:
  - name: docker-sock
    hostPath:
      path: /var/run/docker.sock
"""
        }
    }

    environment {
        DOCKER_REGISTRY = 'registry.company.com'
        IMAGE_NAME = 'myapp'
        KUBE_NAMESPACE = 'default'
        GIT_COMMIT_SHORT = sh(
            script: 'git rev-parse --short HEAD',
            returnStdout: true
        ).trim()
    }

    stages {
        stage('Checkout') {
            steps {
                checkout scm
                script {
                    env.BUILD_VERSION = "${env.BUILD_NUMBER}-${env.GIT_COMMIT_SHORT}"
                }
            }
        }

        stage('Test') {
            steps {
                script {
                    // Tests selon le type d'application
                    if (fileExists('package.json')) {
                        sh 'npm ci && npm test'
                    } else if (fileExists('requirements.txt')) {
                        sh 'pip install -r requirements.txt && python -m pytest'
                    } else if (fileExists('go.mod')) {
                        sh 'go test ./...'
                    }
                }
            }
            post {
                always {
                    publishTestResults testResultsPattern: 'test-results.xml'
                }
            }
        }

        stage('Build Docker Image') {
            steps {
                container('docker') {
                    script {
                        def image = docker.build("${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_VERSION}")

                        // Security scan (optionnel)
                        sh "docker run --rm -v /var/run/docker.sock:/var/run/docker.sock aquasec/trivy:latest image ${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_VERSION}"

                        // Push de l'image
                        docker.withRegistry("https://${DOCKER_REGISTRY}", 'docker-registry-credentials') {
                            image.push()
                            image.push('latest')
                        }
                    }
                }
            }
        }

        stage('Deploy to Staging') {
            when {
                branch 'develop'
            }
            steps {
                container('kubectl') {
                    script {
                        // Mise à jour du deployment avec la nouvelle image
                        sh """
                            kubectl set image deployment/myapp-staging \\
                                myapp=${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_VERSION} \\
                                -n staging

                            kubectl rollout status deployment/myapp-staging -n staging --timeout=300s
                        """
                    }
                }
            }
        }

        stage('Deploy to Production') {
            when {
                branch 'main'
            }
            steps {
                script {
                    // Demande d'approbation manuelle pour la production
                    input message: 'Deploy to Production?', ok: 'Deploy',
                          submitterParameter: 'APPROVER'
                }

                container('helm') {
                    script {
                        // Déploiement avec Helm
                        sh """
                            helm upgrade --install myapp-prod ./helm-chart \\
                                --namespace production \\
                                --set image.tag=${BUILD_VERSION} \\
                                --set image.repository=${DOCKER_REGISTRY}/${IMAGE_NAME} \\
                                --wait --timeout=10m
                        """
                    }
                }
            }
            post {
                success {
                    // Notification de succès
                    slackSend channel: '#deployments',
                              color: 'good',
                              message: "✅ Production deployment successful: ${IMAGE_NAME}:${BUILD_VERSION} by ${env.APPROVER}"
                }
                failure {
                    // Notification d'échec et rollback
                    container('helm') {
                        sh "helm rollback myapp-prod --namespace production"
                    }
                    slackSend channel: '#deployments',
                              color: 'danger',
                              message: "❌ Production deployment failed: ${IMAGE_NAME}:${BUILD_VERSION}. Rolled back automatically."
                }
            }
        }

        stage('GitOps Update') {
            when {
                anyOf {
                    branch 'main'
                    branch 'develop'
                }
            }
            steps {
                script {
                    def environment = env.BRANCH_NAME == 'main' ? 'production' : 'staging'

                    // Clone du repo GitOps et mise à jour
                    sh """
                        git clone https://github.com/company/k8s-gitops-config gitops-repo
                        cd gitops-repo

                        # Configuration Git
                        git config user.email "jenkins@company.com"
                        git config user.name "Jenkins Pipeline"

                        # Mise à jour avec kustomize
                        cd applications/${environment}/myapp
                        kustomize edit set image myapp=${DOCKER_REGISTRY}/${IMAGE_NAME}:${BUILD_VERSION}

                        # Commit et push
                        git add .
                        git commit -m "Update myapp image to ${BUILD_VERSION} in ${environment}"
                        git push origin main
                    """
                }
            }
        }
    }

    post {
        always {
            // Nettoyage des images locales
            sh 'docker system prune -f || true'

            // Archive des artifacts
            archiveArtifacts artifacts: 'target/*.jar, dist/*', allowEmptyArchive: true
        }

        success {
            echo "✅ Pipeline completed successfully!"
        }

        failure {
            echo "❌ Pipeline failed!"
            // Notification d'équipe
            emailext (
                subject: "Pipeline Failed: ${env.JOB_NAME} - ${env.BUILD_NUMBER}",
                body: "Pipeline failed for ${env.JOB_NAME} build ${env.BUILD_NUMBER}. Check Jenkins for details.",
                recipientProviders: [developers(), requestor()]
            )
        }
    }
}
```

#### Pipeline multi-branche avec stratégies

```groovy
// Jenkinsfile.multibranch
pipeline {
    agent none

    environment {
        DOCKER_REGISTRY = 'registry.company.com'
        IMAGE_NAME = 'myapp'
    }

    stages {
        stage('Branch Strategy') {
            parallel {
                stage('Feature Branch') {
                    when {
                        not {
                            anyOf {
                                branch 'main'
                                branch 'develop'
                                branch 'release/*'
                            }
                        }
                    }
                    agent {
                        kubernetes {
                            yamlFile 'k8s/jenkins-agent.yaml'
                        }
                    }
                    steps {
                        echo "🔨 Building feature branch: ${env.BRANCH_NAME}"
                        sh 'make test'
                        sh 'make build'
                        // Pas de déploiement pour les feature branches
                    }
                }

                stage('Develop Branch') {
                    when { branch 'develop' }
                    agent {
                        kubernetes {
                            yamlFile 'k8s/jenkins-agent.yaml'
                        }
                    }
                    stages {
                        stage('Build & Test') {
                            steps {
                                sh 'make test coverage'
                                sh 'make build'
                                publishCoverage adapters: [coberturaAdapter('coverage.xml')]
                            }
                        }
                        stage('Deploy Dev') {
                            steps {
                                sh 'make deploy-dev'
                                sh 'make integration-tests'
                            }
                        }
                    }
                }

                stage('Release Branch') {
                    when { branch 'release/*' }
                    agent {
                        kubernetes {
                            yamlFile 'k8s/jenkins-agent.yaml'
                        }
                    }
                    stages {
                        stage('Build & Test') {
                            steps {
                                sh 'make test'
                                sh 'make security-scan'
                                sh 'make build'
                            }
                        }
                        stage('Deploy Staging') {
                            steps {
                                sh 'make deploy-staging'
                                sh 'make e2e-tests'
                            }
                        }
                        stage('Performance Tests') {
                            steps {
                                sh 'make performance-tests'
                                publishPerformanceReport parsers: [[$class: 'JMeterParser', glob: 'results.jtl']]
                            }
                        }
                    }
                }

                stage('Main Branch') {
                    when { branch 'main' }
                    agent {
                        kubernetes {
                            yamlFile 'k8s/jenkins-agent-prod.yaml'
                        }
                    }
                    stages {
                        stage('Build Release') {
                            steps {
                                sh 'make test'
                                sh 'make build-release'
                                sh 'make sign-artifacts'  // Signature des artifacts
                            }
                        }
                        stage('Deploy Production') {
                            steps {
                                input message: 'Deploy to Production?',
                                      parameters: [
                                          choice(name: 'DEPLOYMENT_STRATEGY',
                                                choices: ['rolling', 'blue-green', 'canary'],
                                                description: 'Deployment strategy')
                                      ]

                                script {
                                    switch(params.DEPLOYMENT_STRATEGY) {
                                        case 'blue-green':
                                            sh 'make deploy-blue-green'
                                            break
                                        case 'canary':
                                            sh 'make deploy-canary'
                                            break
                                        default:
                                            sh 'make deploy-rolling'
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    post {
        always {
            script {
                // Nettoyage conditionnel selon la branche
                if (env.BRANCH_NAME ==~ /feature\/.*/) {
                    echo "Cleanup feature branch resources"
                    sh 'make cleanup-feature || true'
                }
            }
        }
    }
}
```

---

## 9.5.4 Intégration GitLab CI

### Introduction GitLab CI/CD

**GitLab CI/CD** offre une solution intégrée de CI/CD avec un support natif excellent pour Kubernetes via le GitLab Agent.

#### Avantages GitLab CI/CD

**Intégration native**
- Git + CI/CD + Container Registry dans une seule plateforme
- Configuration as Code via `.gitlab-ci.yml`
- Auto DevOps pour démarrage rapide

**Kubernetes native**
- GitLab Agent pour connexion sécurisée
- Déploiement review apps automatique
- GitOps intégré

### Configuration GitLab Agent

#### Installation de l'Agent GitLab

```bash
# Créer le namespace
kubectl create namespace gitlab-agent

# Créer la configuration de l'agent
cat <<EOF > gitlab-agent-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitlab-agent-config
  namespace: gitlab-agent
data:
  config.yaml: |
    gitops:
      # Repository GitOps à surveiller
      manifest_projects:
      - id: "group/k8s-configs"
        default_namespace: "default"
        paths:
        - glob: 'manifests/**/*.yaml'
        - glob: 'applications/**/*.yaml'
        reconcile_timeout: 3600s
        dry_run_strategy: none
        prune: true
        prune_timeout: 3600s
        prune_propagation_policy: foreground
        inventory_policy: must_match

    # Accès pour CI/CD
    ci_access:
      groups:
      - id: "group/subgroup"
        default_namespace: "gitlab-ci"
      projects:
      - id: "group/project"
        default_namespace: "default"

    # Configuration des flux
    flux:
      enabled: true
      namespace: "flux-system"
EOF

kubectl apply -f gitlab-agent-config.yaml

# Installer l'agent avec Helm
helm repo add gitlab https://charts.gitlab.io
helm install gitlab-agent gitlab/gitlab-agent \
  --namespace gitlab-agent \
  --set config.secretName=gitlab-agent-token \
  --set config.kasAddress=wss://kas.gitlab.example.com
```

#### Configuration GitLab Agent Token

```bash
# Token à récupérer depuis l'interface GitLab
# Infrastructure > Kubernetes clusters > Connect a cluster

kubectl create secret generic gitlab-agent-token \
  --from-literal=token="YOUR_GITLAB_AGENT_TOKEN" \
  --namespace gitlab-agent
```

### Pipeline GitLab CI/CD pour Kubernetes

#### Configuration .gitlab-ci.yml basique

```yaml
# .gitlab-ci.yml
# Configuration CI/CD GitLab pour déploiement Kubernetes

variables:
  DOCKER_REGISTRY: $CI_REGISTRY
  IMAGE_NAME: $CI_PROJECT_PATH
  KUBE_NAMESPACE: $CI_PROJECT_NAME
  DOCKER_DRIVER: overlay2
  KUBERNETES_MEMORY_LIMIT: 1Gi
  KUBERNETES_MEMORY_REQUEST: 512Mi
  KUBERNETES_CPU_LIMIT: 500m
  KUBERNETES_CPU_REQUEST: 250m

# Stages du pipeline
stages:
  - test
  - build
  - security
  - deploy
  - cleanup

# Templates pour réutilisation
.docker_template: &docker_template
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: "/certs"
  before_script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY

.kubectl_template: &kubectl_template
  image: bitnami/kubectl:latest
  before_script:
    # Le GitLab Agent gère automatiquement l'authentification
    - kubectl version --client

# Tests unitaires
unit_tests:
  stage: test
  image: node:18-alpine
  script:
    - npm ci
    - npm run test:unit
    - npm run coverage
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml
      junit: junit.xml
    paths:
      - coverage/
    expire_in: 1 week
  coverage: '/Lines\s*:\s*(\d+\.\d+)%/'

# Tests d'intégration
integration_tests:
  stage: test
  image: node:18-alpine
  services:
    - postgres:13-alpine
    - redis:7-alpine
  variables:
    POSTGRES_DB: testdb
    POSTGRES_USER: test
    POSTGRES_PASSWORD: test
    REDIS_URL: redis://redis:6379
  script:
    - npm ci
    - npm run test:integration
  artifacts:
    reports:
      junit: junit-integration.xml
    paths:
      - test-results/
    expire_in: 1 week

# Build de l'image Docker
build_image:
  <<: *docker_template
  stage: build
  script:
    # Tag avec le commit SHA et la branche
    - export IMAGE_TAG=${CI_COMMIT_SHA:0:8}
    - export IMAGE_BRANCH=${CI_COMMIT_REF_SLUG}

    # Build multi-stage pour optimisation
    - docker build --target production
      --tag $CI_REGISTRY_IMAGE:$IMAGE_TAG
      --tag $CI_REGISTRY_IMAGE:$IMAGE_BRANCH
      --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
      --build-arg VCS_REF=$CI_COMMIT_SHA
      --build-arg VERSION=$CI_COMMIT_TAG
      .

    # Push des images
    - docker push $CI_REGISTRY_IMAGE:$IMAGE_TAG
    - docker push $CI_REGISTRY_IMAGE:$IMAGE_BRANCH

    # Tag latest pour main branch
    - |
      if [ "$CI_COMMIT_REF_NAME" = "main" ]; then
        docker tag $CI_REGISTRY_IMAGE:$IMAGE_TAG $CI_REGISTRY_IMAGE:latest
        docker push $CI_REGISTRY_IMAGE:latest
      fi

  # Sauvegarder les métadonnées de l'image
  after_script:
    - echo "IMAGE_TAG=${CI_COMMIT_SHA:0:8}" >> build.env
    - echo "IMAGE_FULL_NAME=$CI_REGISTRY_IMAGE:${CI_COMMIT_SHA:0:8}" >> build.env

  artifacts:
    reports:
      dotenv: build.env
    expire_in: 1 hour

# Scan de sécurité avec Trivy
security_scan:
  stage: security
  image: aquasec/trivy:latest
  script:
    - trivy image
      --exit-code 1
      --severity HIGH,CRITICAL
      --format template
      --template "@/contrib/gitlab.tpl"
      --output gl-container-scanning-report.json
      $CI_REGISTRY_IMAGE:${CI_COMMIT_SHA:0:8}
  artifacts:
    reports:
      container_scanning: gl-container-scanning-report.json
    expire_in: 1 week
  allow_failure: true

# Déploiement en review (branches feature)
deploy_review:
  <<: *kubectl_template
  stage: deploy
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    url: https://$CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG.example.com
    on_stop: cleanup_review
    auto_stop_in: 1 day
  script:
    # Créer le namespace pour la review app
    - kubectl create namespace $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG || true

    # Déployer avec Helm et valeurs personnalisées
    - |
      helm upgrade --install $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG ./helm-chart \
        --namespace $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG \
        --set image.repository=$CI_REGISTRY_IMAGE \
        --set image.tag=${CI_COMMIT_SHA:0:8} \
        --set ingress.enabled=true \
        --set ingress.hosts[0].host=$CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG.example.com \
        --set ingress.hosts[0].paths[0].path=/ \
        --set ingress.hosts[0].paths[0].pathType=Prefix \
        --set resources.requests.memory=256Mi \
        --set resources.requests.cpu=100m \
        --set resources.limits.memory=512Mi \
        --set resources.limits.cpu=200m \
        --set replicaCount=1 \
        --wait --timeout=300s

    # Attendre que le déploiement soit prêt
    - kubectl rollout status deployment/$CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG
      --namespace $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG --timeout=300s

    # Afficher l'URL de la review app
    - echo "Review app deployed at https://$CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG.example.com"

  rules:
    - if: $CI_MERGE_REQUEST_IID
      when: manual
    - if: $CI_COMMIT_REF_NAME != "main" && $CI_COMMIT_REF_NAME != "develop"

# Déploiement staging (branche develop)
deploy_staging:
  <<: *kubectl_template
  stage: deploy
  environment:
    name: staging
    url: https://staging-$CI_PROJECT_NAME.example.com
  script:
    - |
      helm upgrade --install $CI_PROJECT_NAME-staging ./helm-chart \
        --namespace staging \
        --values helm-chart/values-staging.yaml \
        --set image.repository=$CI_REGISTRY_IMAGE \
        --set image.tag=${CI_COMMIT_SHA:0:8} \
        --wait --timeout=600s

    # Tests de smoke après déploiement
    - kubectl run smoke-test-$CI_PIPELINE_ID
      --image=curlimages/curl:latest
      --namespace staging
      --rm -i --restart=Never
      -- curl -f https://staging-$CI_PROJECT_NAME.example.com/health

    # Notification Slack
    - |
      curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"✅ Staging deployment successful: $CI_PROJECT_NAME:${CI_COMMIT_SHA:0:8}\"}" \
        $SLACK_WEBHOOK_URL || true

  rules:
    - if: $CI_COMMIT_REF_NAME == "develop"

# Déploiement production (branche main)
deploy_production:
  <<: *kubectl_template
  stage: deploy
  environment:
    name: production
    url: https://$CI_PROJECT_NAME.example.com
  script:
    # Vérifications pré-déploiement
    - echo "Running pre-deployment checks..."
    - kubectl get nodes
    - kubectl get pods -n production

    # Déploiement avec stratégie rolling update
    - |
      helm upgrade --install $CI_PROJECT_NAME ./helm-chart \
        --namespace production \
        --values helm-chart/values-production.yaml \
        --set image.repository=$CI_REGISTRY_IMAGE \
        --set image.tag=${CI_COMMIT_SHA:0:8} \
        --set deployment.strategy.type=RollingUpdate \
        --set deployment.strategy.rollingUpdate.maxUnavailable=25% \
        --set deployment.strategy.rollingUpdate.maxSurge=25% \
        --wait --timeout=900s

    # Vérifications post-déploiement
    - kubectl rollout status deployment/$CI_PROJECT_NAME --namespace production --timeout=600s

    # Health check
    - sleep 30  # Attendre la stabilisation
    - kubectl run health-check-$CI_PIPELINE_ID
      --image=curlimages/curl:latest
      --namespace production
      --rm -i --restart=Never
      -- curl -f https://$CI_PROJECT_NAME.example.com/health

    # Notification de succès
    - |
      curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"🚀 Production deployment successful: $CI_PROJECT_NAME:${CI_COMMIT_SHA:0:8}\"}" \
        $SLACK_WEBHOOK_URL || true

  when: manual
  rules:
    - if: $CI_COMMIT_REF_NAME == "main"

# GitOps - Mise à jour du repo de configuration
update_gitops:
  stage: deploy
  image: alpine/git:latest
  before_script:
    - apk add --no-cache curl jq
    - git config --global user.email "gitlab-ci@company.com"
    - git config --global user.name "GitLab CI"
  script:
    # Cloner le repo GitOps
    - git clone https://oauth2:$GITOPS_TOKEN@gitlab.company.com/infrastructure/k8s-configs.git
    - cd k8s-configs

    # Déterminer l'environnement selon la branche
    - |
      if [ "$CI_COMMIT_REF_NAME" = "main" ]; then
        ENVIRONMENT="production"
      elif [ "$CI_COMMIT_REF_NAME" = "develop" ]; then
        ENVIRONMENT="staging"
      else
        echo "Branch not configured for GitOps update"
        exit 0
      fi

    # Mettre à jour avec kustomize
    - cd environments/$ENVIRONMENT/$CI_PROJECT_NAME
    - curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
    - ./kustomize edit set image $CI_PROJECT_NAME=$CI_REGISTRY_IMAGE:${CI_COMMIT_SHA:0:8}

    # Vérifier les changements
    - git diff

    # Commit et push
    - git add .
    - |
      git commit -m "Update $CI_PROJECT_NAME image to ${CI_COMMIT_SHA:0:8} in $ENVIRONMENT

      Triggered by: $CI_PIPELINE_URL
      Commit: $CI_COMMIT_SHA
      Branch: $CI_COMMIT_REF_NAME" || exit 0
    - git push origin main

    echo "GitOps repository updated successfully"

  rules:
    - if: $CI_COMMIT_REF_NAME == "main"
      when: on_success
    - if: $CI_COMMIT_REF_NAME == "develop"
      when: on_success

# Cleanup des review apps
cleanup_review:
  <<: *kubectl_template
  stage: cleanup
  environment:
    name: review/$CI_COMMIT_REF_SLUG
    action: stop
  script:
    - helm uninstall $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG
      --namespace $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG || true
    - kubectl delete namespace $CI_PROJECT_NAME-$CI_COMMIT_REF_SLUG || true
    - echo "Review environment cleaned up"
  when: manual
  rules:
    - if: $CI_MERGE_REQUEST_IID
```

### Configuration avancée GitLab CI

#### Pipeline multi-projets avec déclencheurs

```yaml
# .gitlab-ci.yml pour microservices
# Pipeline parent qui orchestre plusieurs services

variables:
  MICROSERVICES: "frontend backend worker notification"

# Déclenchement des builds des microservices
trigger_microservices:
  stage: trigger
  parallel:
    matrix:
      - SERVICE: [frontend, backend, worker, notification]
  trigger:
    project: microservices/$SERVICE
    branch: $CI_COMMIT_REF_NAME
    strategy: depend
  rules:
    - changes:
      - "$SERVICE/**/*"
      - "shared/**/*"
      - ".gitlab-ci.yml"

# Déploiement orchestré
deploy_stack:
  stage: deploy
  needs:
    - trigger_microservices
  script:
    - echo "All microservices built successfully"
    - kubectl apply -f k8s/namespace.yaml
    - kubectl apply -f k8s/configmap.yaml
    - kubectl apply -f k8s/secrets.yaml

    # Déployer dans l'ordre (base de données, puis services)
    - kubectl apply -f k8s/database/
    - kubectl wait --for=condition=ready pod -l app=database --timeout=300s

    - kubectl apply -f k8s/backend/
    - kubectl wait --for=condition=ready pod -l app=backend --timeout=300s

    - kubectl apply -f k8s/frontend/
    - kubectl apply -f k8s/worker/
    - kubectl apply -f k8s/notification/

    # Tests d'intégration globaux
    - kubectl apply -f k8s/tests/integration-tests.yaml
    - kubectl wait --for=condition=complete job/integration-tests --timeout=600s
```

#### Template de déploiement réutilisable

```yaml
# templates/deploy-template.yml
.deploy_template: &deploy_template
  image: bitnami/kubectl:latest
  before_script:
    - kubectl version --client
    - helm version --client
  script:
    # Validation du namespace
    - kubectl create namespace $ENVIRONMENT || true
    - kubectl label namespace $ENVIRONMENT managed-by=gitlab-ci --overwrite

    # Application des secrets
    - |
      if [ -f "k8s/secrets-$ENVIRONMENT.yaml" ]; then
        kubectl apply -f k8s/secrets-$ENVIRONMENT.yaml -n $ENVIRONMENT
      fi

    # Déploiement avec Helm
    - |
      helm upgrade --install $CI_PROJECT_NAME ./helm-chart \
        --namespace $ENVIRONMENT \
        --values helm-chart/values-$ENVIRONMENT.yaml \
        --set image.repository=$CI_REGISTRY_IMAGE \
        --set image.tag=${IMAGE_TAG:-$CI_COMMIT_SHA} \
        --set app.version=$CI_COMMIT_SHA \
        --set app.environment=$ENVIRONMENT \
        --wait --timeout=${DEPLOY_TIMEOUT:-600s}

    # Health check post-déploiement
    - |
      kubectl run healthcheck-$CI_PIPELINE_ID-$ENVIRONMENT \
        --image=curlimages/curl:latest \
        --namespace $ENVIRONMENT \
        --rm -i --restart=Never \
        --quiet \
        -- curl -f -m 30 http://$CI_PROJECT_NAME.$ENVIRONMENT.svc.cluster.local/health

  artifacts:
    reports:
      dotenv: deploy.env

  # Retry en cas d'échec temporaire
  retry:
    max: 2
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

# Utilisation du template
deploy_staging:
  <<: *deploy_template
  stage: deploy
  variables:
    ENVIRONMENT: staging
  environment:
    name: staging
    url: https://staging-$CI_PROJECT_NAME.example.com
  rules:
    - if: $CI_COMMIT_REF_NAME == "develop"

deploy_production:
  <<: *deploy_template
  stage: deploy
  variables:
    ENVIRONMENT: production
    DEPLOY_TIMEOUT: 900s
  environment:
    name: production
    url: https://$CI_PROJECT_NAME.example.com
  when: manual
  rules:
    - if: $CI_COMMIT_REF_NAME == "main"
```

### GitOps avec GitLab Agent

#### Configuration GitOps dans le repository

```yaml
# .gitlab/agents/production/config.yaml
gitops:
  # Projects à surveiller pour GitOps
  manifest_projects:
  - id: "infrastructure/k8s-manifests"
    default_namespace: "default"
    paths:
    # Surveiller tous les YAML dans ces dossiers
    - glob: 'applications/production/**/*.{yaml,yml}'
    - glob: 'infrastructure/production/**/*.{yaml,yml}'

    # Configuration de réconciliation
    reconcile_timeout: 3600s
    dry_run_strategy: none
    prune: true
    prune_timeout: 3600s
    prune_propagation_policy: foreground
    inventory_policy: must_match

    # Inclusions/exclusions
    paths_exclusion:
    - glob: '**/secrets.yaml'  # Exclure les secrets (gérés séparément)
    - glob: '**/.git/**'

ci_access:
  # Accès pour CI/CD depuis GitLab
  groups:
  - id: "infrastructure"
    default_namespace: "gitlab-ci"
  projects:
  - id: "infrastructure/k8s-manifests"
    default_namespace: "default"
    environments:
    - name: "production"
      namespace: "production"
    - name: "staging"
      namespace: "staging"
```

#### Structure du repository GitOps

```
k8s-manifests/
├── applications/
│   ├── production/
│   │   ├── frontend/
│   │   │   ├── deployment.yaml
│   │   │   ├── service.yaml
│   │   │   ├── ingress.yaml
│   │   │   └── kustomization.yaml
│   │   └── backend/
│   │       ├── deployment.yaml
│   │       ├── service.yaml
│   │       └── configmap.yaml
│   └── staging/
│       └── ... (structure similaire)
├── infrastructure/
│   ├── production/
│   │   ├── ingress-nginx/
│   │   ├── cert-manager/
│   │   └── monitoring/
│   └── staging/
└── .gitlab-ci.yml  # Pipeline pour validation
```

### Monitoring des pipelines GitLab CI

#### Métriques et alertes Prometheus

```yaml
# monitoring/gitlab-ci-metrics.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: gitlab-ci-pipelines
  namespace: monitoring
spec:
  selector:
    matchLabels:
      app: gitlab-ci-exporter
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

---
# Alertes pour les pipelines
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: gitlab-ci-alerts
  namespace: monitoring
spec:
  groups:
  - name: gitlab-ci.rules
    rules:
    - alert: GitLabCIPipelineFailed
      expr: increase(gitlab_ci_pipeline_duration_seconds{status="failed"}[5m]) > 0
      for: 0m
      labels:
        severity: warning
        team: devops
      annotations:
        summary: "GitLab CI Pipeline Failed"
        description: "Pipeline {{ $labels.project }} failed in stage {{ $labels.stage }}"

    - alert: GitLabCIHighFailureRate
      expr: |
        (
          rate(gitlab_ci_pipeline_duration_seconds{status="failed"}[1h])
          /
          rate(gitlab_ci_pipeline_duration_seconds[1h])
        ) * 100 > 20
      for: 10m
      labels:
        severity: critical
        team: devops
      annotations:
        summary: "High GitLab CI Failure Rate"
        description: "Pipeline failure rate is {{ $value }}% over the last hour"
```

### Sécurité et bonnes pratiques

#### Variables et secrets sécurisés

```yaml
# Configuration des variables dans GitLab
# Settings > CI/CD > Variables

variables:
  # Variables publiques (visible dans les logs)
  DOCKER_REGISTRY: registry.company.com
  KUBE_NAMESPACE: production

  # Variables protégées (seulement branches/tags protégés)
  PRODUCTION_DB_HOST:
    value: prod-db.company.com
    protected: true

  # Variables masquées (non visibles dans les logs)
  API_SECRET_KEY:
    value: "super-secret-key-here"
    masked: true
    protected: true

  # Variables de type file (pour certificats, kubeconfig)
  KUBECONFIG:
    value: |
      apiVersion: v1
      kind: Config
      clusters: [...]
    type: file
    protected: true
    masked: true
```

#### RBAC pour GitLab CI

```yaml
# rbac/gitlab-ci-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitlab-ci
  namespace: gitlab-ci
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: gitlab-ci-deployer
rules:
# Permissions pour les déploiements
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets", "daemonsets", "statefulsets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

# Permissions pour les services et ingress
- apiGroups: [""]
  resources: ["services", "endpoints"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

- apiGroups: ["networking.k8s.io"]
  resources: ["ingresses"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

# Permissions pour les pods (logs, exec)
- apiGroups: [""]
  resources: ["pods", "pods/log", "pods/exec"]
  verbs: ["get", "list", "watch", "create", "delete"]

# Permissions pour les configmaps et secrets
- apiGroups: [""]
  resources: ["configmaps", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: gitlab-ci-deployer
subjects:
- kind: ServiceAccount
  name: gitlab-ci
  namespace: gitlab-ci
roleRef:
  kind: ClusterRole
  name: gitlab-ci-deployer
  apiGroup: rbac.authorization.k8s.io
```

---

## Conclusion de la section 9.5

Cette section a exploré les principales approches GitOps et CI/CD pour Kubernetes, chacune avec ses spécificités et cas d'usage optimaux.

### Récapitulatif des outils

#### ArgoCD vs Flux
**ArgoCD** : Interface graphique riche, configuration centralisée, idéal pour débuter
**Flux** : Approche modulaire, intégration CNCF native, plus de flexibilité

#### Tekton
**Forces** : Cloud-native pur, extensible, réutilisable
**Complexité** : Courbe d'apprentissage élevée, configuration verbose

#### Jenkins sur K8s
**Avantages** : Écosystème mature, agents dynamiques, migration facilité
**Considérations** : Héritage monolithique, maintenance plus lourde

#### GitLab CI
**Intégration** : Solution tout-en-un, GitLab Agent performant
**Simplicité** : Configuration intuitive, Auto DevOps

### Choix stratégique par contexte

**Startup/PME** : GitLab CI + ArgoCD
→ Simplicité, coûts maîtrisés, montée en compétences rapide

**Entreprise existante avec Jenkins** : Jenkins sur K8s + ArgoCD
→ Migration progressive, réutilisation des compétences

**Organisation cloud-native** : Tekton + Flux
→ Solution entièrement Kubernetes, extensibilité maximale

**Multi-cloud complexe** : GitLab CI + Flux + Policies
→ Gouvernance avancée, conformité entreprise

### Patterns GitOps universels

✅ **Git comme source de vérité** pour toute configuration
✅ **Pull-based deployment** avec agents dans le cluster
✅ **Observabilité complète** des déploiements
✅ **Séparation Code/Config** avec repositories dédiés
✅ **Review process** pour tous changements de configuration

### Sécurité transversale

🔐 **Least privilege** pour tous les service accounts
🔐 **Secrets management** avec rotation automatique
🔐 **Image scanning** intégré aux pipelines
🔐 **Network policies** pour isoler les environments
🔐 **Audit logging** complet des déploiements

La maîtrise de GitOps et CI/CD sur Kubernetes représente l'aboutissement de la modernisation des pratiques de développement, permettant des déploiements fiables, traçables et automatisés à grande échelle.

⏭️
