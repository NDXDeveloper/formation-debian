üîù Retour au [Sommaire](/SOMMAIRE.md)

# 9.3 Distributions Kubernetes

*Module 9 - Kubernetes et orchestration | Niveau : Avanc√©*

## Vue d'ensemble

Kubernetes "vanilla" (la version officielle) peut √™tre complexe √† installer et g√©rer. Diff√©rentes distributions ont √©merg√© pour simplifier l'exp√©rience utilisateur selon des cas d'usage sp√©cifiques. Cette section explore les principales alternatives √† kubeadm, leurs avantages et leurs cas d'usage appropri√©s.

**Pourquoi des distributions alternatives ?**
- **Simplicit√© d'installation** : R√©duction de la complexit√© op√©rationnelle
- **Cas d'usage sp√©cialis√©s** : Edge computing, d√©veloppement, production
- **Optimisations** : Performance, empreinte m√©moire, s√©curit√©
- **√âcosyst√®me int√©gr√©** : Outils compl√©mentaires pr√©-configur√©s

### Comparaison des distributions

| Distribution | Complexit√© | Empreinte | Cas d'usage | Production |
|--------------|------------|-----------|-------------|------------|
| **kubeadm** | √âlev√©e | Standard | Apprentissage/Prod | ‚úÖ |
| **K3s** | Faible | Minimale | Edge/IoT | ‚úÖ |
| **MicroK8s** | Faible | Petite | Dev/Test | ‚ö†Ô∏è |
| **Kind** | Tr√®s faible | Virtuelle | Dev/CI | ‚ùå |
| **Minikube** | Faible | VM | Dev local | ‚ùå |
| **Rancher** | Mod√©r√©e | √âlev√©e | Multi-cluster | ‚úÖ |

---

## 9.3.1 K3s (lightweight Kubernetes)

### Introduction √† K3s

**K3s** est une distribution Kubernetes l√©g√®re d√©velopp√©e par Rancher Labs, optimis√©e pour les environnements contraints en ressources.

#### Caract√©ristiques principales :

**Architecture simplifi√©e**
- **Binaire unique** : Un seul ex√©cutable contient tous les composants
- **SQLite par d√©faut** : Remplace etcd pour les d√©ploiements simples
- **Batteries incluses** : CNI, DNS, Ingress Controller int√©gr√©s
- **Empreinte r√©duite** : ~40 MB binaire, ~512 MB RAM minimum

**Composants supprim√©s/remplac√©s**
- Pilotes cloud legacy
- Plugins stockage non essentiels
- Composants alpha/beta non stables
- Docker remplac√© par containerd

**Ajouts sp√©cialis√©s**
- **Traefik** comme Ingress Controller par d√©faut
- **ServiceLB** pour LoadBalancer simple
- **Local Path Provisioner** pour stockage local
- **Network Policies** avec Canal (Flannel + Calico)

### Installation de K3s

#### Installation serveur simple

```bash
# Installation en une commande
curl -sfL https://get.k3s.io | sh -

# Ou avec options sp√©cifiques
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="--disable=traefik --write-kubeconfig-mode=644" sh -

# V√©rifier l'installation
sudo k3s kubectl get nodes

# Configurer kubectl pour l'utilisateur
mkdir -p ~/.kube
sudo cp /etc/rancher/k3s/k3s.yaml ~/.kube/config
sudo chown $(id -u):$(id -g) ~/.kube/config

# Ou utiliser directement k3s kubectl
alias kubectl='k3s kubectl'
```

#### Options d'installation courantes

```bash
# D√©sactiver certains composants
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="
  --disable=traefik
  --disable=servicelb
  --disable=local-storage
  --write-kubeconfig-mode=644
  --cluster-cidr=10.42.0.0/16
  --service-cidr=10.43.0.0/16
" sh -

# Installation avec configuration externe
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="
  --config=/etc/rancher/k3s/config.yaml
" sh -
```

#### Fichier de configuration K3s

```yaml
# /etc/rancher/k3s/config.yaml
# Configuration du cluster
cluster-cidr: "10.42.0.0/16"
service-cidr: "10.43.0.0/16"
cluster-dns: "10.43.0.10"

# D√©sactiver des composants
disable:
  - traefik
  - servicelb

# Configuration r√©seau
flannel-backend: "vxlan"
flannel-iface: "eth0"

# S√©curit√©
write-kubeconfig-mode: "0644"
protect-kernel-defaults: true

# Logging
log: "/var/log/k3s.log"
alsologtostderr: true

# Node labels
node-label:
  - "environment=production"
  - "region=europe"

# Node taints
node-taint:
  - "node-role.kubernetes.io/master=true:NoSchedule"
```

### Cluster K3s HA

#### Architecture HA avec base de donn√©es externe

```bash
# Installation du serveur avec MySQL/PostgreSQL
curl -sfL https://get.k3s.io | sh -s - server \
  --datastore-endpoint="mysql://username:password@tcp(hostname:3306)/k3s"

# Ou avec PostgreSQL
curl -sfL https://get.k3s.io | sh -s - server \
  --datastore-endpoint="postgres://username:password@hostname:5432/k3s?sslmode=disable"
```

#### Cluster HA avec etcd int√©gr√©

```bash
# Premier serveur (initialise le cluster)
curl -sfL https://get.k3s.io | sh -s - server \
  --cluster-init \
  --token=SECRET_TOKEN

# Serveurs suppl√©mentaires
curl -sfL https://get.k3s.io | sh -s - server \
  --server=https://<FIRST_SERVER_IP>:6443 \
  --token=SECRET_TOKEN

# R√©cup√©rer le token sur le premier serveur
sudo cat /var/lib/rancher/k3s/server/node-token
```

### Agents K3s (Worker nodes)

```bash
# Installation d'un agent
curl -sfL https://get.k3s.io | K3S_URL=https://<SERVER_IP>:6443 \
  K3S_TOKEN=<NODE_TOKEN> sh -

# Avec options sp√©cifiques
curl -sfL https://get.k3s.io | K3S_URL=https://server.example.com:6443 \
  K3S_TOKEN=SECRET_TOKEN \
  INSTALL_K3S_EXEC="--node-label region=edge --node-label type=worker" sh -
```

### Configuration avanc√©e K3s

#### Registries priv√©s

```yaml
# /etc/rancher/k3s/registries.yaml
mirrors:
  "docker.io":
    endpoint:
      - "https://registry.example.com"
  "registry.example.com":
    endpoint:
      - "https://registry.example.com"

configs:
  "registry.example.com":
    auth:
      username: "user"
      password: "pass"
    tls:
      ca_file: "/path/to/ca.crt"
      cert_file: "/path/to/cert.crt"
      key_file: "/path/to/key.key"
```

#### Helm int√©gr√©

```bash
# Les charts dans ce dossier sont automatiquement d√©ploy√©s
sudo mkdir -p /var/lib/rancher/k3s/server/manifests

# Exemple: installer Prometheus
cat <<EOF | sudo tee /var/lib/rancher/k3s/server/manifests/prometheus.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
---
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: prometheus
  namespace: kube-system
spec:
  chart: prometheus
  repo: https://prometheus-community.github.io/helm-charts
  targetNamespace: monitoring
  valuesContent: |
    server:
      persistentVolume:
        size: 10Gi
EOF
```

---

## 9.3.2 MicroK8s et alternatives

### MicroK8s par Canonical

**MicroK8s** est la distribution Kubernetes de Canonical (Ubuntu), con√ßue pour la simplicit√© et le d√©veloppement.

#### Caract√©ristiques MicroK8s

**Avantages**
- **Installation snap** : Simple sur Ubuntu/Debian
- **Addons modulaires** : Activation √† la demande
- **Multi-node** : Clustering facile
- **Batteries incluses** : Dashboard, DNS, stockage

**Limitations**
- **D√©pendance snap** : Moins flexible que les binaires
- **Ubuntu-centrique** : Optimis√© pour Ubuntu
- **Overhead** : Plus lourd que K3s

### Installation MicroK8s

#### Sur Debian avec snap

```bash
# Installer snapd sur Debian
sudo apt update
sudo apt install -y snapd
sudo systemctl enable --now snapd

# Ajouter le r√©pertoire snap au PATH
echo 'export PATH=$PATH:/snap/bin' >> ~/.bashrc
source ~/.bashrc

# Red√©marrer pour initialiser snapd
sudo reboot

# Installer MicroK8s
sudo snap install microk8s --classic

# Ajouter l'utilisateur au groupe
sudo usermod -aG microk8s $USER
newgrp microk8s

# V√©rifier l'installation
microk8s status --wait-ready
```

#### Configuration de base

```bash
# Activer les addons essentiels
microk8s enable dns dashboard storage

# Activer d'autres addons utiles
microk8s enable ingress metallb registry

# Lister les addons disponibles
microk8s status

# Configurer kubectl
microk8s kubectl config view --raw > ~/.kube/config

# Ou utiliser l'alias
alias kubectl='microk8s kubectl'
```

### Addons MicroK8s

#### Addons de base

```bash
# DNS (CoreDNS)
microk8s enable dns

# Dashboard Kubernetes
microk8s enable dashboard

# Acc√©der au dashboard
token=$(microk8s kubectl -n kube-system get secret | grep default-token | cut -d " " -f1)
microk8s kubectl -n kube-system describe secret $token
microk8s kubectl proxy
# Acc√®s: http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/
```

#### Addons r√©seau et stockage

```bash
# Ingress NGINX
microk8s enable ingress

# MetalLB pour LoadBalancer
microk8s enable metallb:10.64.140.43-10.64.140.49

# Registry Docker local
microk8s enable registry

# Stockage persistant
microk8s enable storage
microk8s enable rook-ceph  # Stockage distribu√©
```

#### Addons monitoring et observabilit√©

```bash
# Prometheus + Grafana
microk8s enable prometheus

# Jaeger pour le tracing
microk8s enable jaeger

# Fluentd pour les logs
microk8s enable fluentd
```

### Clustering MicroK8s

```bash
# Sur le n≈ìud principal
microk8s add-node

# Cette commande affiche quelque chose comme:
# microk8s join 192.168.1.10:25000/TOKEN --worker

# Sur les n≈ìuds √† ajouter
microk8s join 192.168.1.10:25000/TOKEN --worker

# V√©rifier le cluster
microk8s kubectl get nodes
```

### Alternatives l√©g√®res

#### Minikube

Minikube est id√©al pour l'apprentissage et le d√©veloppement local.

```bash
# Installation
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# D√©marrage
minikube start --driver=docker

# Ou avec KVM
minikube start --driver=kvm2

# Activer des addons
minikube addons enable dashboard
minikube addons enable ingress

# Acc√©der aux services
minikube service <service-name>
minikube tunnel  # Pour LoadBalancer
```

#### k0s par Mirantis

```bash
# Installation k0s
curl -sSLf https://get.k0s.sh | sudo sh

# Initialiser le contr√¥leur
sudo k0s install controller --single

# D√©marrer le service
sudo systemctl start k0scontroller

# Configuration kubectl
sudo k0s kubeconfig admin > ~/.kube/config
```

---

## 9.3.3 Rancher sur Debian

### Introduction √† Rancher

**Rancher** est une plateforme compl√®te de gestion de Kubernetes qui simplifie le d√©ploiement et la gestion de clusters multiples.

#### Fonctionnalit√©s principales

**Gestion multi-cluster**
- Interface web centralis√©e
- D√©ploiement de clusters sur diff√©rents providers
- Gestion centralis√©e des utilisateurs et des acc√®s

**Catalogue d'applications**
- Helm charts pr√©-configur√©s
- Applications populaires (monitoring, logging, CI/CD)
- Templates personnalis√©s

**S√©curit√© int√©gr√©e**
- RBAC avanc√© avec interface graphique
- Scan de s√©curit√© des images
- Conformit√© et politiques

### Architecture Rancher

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Rancher UI     ‚îÇ  ‚Üê Interface web de gestion
‚îÇ  (Management)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Downstream      ‚îÇ  ‚Üê Clusters Kubernetes g√©r√©s
‚îÇ Clusters        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Installation de Rancher

#### Pr√©requis

```bash
# Installer Docker (si pas d√©j√† fait)
curl -fsSL https://get.docker.com | sh
sudo usermod -aG docker $USER

# Ou utiliser un cluster K3s existant
curl -sfL https://get.k3s.io | sh -
```

#### Installation avec Docker (simple)

```bash
# Lancer Rancher en conteneur
sudo docker run -d --restart=unless-stopped \
  -p 80:80 -p 443:443 \
  --privileged \
  -v /opt/rancher:/var/lib/rancher \
  rancher/rancher:latest

# R√©cup√©rer le mot de passe bootstrap
sudo docker logs $(sudo docker ps | grep rancher/rancher | awk '{print $1}') 2>&1 | grep "Bootstrap Password:"

# Acc√©der √† l'interface: https://your-server-ip
```

#### Installation sur cluster K3s

```bash
# Installer Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Ajouter le repo Rancher
helm repo add rancher-latest https://releases.rancher.com/server-charts/latest
helm repo update

# Cr√©er le namespace
kubectl create namespace cattle-system

# Installer cert-manager
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.crds.yaml
helm repo add jetstack https://charts.jetstack.io
helm repo update
helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.13.0

# Installer Rancher
helm install rancher rancher-latest/rancher \
  --namespace cattle-system \
  --set hostname=rancher.example.com \
  --set bootstrapPassword=admin123 \
  --set ingress.tls.source=letsEncrypt \
  --set letsEncrypt.email=admin@example.com \
  --set letsEncrypt.environment=production
```

### Configuration initiale de Rancher

#### Premier acc√®s

1. **Acc√®s web** : Naviguez vers `https://rancher.example.com`
2. **Mot de passe** : Utilisez le mot de passe bootstrap
3. **Configuration SSL** : Configurez le certificat si n√©cessaire
4. **URL du serveur** : Confirmez l'URL d'acc√®s

#### Cr√©ation d'un cluster

```yaml
# Via l'interface ou API, √©quivalent √† ce manifest
apiVersion: provisioning.cattle.io/v1
kind: Cluster
metadata:
  name: production-cluster
  namespace: fleet-default
spec:
  kubernetesVersion: v1.28.2+k3s1
  rkeConfig:
    machineGlobalConfig:
      disable:
        - rke2-snapshot-controller
        - rke2-snapshot-controller-crd
        - rke2-snapshot-validation-webhook
    machinePools:
    - name: controlplane-pool
      quantity: 1
      unhealthyNodeTimeout: 0s
      machineConfigRef:
        kind: VmwarevsphereConfig
        name: controlplane-config
      roleTemplate:
        controlPlane: true
        etcd: true
        worker: false
```

### Gestion des applications avec Rancher

#### Apps & Marketplace

```bash
# Via l'interface Rancher:
# 1. Aller dans "Apps & Marketplace"
# 2. Parcourir le catalogue
# 3. Installer des applications populaires

# Exemples d'applications disponibles:
# - Prometheus & Grafana (monitoring)
# - Longhorn (stockage distribu√©)
# - Istio (service mesh)
# - GitLab (CI/CD)
```

#### Projects et Namespaces

Rancher organise les ressources en **Projects** qui regroupent plusieurs namespaces.

```yaml
# Exemple de Project
apiVersion: management.cattle.io/v3
kind: Project
metadata:
  name: production
  namespace: c-cluster-id
spec:
  displayName: "Production Environment"
  description: "Production workloads"
  namespaceDefaultResourceQuota:
    limit:
      requests.cpu: "2"
      requests.memory: "4Gi"
      limits.cpu: "4"
      limits.memory: "8Gi"
```

### Monitoring avec Rancher

#### Activation du monitoring

```bash
# Via interface Rancher:
# 1. Cluster -> Tools -> Monitoring
# 2. Install Monitoring
# 3. Configurer les param√®tres

# Configuration personnalis√©e possible via values.yaml
```

#### Dashboards Grafana int√©gr√©s

Rancher fournit des dashboards pr√©configur√©s pour :
- Vue cluster (CPU, m√©moire, r√©seau)
- Vue n≈ìuds (utilisation des ressources)
- Vue workloads (applications)
- Vue stockage persistant

### S√©curit√© et RBAC avec Rancher

#### Gestion des utilisateurs

```bash
# Via interface Rancher:
# 1. Users & Authentication
# 2. Ajouter des utilisateurs locaux ou configurer l'AD/LDAP
# 3. Assigner des r√¥les globaux et par cluster
```

#### R√¥les Rancher

**R√¥les globaux**
- **Global Admin** : Acc√®s complet
- **Standard User** : Acc√®s aux clusters assign√©s
- **User Base** : Acc√®s minimal

**R√¥les par cluster**
- **Cluster Owner** : Admin du cluster
- **Cluster Member** : Acc√®s en lecture/√©criture
- **Read Only** : Acc√®s lecture seule

---

## 9.3.4 Kind pour d√©veloppement

### Introduction √† Kind

**Kind** (Kubernetes IN Docker) cr√©e des clusters Kubernetes locaux en utilisant des conteneurs Docker comme n≈ìuds.

#### Avantages de Kind

**D√©veloppement**
- **Rapidit√©** : D√©marrage en secondes
- **Isolation** : Clusters jetables
- **CI/CD** : Id√©al pour les tests automatis√©s
- **Simplicit√©** : Configuration minimale

**Cas d'usage**
- Tests d'applications Kubernetes
- D√©veloppement de controllers/operators
- CI/CD pipelines
- Formations et d√©monstrations

### Installation de Kind

```bash
# M√©thode 1: Binaire
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# M√©thode 2: Go (si install√©)
go install sigs.k8s.io/kind@v0.20.0

# M√©thode 3: Depuis les sources
git clone https://github.com/kubernetes-sigs/kind
cd kind
make build
sudo cp bin/kind /usr/local/bin/
```

### Utilisation de base de Kind

```bash
# Cr√©er un cluster simple
kind create cluster

# Cr√©er un cluster avec nom sp√©cifique
kind create cluster --name dev-cluster

# Lister les clusters
kind get clusters

# Obtenir la kubeconfig
kind get kubeconfig --name dev-cluster

# Supprimer un cluster
kind delete cluster --name dev-cluster
```

### Configuration avanc√©e de Kind

#### Fichier de configuration

```yaml
# kind-config.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
name: development

# Configuration des n≈ìuds
nodes:
- role: control-plane
  # Port mapping pour acc√©der aux services
  extraPortMappings:
  - containerPort: 80
    hostPort: 8080
    protocol: TCP
  - containerPort: 443
    hostPort: 8443
    protocol: TCP
  # Mounts pour partager des fichiers
  extraMounts:
  - hostPath: /tmp/shared
    containerPath: /shared

# N≈ìuds workers
- role: worker
- role: worker

# Configuration r√©seau
networking:
  # D√©sactiver le CNI par d√©faut
  disableDefaultCNI: true
  # CIDR personnalis√© pour les pods
  podSubnet: "10.244.0.0/16"
  # CIDR pour les services
  serviceSubnet: "10.96.0.0/12"

# Images personnalis√©es
kubeadmConfigPatches:
- |
  kind: InitConfiguration
  nodeRegistration:
    kubeletExtraArgs:
      node-labels: "environment=development"
```

#### Cluster multi-n≈ìuds

```bash
# Cr√©er le cluster avec la config
kind create cluster --config=kind-config.yaml

# V√©rifier les n≈ìuds
kubectl get nodes

# V√©rifier les conteneurs Docker
docker ps | grep kind
```

### D√©veloppement avec Kind

#### Load des images locales

```bash
# Construire une image locale
docker build -t myapp:latest .

# Charger l'image dans Kind
kind load docker-image myapp:latest --name development

# Ou depuis un fichier tar
docker save myapp:latest | kind load image-archive /dev/stdin --name development
```

#### Registry local

```yaml
# local-registry-config.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
containerdConfigPatches:
- |-
  [plugins."io.containerd.grpc.v1.cri".registry.mirrors."localhost:5001"]
    endpoint = ["http://registry:5000"]
```

```bash
# D√©marrer un registry local
docker run -d --restart=always -p 5001:5000 --name registry registry:2

# Cr√©er le cluster avec le registry
kind create cluster --config=local-registry-config.yaml

# Connecter le registry au r√©seau Kind
docker network connect kind registry

# Pousser des images vers le registry local
docker tag myapp:latest localhost:5001/myapp:latest
docker push localhost:5001/myapp:latest
```

### Testing avec Kind

#### Tests d'int√©gration

```bash
#!/bin/bash
# test-integration.sh

# Cr√©er un cluster de test
kind create cluster --name test-cluster

# D√©ployer l'application
kubectl apply -f manifests/

# Attendre que les pods soient pr√™ts
kubectl wait --for=condition=ready pod -l app=myapp --timeout=300s

# Ex√©cuter les tests
go test ./tests/integration/...

# Nettoyer
kind delete cluster --name test-cluster
```

#### CI/CD avec Kind

```yaml
# .github/workflows/test.yml
name: Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Install Kind
      run: |
        curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
        chmod +x ./kind
        sudo mv ./kind /usr/local/bin/kind

    - name: Create cluster
      run: kind create cluster

    - name: Test deployment
      run: |
        kubectl apply -f manifests/
        kubectl wait --for=condition=ready pod -l app=myapp

    - name: Run tests
      run: go test ./...
```

### Ingress avec Kind

#### Configuration Ingress

```yaml
# kind-ingress-config.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
```

```bash
# Cr√©er le cluster avec Ingress
kind create cluster --config=kind-ingress-config.yaml

# Installer NGINX Ingress
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml

# Attendre que l'Ingress soit pr√™t
kubectl wait --namespace ingress-nginx \
  --for=condition=ready pod \
  --selector=app.kubernetes.io/component=controller \
  --timeout=90s
```

#### Test de l'Ingress

```yaml
# test-ingress.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hello-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: hello-app
  template:
    metadata:
      labels:
        app: hello-app
    spec:
      containers:
      - name: hello-app
        image: gcr.io/google-samples/hello-app:1.0
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: hello-service
spec:
  selector:
    app: hello-app
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: hello-ingress
spec:
  rules:
  - host: hello.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: hello-service
            port:
              number: 80
```

```bash
# D√©ployer l'application
kubectl apply -f test-ingress.yaml

# Tester l'acc√®s
curl -H "Host: hello.local" http://localhost/

# Ou ajouter √† /etc/hosts
echo "127.0.0.1 hello.local" | sudo tee -a /etc/hosts
curl http://hello.local/
```

### Debugging avec Kind

#### Acc√®s aux n≈ìuds

```bash
# Lister les conteneurs des n≈ìuds
docker ps | grep kind

# Acc√©der √† un n≈ìud
docker exec -it kind-control-plane bash

# Examiner les logs des composants
docker exec kind-control-plane journalctl -u kubelet

# Examiner la configuration
docker exec kind-control-plane cat /etc/kubernetes/kubelet/kubelet-config.yaml
```

#### Export des logs

```bash
# Exporter les logs du cluster
kind export logs --name development ./logs/

# Structure des logs:
# logs/
#   docker-info.txt
#   kind-control-plane/
#     kubelet.log
#     containerd.log
#     kubernetes/
```

---

## Comparaison finale et recommandations

### Matrice de choix

| Besoin | Distribution recommand√©e | Raison |
|--------|------------------------|--------|
| **Production edge/IoT** | K3s | L√©ger, stable, HA |
| **D√©veloppement local** | Kind ou MicroK8s | Rapide, jetable |
| **Multi-cluster enterprise** | Rancher | Gestion centralis√©e |
| **CI/CD testing** | Kind | Int√©gration parfaite |
| **Apprentissage K8s** | MicroK8s ou Minikube | Addons √©ducatifs |
| **Production traditionnelle** | kubeadm | Contr√¥le complet |

### Crit√®res de s√©lection

**Ressources disponibles**
- **< 1GB RAM** : K3s uniquement
- **1-4GB RAM** : K3s, MicroK8s, Kind
- **> 4GB RAM** : Toutes options

**Complexit√© acceptable**
- **Minimal** : Kind, MicroK8s
- **Mod√©r√©** : K3s, Rancher
- **√âlev√©** : kubeadm

**Persistance des donn√©es**
- **Jetable** : Kind, Minikube
- **D√©veloppement** : MicroK8s, K3s local
- **Production** : K3s HA, Rancher, kubeadm

### Guide de migration

#### De Kind vers K3s
```bash
# Export de la configuration
kubectl get all -A -o yaml > backup.yaml

# Nettoyage des m√©tadonn√©es Kind-sp√©cifiques
sed -i '/creationTimestamp/d' backup.yaml
sed -i '/resourceVersion/d' backup.yaml
sed -i '/uid:/d' backup.yaml

# D√©ployer sur K3s
kubectl apply -f backup.yaml
```

#### De MicroK8s vers production
```bash
# Export des applications
microk8s kubectl get deployments,services,ingresses -A -o yaml > apps.yaml

# Adaptation des manifests pour K3s/kubeadm
# (suppression des r√©f√©rences MicroK8s-sp√©cifiques)
```

---

## Conclusion

Les distributions Kubernetes offrent des alternatives adapt√©es √† diff√©rents cas d'usage :

### Points cl√©s

‚úÖ **K3s** - Le choix optimal pour la production edge et les environnements contraints
‚úÖ **MicroK8s** - Parfait pour le d√©veloppement sur Ubuntu/Debian
‚úÖ **Kind** - Incontournable pour les tests et CI/CD
‚úÖ **Rancher** - Excellence pour la gestion multi-cluster enterprise

### Recommandations finales

**Pour d√©buter** : Commencez avec Kind pour l'apprentissage, puis migrez vers K3s pour des d√©ploiements plus permanents.

**Pour la production** :
- **Edge/IoT** : K3s avec sa faible empreinte et sa robustesse
- **Enterprise** : Rancher pour la gestion centralis√©e de multiples clusters
- **Cloud-native** : kubeadm pour le contr√¥le complet et la conformit√©

**Pour le d√©veloppement** :
- **Tests rapides** : Kind avec sa cr√©ation/destruction instantan√©e
- **D√©veloppement continu** : MicroK8s avec ses addons int√©gr√©s
- **Int√©gration CI/CD** : Kind dans les pipelines automatis√©s

### Bonnes pratiques par distribution

#### K3s en production
```bash
# Configuration recommand√©e pour production
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="
  --write-kubeconfig-mode=644
  --protect-kernel-defaults=true
  --secrets-encryption=true
  --disable=traefik
  --disable=servicelb
  --kube-apiserver-arg=audit-log-path=/var/log/k3s-audit.log
  --kube-apiserver-arg=audit-log-maxage=30
  --kube-apiserver-arg=audit-log-maxbackup=10
  --kube-apiserver-arg=audit-log-maxsize=100
" sh -
```

#### MicroK8s pour d√©veloppement
```bash
# Stack de d√©veloppement complet
microk8s enable dns dashboard storage ingress registry
microk8s enable prometheus jaeger fluentd
microk8s enable knative  # Pour serverless
```

#### Kind pour CI/CD
```yaml
# .github/workflows/k8s-test.yml (exemple complet)
name: Kubernetes Tests
on: [push, pull_request]

jobs:
  k8s-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        k8s-version: ["1.27.3", "1.28.0", "1.29.0"]

    steps:
    - name: Checkout
      uses: actions/checkout@v4

    - name: Setup Kind
      uses: helm/kind-action@v1.8.0
      with:
        kubernetes_version: v${{ matrix.k8s-version }}
        cluster_name: test-cluster
        config: .github/kind-config.yaml

    - name: Load images
      run: |
        docker build -t myapp:test .
        kind load docker-image myapp:test --name test-cluster

    - name: Deploy and test
      run: |
        kubectl apply -f k8s/
        kubectl wait --for=condition=available --timeout=300s deployment/myapp
        kubectl run test --rm -i --restart=Never --image=curlimages/curl -- \
          curl -f http://myapp-service:80/health

    - name: Cleanup
      if: always()
      run: kind delete cluster --name test-cluster
```

### Troubleshooting par distribution

#### K3s Common Issues

```bash
# Probl√®me: K3s ne d√©marre pas
sudo systemctl status k3s
sudo journalctl -u k3s

# Solution courante: V√©rifier les permissions
sudo chown -R root:root /var/lib/rancher/k3s
sudo chmod 600 /etc/rancher/k3s/k3s.yaml

# Probl√®me: Pods en pending
kubectl describe nodes
kubectl get events --sort-by=.metadata.creationTimestamp

# Red√©marrage propre
sudo systemctl stop k3s
sudo /usr/local/bin/k3s-killall.sh
sudo systemctl start k3s
```

#### MicroK8s Common Issues

```bash
# Probl√®me: MicroK8s ne d√©marre pas
microk8s status
microk8s inspect

# Solution: R√©initialiser
microk8s reset
microk8s start

# Probl√®me: Addons ne fonctionnent pas
microk8s disable <addon>
microk8s enable <addon>

# V√©rifier les logs
microk8s kubectl logs -n kube-system <pod-name>
```

#### Kind Common Issues

```bash
# Probl√®me: Cluster ne se cr√©e pas
kind create cluster --verbosity=1

# Solution: Nettoyer Docker
docker system prune
kind delete cluster --name <cluster-name>

# Probl√®me: Images ne se chargent pas
docker images | grep <image-name>
kind load docker-image <image> --name <cluster-name>

# V√©rifier les images dans le cluster
docker exec -it <kind-node> crictl images
```

### Surveillance et maintenance

#### Monitoring K3s

```yaml
# k3s-monitoring.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
    scrape_configs:
    - job_name: 'k3s-nodes'
      static_configs:
      - targets: ['localhost:10249', 'localhost:10250']
    - job_name: 'k3s-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

#### Health checks automatis√©s

```bash
#!/bin/bash
# health-check.sh - Script de surveillance

check_k3s_health() {
    if ! systemctl is-active --quiet k3s; then
        echo "K3s service is not running"
        exit 1
    fi

    if ! k3s kubectl get nodes | grep -q "Ready"; then
        echo "No ready nodes found"
        exit 1
    fi

    # V√©rifier les composants critiques
    critical_pods="coredns local-path-provisioner traefik"
    for pod in $critical_pods; do
        if ! k3s kubectl get pods -A | grep $pod | grep -q "Running"; then
            echo "Critical pod $pod not running"
            exit 1
        fi
    done

    echo "K3s cluster is healthy"
}

check_k3s_health
```

### Migration entre distributions

#### De Kind vers K3s (D√©veloppement vers Production)

```bash
#!/bin/bash
# migrate-kind-to-k3s.sh

echo "=== Migration Kind vers K3s ==="

# 1. Export des ressources depuis Kind
echo "Exportation des ressources..."
kubectl config use-context kind-dev-cluster

# Exporter les manifests (sans les ressources syst√®me)
kubectl get deployments,services,ingresses,configmaps,secrets \
  --all-namespaces \
  -o yaml > app-resources.yaml

# 2. Nettoyer les m√©tadonn√©es sp√©cifiques √† Kind
echo "Nettoyage des m√©tadonn√©es..."
sed -i '/resourceVersion:/d' app-resources.yaml
sed -i '/uid:/d' app-resources.yaml
sed -i '/creationTimestamp:/d' app-resources.yaml
sed -i '/selfLink:/d' app-resources.yaml

# 3. Installer K3s si pas d√©j√† fait
echo "Installation de K3s..."
if ! command -v k3s &> /dev/null; then
    curl -sfL https://get.k3s.io | sh -
fi

# 4. Attendre que K3s soit pr√™t
echo "Attente de la disponibilit√© de K3s..."
while ! k3s kubectl get nodes 2>/dev/null | grep -q "Ready"; do
    sleep 5
done

# 5. Appliquer les ressources sur K3s
echo "D√©ploiement sur K3s..."
k3s kubectl apply -f app-resources.yaml

echo "Migration termin√©e !"
echo "V√©rifiez le statut: k3s kubectl get pods -A"
```

#### De MicroK8s vers Rancher

```bash
#!/bin/bash
# migrate-microk8s-to-rancher.sh

# 1. Export depuis MicroK8s
microk8s kubectl get all,ingress,configmap,secret \
  --all-namespaces -o yaml > microk8s-backup.yaml

# 2. Filtrer et nettoyer
grep -v "microk8s" microk8s-backup.yaml > cleaned-backup.yaml

# 3. Importer dans Rancher (via l'interface ou kubectl)
# Se connecter au cluster g√©r√© par Rancher puis:
kubectl apply -f cleaned-backup.yaml
```

### Performance tuning par distribution

#### Optimisation K3s

```yaml
# /etc/rancher/k3s/config.yaml
# Configuration optimis√©e pour production
node-label:
  - "node-type=production"
kubelet-arg:
  - "max-pods=250"
  - "image-gc-high-threshold=90"
  - "image-gc-low-threshold=80"
kube-apiserver-arg:
  - "max-requests-inflight=400"
  - "max-mutating-requests-inflight=200"
kube-controller-manager-arg:
  - "kube-api-qps=100"
  - "kube-api-burst=100"
```

#### Optimisation Kind pour gros projets

```yaml
# kind-performance-config.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraMounts:
  - hostPath: /tmp/kind-cache
    containerPath: /var/local-path-provisioner
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    etcd:
      local:
        serverCertSANs:
        - "localhost"
        peerCertSANs:
        - "localhost"
        dataDir: "/tmp/kind-etcd"
    apiServer:
      certSANs:
      - "localhost"
- role: worker
  extraMounts:
  - hostPath: /tmp/kind-cache
    containerPath: /var/local-path-provisioner
```

### S√©curit√© par distribution

#### Hardening K3s

```bash
# Script de s√©curisation K3s
sudo tee /etc/rancher/k3s/config.yaml <<EOF
protect-kernel-defaults: true
secrets-encryption: true
kube-apiserver-arg:
  - "audit-log-path=/var/log/k3s-audit.log"
  - "audit-log-maxage=30"
  - "audit-log-maxbackup=10"
  - "audit-log-maxsize=100"
  - "audit-policy-file=/etc/rancher/k3s/audit-policy.yaml"
  - "request-timeout=300s"
  - "service-account-lookup=true"
kube-controller-manager-arg:
  - "terminated-pod-gc-threshold=10"
  - "use-service-account-credentials=true"
kubelet-arg:
  - "streaming-connection-idle-timeout=5m"
  - "make-iptables-util-chains=true"
EOF

# Politique d'audit
sudo tee /etc/rancher/k3s/audit-policy.yaml <<EOF
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: None
  users: ["system:kube-proxy"]
  verbs: ["watch"]
  resources:
  - group: ""
    resources: ["endpoints", "services"]
- level: None
  namespaces: ["kube-system"]
  verbs: ["get"]
  resources:
  - group: ""
    resources: ["configmaps"]
- level: None
  users: ["kubelet"]
  verbs: ["get"]
  resources:
  - group: ""
    resources: ["nodes"]
- level: Request
  omitStages: ["RequestReceived"]
  resources:
  - group: ""
    resources: ["secrets", "configmaps"]
- level: Metadata
  omitStages: ["RequestReceived"]
EOF
```

#### S√©curisation Rancher

```yaml
# rancher-security-values.yaml pour Helm
global:
  cattle:
    psp:
      enabled: true
auditLog:
  level: 1
  destination: hostPath
  hostPath: /var/log/rancher/audit
ingress:
  tls:
    source: letsEncrypt
  extraAnnotations:
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/ssl-protocols: "TLSv1.2 TLSv1.3"
```

### Automatisation avanc√©e

#### GitOps avec ArgoCD sur K3s

```bash
# Installation ArgoCD sur K3s
k3s kubectl create namespace argocd
k3s kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# Configuration Ingress pour ArgoCD
cat <<EOF | k3s kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: argocd-server-ingress
  namespace: argocd
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: "GRPC"
    nginx.ingress.kubernetes.io/server-snippet: |
      grpc_read_timeout 300;
      grpc_send_timeout 300;
      client_max_body_size 1m;
spec:
  rules:
  - host: argocd.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: argocd-server
            port:
              number: 80
  tls:
  - hosts:
    - argocd.local
    secretName: argocd-secret
EOF
```

#### Backup automatis√© multi-distributions

```bash
#!/bin/bash
# universal-k8s-backup.sh

detect_distribution() {
    if command -v k3s &> /dev/null; then
        echo "k3s"
        KUBECTL="k3s kubectl"
    elif command -v microk8s &> /dev/null; then
        echo "microk8s"
        KUBECTL="microk8s kubectl"
    elif docker ps | grep -q "kind"; then
        echo "kind"
        KUBECTL="kubectl"
    else
        echo "standard"
        KUBECTL="kubectl"
    fi
}

backup_etcd() {
    local distro=$1
    case $distro in
        k3s)
            ETCDCTL_API=3 etcdctl snapshot save "/backup/k3s-snapshot-$(date +%Y%m%d-%H%M%S).db" \
              --endpoints=https://127.0.0.1:2379 \
              --cacert=/var/lib/rancher/k3s/server/tls/etcd/server-ca.crt \
              --cert=/var/lib/rancher/k3s/server/tls/etcd/server-client.crt \
              --key=/var/lib/rancher/k3s/server/tls/etcd/server-client.key
            ;;
        standard)
            ETCDCTL_API=3 etcdctl snapshot save "/backup/etcd-snapshot-$(date +%Y%m%d-%H%M%S).db" \
              --endpoints=https://127.0.0.1:2379 \
              --cacert=/etc/kubernetes/pki/etcd/ca.crt \
              --cert=/etc/kubernetes/pki/etcd/server.crt \
              --key=/etc/kubernetes/pki/etcd/server.key
            ;;
    esac
}

backup_resources() {
    mkdir -p "/backup/resources/$(date +%Y%m%d)"

    # Backup de toutes les ressources
    $KUBECTL get all --all-namespaces -o yaml > "/backup/resources/$(date +%Y%m%d)/all-resources.yaml"

    # Backup des CRDs
    $KUBECTL get crd -o yaml > "/backup/resources/$(date +%Y%m%d)/crds.yaml"

    # Backup des secrets (attention √† la s√©curit√© !)
    $KUBECTL get secrets --all-namespaces -o yaml > "/backup/resources/$(date +%Y%m%d)/secrets.yaml"
}

main() {
    DISTRO=$(detect_distribution)
    echo "Distribution d√©tect√©e: $DISTRO"

    mkdir -p /backup

    backup_resources

    if [[ "$DISTRO" != "kind" && "$DISTRO" != "microk8s" ]]; then
        backup_etcd $DISTRO
    fi

    echo "Backup termin√© dans /backup/"
    ls -la /backup/
}

main "$@"
```

### Conclusion finale

Les distributions Kubernetes offrent une flexibilit√© remarquable pour s'adapter aux diff√©rents besoins :

**√âcosyst√®me mature** : Chaque distribution a trouv√© sa place dans l'√©cosyst√®me
**Interop√©rabilit√©** : Les comp√©tences sont largement transf√©rables
**√âvolution continue** : Les distributions s'am√©liorent constamment

**Choix strat√©gique recommand√©** :
1. **Apprentissage** : Kind + MicroK8s
2. **D√©veloppement** : Kind (tests) + K3s (staging)
3. **Production** : K3s (edge) + Rancher (enterprise) + kubeadm (cloud)

La ma√Ætrise de plusieurs distributions vous permet de choisir l'outil optimal pour chaque contexte, maximisant l'efficacit√© et la pertinence de vos d√©ploiements Kubernetes.

‚è≠Ô∏è
